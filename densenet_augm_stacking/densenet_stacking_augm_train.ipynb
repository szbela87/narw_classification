{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845c8b9b-fb9a-4e89-a5e8-eff6f1e9af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import KFold\n",
    "from torchvision.models import densenet121\n",
    "\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442f1f8-21a2-4145-aee2-b66b5fb03af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f47788-9a7b-46a1-abb2-1254484d142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "SEED = 2024\n",
    "BATCH_SIZE = 32\n",
    "TEST_SPLIT_RATIO = 0.25\n",
    "N_FFT = 256\n",
    "HOP_LEN = 256 // 6\n",
    "AUGM = True\n",
    "# Creating the results directory\n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')\n",
    "RESULTS_FILENAME = \"./results/inrun_results\" # _x.csv\n",
    "VALID_RESULTS_FILENAME = \"./results/valid_results\" # _x.csv\n",
    "TRAIN_RESULTS_FILENAME = \"./results/train_results\" # _x.csv\n",
    "BEST_MODEL_FILENAME = \"./results/best-model\" # _x.pt\n",
    "DIV_FACTOR = 5.\n",
    "FINAL_DIV_FACTOR = 10.\n",
    "WEIGHT_DECAY = 0.005\n",
    "LEARNING_RATE = 0.0005\n",
    "EVAL_FREQ=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1385666-618c-4f6b-a7c3-f6557b4ea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = \"../data/train_whales.csv\"\n",
    "TEST_DATASET = \"../data/test_whales.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b41649-9ec3-4cb7-be98-df999eed5c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available: True\n",
      "Device: ['NVIDIA GeForce RTX 3090']\n"
     ]
    }
   ],
   "source": [
    "# Fixing the seeds\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Cuda is available: {torch.cuda.is_available()}\")\n",
    "dev_names = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "print(f\"Device: {dev_names}\")\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78bb6c-63b7-424a-aa78-26cb11def586",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159c0f8-3c55-4436-9ea0-6e8fe91884f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39dedb9f-9568-48bd-8435-7643eba80e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"no-whale\",\"whale\"]\n",
    "target_names_dict = {target_names[i]: i for i in range(len(target_names))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584bdfe-0b63-4359-bcf2-f06605c58423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ccfa212-ff54-421c-8209-cc0acd7381c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading - Elapsed time: 5.56s\n"
     ]
    }
   ],
   "source": [
    "t_s = default_timer()\n",
    "data_train = pd.read_csv(TRAIN_DATASET,sep=\",\")\n",
    "columns = data_train.columns\n",
    "data_train[columns[-1]]=data_train[columns[-1]].replace(target_names_dict)\n",
    "data_train = data_train.values\n",
    "data_train_labels = data_train[:,-1].reshape(-1)\n",
    "data_train_labels = data_train_labels.astype(int)\n",
    "data_train = data_train[:,:-1]\n",
    "t_e = default_timer()\n",
    "\n",
    "print(f\"Data loading - Elapsed time: {t_e-t_s:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e557db05-6f57-4bc2-8578-f1959148bf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10316, 4000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd890c17-4072-468f-82a7-c97ea0f61427",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a6bf254-fc7b-49f2-af44-9ec6bce5c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data_shift(data, u=1.0):\n",
    "    if np.random.random() < u:\n",
    "        shift = int(round(np.random.uniform(-len(data)*0.25, len(data)*0.25)))\n",
    "        data = np.roll(data, shift)\n",
    "    return data\n",
    "\n",
    "class AugmentedSTFTDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, n_fft, hop_length, augment=False):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = self.inputs[idx]\n",
    "        \n",
    "        if self.augment:\n",
    "            sample = random_data_shift(sample)\n",
    "        \n",
    "        data = librosa.stft(sample, n_fft=self.n_fft, hop_length=self.hop_length)\n",
    "        data = librosa.amplitude_to_db(np.abs(data), ref=np.max)\n",
    "        data = np.flipud(data)  # Flip vertically\n",
    "        data = data.copy()  \n",
    "        data = np.expand_dims(data, axis=-1)  # Add channel dimension\n",
    "        data = np.transpose(data, (2, 0, 1))  # Reorder dimensions to match PyTorch expectations\n",
    "        return torch.FloatTensor(data), torch.LongTensor([self.targets[idx]])\n",
    "\n",
    "# Data loader\n",
    "def create_dataloader(inputs, targets, batch_size, n_fft, hop_length, shuffle=True, augment=False):\n",
    "    dataset = AugmentedSTFTDataset(inputs, targets, n_fft, hop_length, augment=augment)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e471dc3a-514f-4239-b48f-26af07d92d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,) [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "(20,) [18 19  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "source": [
    "test = np.arange(20)\n",
    "print(test.shape, test)\n",
    "test_out = random_data_shift(test)\n",
    "print(test_out.shape,test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debff9c-4aae-4748-86f9-dd656c3c6f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97aa8121-08c4-4e4a-8b81-6fcad8821ff8",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb480af7-7e5d-4c3b-969c-4b7554ed28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Densenet121(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.densenet121 = densenet121().features\n",
    "        self.densenet121.conv0 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.classifier = torch.nn.Linear(1024, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.densenet121.forward(x)\n",
    "        out = torch.nn.functional.avg_pool2d(out, kernel_size = out.shape[2:], stride= out.shape[2:], padding=0, count_include_pad = False)\n",
    "        out = self.classifier(out.view(out.shape[0], -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad4ce4b-f93b-4945-97d0-010181735fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Densenet121(\n",
       "  (densenet121): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Densenet121()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95167e3b-192e-4076-b4e0-a576a3c0d810",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5fbf62-5852-4d05-8f21-56c458e791f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83695a75-92cb-4df8-b695-3cbb44b1dd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    number_of_elements = 0\n",
    "    \n",
    "    correct_pred = torch.zeros(2)\n",
    "    total_pred = torch.zeros(2)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for x, y in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.float().to(device).view(-1,1)\n",
    "            \n",
    "            batch_size = x.shape[0]\n",
    "            number_of_elements += batch_size\n",
    "            \n",
    "            pred = model(x).view(-1,1)\n",
    "            loss = criterion(pred, y)\n",
    "            \n",
    "            top_pred = (torch.sigmoid(pred) > 0.5).int()\n",
    "            acc = top_pred.eq(y.int().view_as(top_pred)).sum()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "            y_true.append(y.int().cpu().numpy())\n",
    "            y_pred.append(top_pred.cpu().numpy())\n",
    "            \n",
    "        y_true_a = np.concatenate(y_true, axis=0)\n",
    "        y_pred_a = np.concatenate(y_pred, axis=0)\n",
    "                        \n",
    "        #balanced_acc = balanced_accuracy_score(y_true_a, y_pred_a)\n",
    "        acc = accuracy_score(y_true_a, y_pred_a)\n",
    "\n",
    "    return epoch_loss / number_of_elements, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ac50b-fdaf-4973-806b-274f46017039",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9233037b-22f8-4668-8ae9-b01dcb7a2c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    0    0    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 7.94s | lr: 1.02e-04 | Val. Loss: 0.437 |  Val. Acc: 81.20% | B. Val. Loss: 0.437 |  B. Val. Acc: 81.20%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 16.46s | lr: 1.07e-04 | Val. Loss: 0.418 |  Val. Acc: 80.91% | B. Val. Loss: 0.418 |  B. Val. Acc: 81.20%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 24.78s | lr: 1.15e-04 | Val. Loss: 0.422 |  Val. Acc: 81.25% | B. Val. Loss: 0.418 |  B. Val. Acc: 81.25%\n",
      "Epoch: 001 | ET: 49.70s | \t Train Loss: 0.348 | Train Acc: 84.17% \t Val. Loss: 0.335 |  Val. Acc: 84.64% \t | B. Val. Loss: 0.335 |  B. Val. Acc: 84.64%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.46s | lr: 1.41e-04 | Val. Loss: 0.298 |  Val. Acc: 87.55% | B. Val. Loss: 0.298 |  B. Val. Acc: 87.55%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 13.97s | lr: 1.59e-04 | Val. Loss: 0.347 |  Val. Acc: 85.95% | B. Val. Loss: 0.298 |  B. Val. Acc: 87.55%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.29s | lr: 1.79e-04 | Val. Loss: 0.298 |  Val. Acc: 88.57% | B. Val. Loss: 0.298 |  B. Val. Acc: 88.57%\n",
      "Epoch: 002 | ET: 46.72s | \t Train Loss: 0.316 | Train Acc: 85.28% \t Val. Loss: 0.303 |  Val. Acc: 86.72% \t | B. Val. Loss: 0.298 |  B. Val. Acc: 88.57%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.46s | lr: 2.23e-04 | Val. Loss: 0.280 |  Val. Acc: 87.98% | B. Val. Loss: 0.280 |  B. Val. Acc: 88.57%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 13.83s | lr: 2.48e-04 | Val. Loss: 0.256 |  Val. Acc: 89.73% | B. Val. Loss: 0.256 |  B. Val. Acc: 89.73%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.36s | lr: 2.74e-04 | Val. Loss: 0.241 |  Val. Acc: 91.04% | B. Val. Loss: 0.241 |  B. Val. Acc: 91.04%\n",
      "Epoch: 003 | ET: 46.75s | \t Train Loss: 0.261 | Train Acc: 89.70% \t Val. Loss: 0.237 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.237 |  B. Val. Acc: 91.04%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.45s | lr: 3.26e-04 | Val. Loss: 0.213 |  Val. Acc: 91.96% | B. Val. Loss: 0.213 |  B. Val. Acc: 91.96%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.93s | lr: 3.52e-04 | Val. Loss: 0.277 |  Val. Acc: 89.24% | B. Val. Loss: 0.213 |  B. Val. Acc: 91.96%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.24s | lr: 3.77e-04 | Val. Loss: 0.215 |  Val. Acc: 91.57% | B. Val. Loss: 0.213 |  B. Val. Acc: 91.96%\n",
      "Epoch: 004 | ET: 46.46s | \t Train Loss: 0.240 | Train Acc: 90.20% \t Val. Loss: 0.210 |  Val. Acc: 91.91% \t | B. Val. Loss: 0.210 |  B. Val. Acc: 91.96%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.45s | lr: 4.22e-04 | Val. Loss: 0.206 |  Val. Acc: 91.52% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.96%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.76s | lr: 4.42e-04 | Val. Loss: 0.231 |  Val. Acc: 91.67% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.96%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.08s | lr: 4.59e-04 | Val. Loss: 0.196 |  Val. Acc: 92.01% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.01%\n",
      "Epoch: 005 | ET: 46.70s | \t Train Loss: 0.220 | Train Acc: 90.86% \t Val. Loss: 0.190 |  Val. Acc: 92.64% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.64%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.45s | lr: 4.85e-04 | Val. Loss: 0.189 |  Val. Acc: 92.88% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.88%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.94s | lr: 4.93e-04 | Val. Loss: 0.304 |  Val. Acc: 86.68% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.88%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.26s | lr: 4.98e-04 | Val. Loss: 0.192 |  Val. Acc: 92.15% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.88%\n",
      "Epoch: 006 | ET: 46.62s | \t Train Loss: 0.210 | Train Acc: 91.23% \t Val. Loss: 0.187 |  Val. Acc: 92.78% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.88%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.45s | lr: 5.00e-04 | Val. Loss: 0.172 |  Val. Acc: 93.70% | B. Val. Loss: 0.172 |  B. Val. Acc: 93.70%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.94s | lr: 4.98e-04 | Val. Loss: 0.242 |  Val. Acc: 89.83% | B. Val. Loss: 0.172 |  B. Val. Acc: 93.70%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.27s | lr: 4.96e-04 | Val. Loss: 0.183 |  Val. Acc: 92.20% | B. Val. Loss: 0.172 |  B. Val. Acc: 93.70%\n",
      "Epoch: 007 | ET: 46.56s | \t Train Loss: 0.208 | Train Acc: 91.17% \t Val. Loss: 0.191 |  Val. Acc: 92.25% \t | B. Val. Loss: 0.172 |  B. Val. Acc: 93.70%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.46s | lr: 4.90e-04 | Val. Loss: 0.169 |  Val. Acc: 93.41% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.70%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.78s | lr: 4.86e-04 | Val. Loss: 0.259 |  Val. Acc: 89.92% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.70%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.10s | lr: 4.81e-04 | Val. Loss: 0.171 |  Val. Acc: 92.68% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.70%\n",
      "Epoch: 008 | ET: 46.39s | \t Train Loss: 0.194 | Train Acc: 91.82% \t Val. Loss: 0.179 |  Val. Acc: 92.88% \t | B. Val. Loss: 0.169 |  B. Val. Acc: 93.70%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.45s | lr: 4.69e-04 | Val. Loss: 0.162 |  Val. Acc: 93.22% | B. Val. Loss: 0.162 |  B. Val. Acc: 93.70%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.78s | lr: 4.62e-04 | Val. Loss: 0.201 |  Val. Acc: 91.52% | B. Val. Loss: 0.162 |  B. Val. Acc: 93.70%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.11s | lr: 4.55e-04 | Val. Loss: 0.166 |  Val. Acc: 93.17% | B. Val. Loss: 0.162 |  B. Val. Acc: 93.70%\n",
      "Epoch: 009 | ET: 46.38s | \t Train Loss: 0.232 | Train Acc: 90.81% \t Val. Loss: 0.222 |  Val. Acc: 90.89% \t | B. Val. Loss: 0.162 |  B. Val. Acc: 93.70%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.45s | lr: 4.38e-04 | Val. Loss: 0.161 |  Val. Acc: 93.80% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.99s | lr: 4.28e-04 | Val. Loss: 0.165 |  Val. Acc: 93.27% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.35s | lr: 4.18e-04 | Val. Loss: 0.178 |  Val. Acc: 92.39% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "Epoch: 010 | ET: 46.72s | \t Train Loss: 0.185 | Train Acc: 92.61% \t Val. Loss: 0.170 |  Val. Acc: 93.51% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.47s | lr: 3.97e-04 | Val. Loss: 0.177 |  Val. Acc: 91.86% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.82s | lr: 3.85e-04 | Val. Loss: 0.200 |  Val. Acc: 91.62% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.17s | lr: 3.73e-04 | Val. Loss: 0.221 |  Val. Acc: 92.20% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "Epoch: 011 | ET: 46.56s | \t Train Loss: 0.189 | Train Acc: 92.49% \t Val. Loss: 0.175 |  Val. Acc: 93.12% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.54s | lr: 3.49e-04 | Val. Loss: 0.172 |  Val. Acc: 92.30% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.89s | lr: 3.36e-04 | Val. Loss: 0.207 |  Val. Acc: 91.13% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.24s | lr: 3.23e-04 | Val. Loss: 0.184 |  Val. Acc: 92.78% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "Epoch: 012 | ET: 46.62s | \t Train Loss: 0.165 | Train Acc: 93.15% \t Val. Loss: 0.163 |  Val. Acc: 93.17% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.46s | lr: 2.96e-04 | Val. Loss: 0.158 |  Val. Acc: 93.65% | B. Val. Loss: 0.158 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.82s | lr: 2.82e-04 | Val. Loss: 0.165 |  Val. Acc: 92.97% | B. Val. Loss: 0.158 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.16s | lr: 2.68e-04 | Val. Loss: 0.213 |  Val. Acc: 92.97% | B. Val. Loss: 0.158 |  B. Val. Acc: 93.80%\n",
      "Epoch: 013 | ET: 46.68s | \t Train Loss: 0.163 | Train Acc: 93.00% \t Val. Loss: 0.159 |  Val. Acc: 93.90% \t | B. Val. Loss: 0.158 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.46s | lr: 2.41e-04 | Val. Loss: 0.161 |  Val. Acc: 93.07% | B. Val. Loss: 0.158 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.80s | lr: 2.27e-04 | Val. Loss: 0.164 |  Val. Acc: 93.02% | B. Val. Loss: 0.158 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.14s | lr: 2.14e-04 | Val. Loss: 0.194 |  Val. Acc: 91.76% | B. Val. Loss: 0.158 |  B. Val. Acc: 93.90%\n",
      "Epoch: 014 | ET: 46.48s | \t Train Loss: 0.147 | Train Acc: 93.92% \t Val. Loss: 0.161 |  Val. Acc: 93.51% \t | B. Val. Loss: 0.158 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.157 |  Val. Acc: 93.65% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.82s | lr: 1.74e-04 | Val. Loss: 0.169 |  Val. Acc: 92.78% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.15s | lr: 1.61e-04 | Val. Loss: 0.163 |  Val. Acc: 92.54% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "Epoch: 015 | ET: 46.48s | \t Train Loss: 0.147 | Train Acc: 93.87% \t Val. Loss: 0.168 |  Val. Acc: 92.25% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.45s | lr: 1.36e-04 | Val. Loss: 0.158 |  Val. Acc: 93.75% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.77s | lr: 1.24e-04 | Val. Loss: 0.169 |  Val. Acc: 92.54% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.08s | lr: 1.13e-04 | Val. Loss: 0.162 |  Val. Acc: 93.31% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "Epoch: 016 | ET: 46.34s | \t Train Loss: 0.143 | Train Acc: 94.17% \t Val. Loss: 0.164 |  Val. Acc: 93.17% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.45s | lr: 9.17e-05 | Val. Loss: 0.160 |  Val. Acc: 93.70% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.77s | lr: 8.16e-05 | Val. Loss: 0.163 |  Val. Acc: 93.94% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.94%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.35s | lr: 7.21e-05 | Val. Loss: 0.160 |  Val. Acc: 93.99% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "Epoch: 017 | ET: 46.82s | \t Train Loss: 0.128 | Train Acc: 94.62% \t Val. Loss: 0.167 |  Val. Acc: 93.36% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.45s | lr: 5.51e-05 | Val. Loss: 0.164 |  Val. Acc: 93.85% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.76s | lr: 4.74e-05 | Val. Loss: 0.167 |  Val. Acc: 92.83% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.07s | lr: 4.04e-05 | Val. Loss: 0.160 |  Val. Acc: 93.41% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "Epoch: 018 | ET: 46.31s | \t Train Loss: 0.121 | Train Acc: 95.25% \t Val. Loss: 0.166 |  Val. Acc: 93.70% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.45s | lr: 2.86e-05 | Val. Loss: 0.169 |  Val. Acc: 93.02% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.76s | lr: 2.37e-05 | Val. Loss: 0.173 |  Val. Acc: 93.51% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.08s | lr: 1.95e-05 | Val. Loss: 0.165 |  Val. Acc: 93.60% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "Epoch: 019 | ET: 46.33s | \t Train Loss: 0.116 | Train Acc: 95.67% \t Val. Loss: 0.175 |  Val. Acc: 92.97% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.45s | lr: 1.34e-05 | Val. Loss: 0.167 |  Val. Acc: 93.46% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.78s | lr: 1.15e-05 | Val. Loss: 0.170 |  Val. Acc: 93.31% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.10s | lr: 1.04e-05 | Val. Loss: 0.169 |  Val. Acc: 93.51% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "Epoch: 020 | ET: 46.39s | \t Train Loss: 0.111 | Train Acc: 95.64% \t Val. Loss: 0.171 |  Val. Acc: 93.27% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.99%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    0    1    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.47s | lr: 1.02e-04 | Val. Loss: 0.472 |  Val. Acc: 76.11% | B. Val. Loss: 0.472 |  B. Val. Acc: 76.11%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.89s | lr: 1.07e-04 | Val. Loss: 0.409 |  Val. Acc: 81.10% | B. Val. Loss: 0.409 |  B. Val. Acc: 81.10%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.45s | lr: 1.15e-04 | Val. Loss: 0.420 |  Val. Acc: 80.91% | B. Val. Loss: 0.409 |  B. Val. Acc: 81.10%\n",
      "Epoch: 001 | ET: 46.92s | \t Train Loss: 0.359 | Train Acc: 84.34% \t Val. Loss: 0.347 |  Val. Acc: 84.88% \t | B. Val. Loss: 0.347 |  B. Val. Acc: 84.88%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.45s | lr: 1.41e-04 | Val. Loss: 0.312 |  Val. Acc: 87.11% | B. Val. Loss: 0.312 |  B. Val. Acc: 87.11%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 13.97s | lr: 1.59e-04 | Val. Loss: 0.377 |  Val. Acc: 83.96% | B. Val. Loss: 0.312 |  B. Val. Acc: 87.11%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.39s | lr: 1.79e-04 | Val. Loss: 0.324 |  Val. Acc: 85.32% | B. Val. Loss: 0.312 |  B. Val. Acc: 87.11%\n",
      "Epoch: 002 | ET: 46.74s | \t Train Loss: 0.383 | Train Acc: 82.05% \t Val. Loss: 0.382 |  Val. Acc: 81.83% \t | B. Val. Loss: 0.312 |  B. Val. Acc: 87.11%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.47s | lr: 2.23e-04 | Val. Loss: 0.259 |  Val. Acc: 89.49% | B. Val. Loss: 0.259 |  B. Val. Acc: 89.49%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.04s | lr: 2.48e-04 | Val. Loss: 0.251 |  Val. Acc: 88.91% | B. Val. Loss: 0.251 |  B. Val. Acc: 89.49%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.38s | lr: 2.74e-04 | Val. Loss: 0.242 |  Val. Acc: 89.53% | B. Val. Loss: 0.242 |  B. Val. Acc: 89.53%\n",
      "Epoch: 003 | ET: 46.88s | \t Train Loss: 0.293 | Train Acc: 87.35% \t Val. Loss: 0.280 |  Val. Acc: 87.94% \t | B. Val. Loss: 0.242 |  B. Val. Acc: 89.53%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.276 |  Val. Acc: 88.66% | B. Val. Loss: 0.242 |  B. Val. Acc: 89.53%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.80s | lr: 3.52e-04 | Val. Loss: 0.199 |  Val. Acc: 91.76% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.34s | lr: 3.77e-04 | Val. Loss: 0.225 |  Val. Acc: 91.18% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.76%\n",
      "Epoch: 004 | ET: 46.67s | \t Train Loss: 0.226 | Train Acc: 90.32% \t Val. Loss: 0.202 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 91.76%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.197 |  Val. Acc: 92.73% | B. Val. Loss: 0.197 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.03s | lr: 4.42e-04 | Val. Loss: 0.322 |  Val. Acc: 89.44% | B. Val. Loss: 0.197 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.38s | lr: 4.59e-04 | Val. Loss: 0.345 |  Val. Acc: 84.16% | B. Val. Loss: 0.197 |  B. Val. Acc: 92.73%\n",
      "Epoch: 005 | ET: 46.72s | \t Train Loss: 0.201 | Train Acc: 90.69% \t Val. Loss: 0.184 |  Val. Acc: 92.01% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.186 |  Val. Acc: 92.05% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.83s | lr: 4.93e-04 | Val. Loss: 0.184 |  Val. Acc: 91.62% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.18s | lr: 4.98e-04 | Val. Loss: 0.210 |  Val. Acc: 90.65% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.73%\n",
      "Epoch: 006 | ET: 46.56s | \t Train Loss: 0.217 | Train Acc: 90.48% \t Val. Loss: 0.210 |  Val. Acc: 90.50% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.180 |  Val. Acc: 92.20% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.83s | lr: 4.98e-04 | Val. Loss: 0.198 |  Val. Acc: 92.10% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.18s | lr: 4.96e-04 | Val. Loss: 0.208 |  Val. Acc: 91.62% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.73%\n",
      "Epoch: 007 | ET: 46.61s | \t Train Loss: 0.211 | Train Acc: 91.38% \t Val. Loss: 0.199 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.180 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.47s | lr: 4.90e-04 | Val. Loss: 0.174 |  Val. Acc: 92.97% | B. Val. Loss: 0.174 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.02s | lr: 4.86e-04 | Val. Loss: 0.170 |  Val. Acc: 93.27% | B. Val. Loss: 0.170 |  B. Val. Acc: 93.27%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.54s | lr: 4.81e-04 | Val. Loss: 0.176 |  Val. Acc: 92.39% | B. Val. Loss: 0.170 |  B. Val. Acc: 93.27%\n",
      "Epoch: 008 | ET: 46.89s | \t Train Loss: 0.222 | Train Acc: 90.50% \t Val. Loss: 0.194 |  Val. Acc: 91.33% \t | B. Val. Loss: 0.170 |  B. Val. Acc: 93.27%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.47s | lr: 4.69e-04 | Val. Loss: 0.163 |  Val. Acc: 93.36% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 14.02s | lr: 4.62e-04 | Val. Loss: 0.173 |  Val. Acc: 92.39% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.37s | lr: 4.55e-04 | Val. Loss: 0.211 |  Val. Acc: 91.18% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.36%\n",
      "Epoch: 009 | ET: 46.72s | \t Train Loss: 0.205 | Train Acc: 92.28% \t Val. Loss: 0.197 |  Val. Acc: 92.39% \t | B. Val. Loss: 0.163 |  B. Val. Acc: 93.36%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.47s | lr: 4.38e-04 | Val. Loss: 0.161 |  Val. Acc: 93.12% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.82s | lr: 4.28e-04 | Val. Loss: 0.173 |  Val. Acc: 92.34% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.16s | lr: 4.18e-04 | Val. Loss: 0.164 |  Val. Acc: 93.36% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.36%\n",
      "Epoch: 010 | ET: 46.51s | \t Train Loss: 0.177 | Train Acc: 92.80% \t Val. Loss: 0.169 |  Val. Acc: 92.88% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.36%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.47s | lr: 3.97e-04 | Val. Loss: 0.175 |  Val. Acc: 92.05% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.82s | lr: 3.85e-04 | Val. Loss: 0.165 |  Val. Acc: 93.17% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.16s | lr: 3.73e-04 | Val. Loss: 0.163 |  Val. Acc: 93.75% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.75%\n",
      "Epoch: 011 | ET: 46.68s | \t Train Loss: 0.216 | Train Acc: 89.71% \t Val. Loss: 0.219 |  Val. Acc: 90.12% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.75%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.47s | lr: 3.49e-04 | Val. Loss: 0.156 |  Val. Acc: 93.51% | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.82s | lr: 3.36e-04 | Val. Loss: 0.166 |  Val. Acc: 93.22% | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.17s | lr: 3.23e-04 | Val. Loss: 0.185 |  Val. Acc: 92.68% | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "Epoch: 012 | ET: 46.52s | \t Train Loss: 0.176 | Train Acc: 92.69% \t Val. Loss: 0.168 |  Val. Acc: 93.36% \t | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.47s | lr: 2.96e-04 | Val. Loss: 0.162 |  Val. Acc: 93.12% | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.89s | lr: 2.82e-04 | Val. Loss: 0.168 |  Val. Acc: 93.07% | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.24s | lr: 2.68e-04 | Val. Loss: 0.166 |  Val. Acc: 93.31% | B. Val. Loss: 0.156 |  B. Val. Acc: 93.75%\n",
      "Epoch: 013 | ET: 46.74s | \t Train Loss: 0.154 | Train Acc: 93.84% \t Val. Loss: 0.156 |  Val. Acc: 94.04% \t | B. Val. Loss: 0.156 |  B. Val. Acc: 94.04%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.155 |  Val. Acc: 93.70% | B. Val. Loss: 0.155 |  B. Val. Acc: 94.04%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.82s | lr: 2.27e-04 | Val. Loss: 0.162 |  Val. Acc: 93.70% | B. Val. Loss: 0.155 |  B. Val. Acc: 94.04%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.16s | lr: 2.14e-04 | Val. Loss: 0.171 |  Val. Acc: 93.46% | B. Val. Loss: 0.155 |  B. Val. Acc: 94.04%\n",
      "Epoch: 014 | ET: 46.47s | \t Train Loss: 0.169 | Train Acc: 93.18% \t Val. Loss: 0.181 |  Val. Acc: 92.25% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 94.04%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.47s | lr: 1.87e-04 | Val. Loss: 0.151 |  Val. Acc: 94.14% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.98s | lr: 1.74e-04 | Val. Loss: 0.159 |  Val. Acc: 93.31% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.32s | lr: 1.61e-04 | Val. Loss: 0.163 |  Val. Acc: 93.27% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "Epoch: 015 | ET: 46.66s | \t Train Loss: 0.147 | Train Acc: 93.97% \t Val. Loss: 0.161 |  Val. Acc: 93.17% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.47s | lr: 1.36e-04 | Val. Loss: 0.153 |  Val. Acc: 93.70% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.81s | lr: 1.24e-04 | Val. Loss: 0.171 |  Val. Acc: 91.91% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.14s | lr: 1.13e-04 | Val. Loss: 0.164 |  Val. Acc: 93.51% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "Epoch: 016 | ET: 46.44s | \t Train Loss: 0.140 | Train Acc: 94.35% \t Val. Loss: 0.158 |  Val. Acc: 93.56% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.47s | lr: 9.17e-05 | Val. Loss: 0.153 |  Val. Acc: 93.85% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.81s | lr: 8.16e-05 | Val. Loss: 0.157 |  Val. Acc: 93.85% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.16s | lr: 7.21e-05 | Val. Loss: 0.163 |  Val. Acc: 93.85% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "Epoch: 017 | ET: 46.47s | \t Train Loss: 0.128 | Train Acc: 95.15% \t Val. Loss: 0.165 |  Val. Acc: 93.56% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.47s | lr: 5.51e-05 | Val. Loss: 0.159 |  Val. Acc: 92.97% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.81s | lr: 4.74e-05 | Val. Loss: 0.167 |  Val. Acc: 92.49% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.15s | lr: 4.04e-05 | Val. Loss: 0.160 |  Val. Acc: 93.22% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "Epoch: 018 | ET: 46.59s | \t Train Loss: 0.121 | Train Acc: 95.13% \t Val. Loss: 0.156 |  Val. Acc: 93.56% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.47s | lr: 2.86e-05 | Val. Loss: 0.157 |  Val. Acc: 93.60% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.83s | lr: 2.37e-05 | Val. Loss: 0.163 |  Val. Acc: 93.07% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.21s | lr: 1.95e-05 | Val. Loss: 0.164 |  Val. Acc: 92.68% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "Epoch: 019 | ET: 46.64s | \t Train Loss: 0.115 | Train Acc: 95.72% \t Val. Loss: 0.168 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.166 |  Val. Acc: 92.64% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.84s | lr: 1.15e-05 | Val. Loss: 0.167 |  Val. Acc: 92.88% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.20s | lr: 1.04e-05 | Val. Loss: 0.164 |  Val. Acc: 93.17% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "Epoch: 020 | ET: 46.56s | \t Train Loss: 0.111 | Train Acc: 95.87% \t Val. Loss: 0.168 |  Val. Acc: 92.83% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    0    2    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.450 |  Val. Acc: 80.86% | B. Val. Loss: 0.450 |  B. Val. Acc: 80.86%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.92s | lr: 1.07e-04 | Val. Loss: 0.447 |  Val. Acc: 79.12% | B. Val. Loss: 0.447 |  B. Val. Acc: 80.86%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.27s | lr: 1.15e-04 | Val. Loss: 0.493 |  Val. Acc: 76.79% | B. Val. Loss: 0.447 |  B. Val. Acc: 80.86%\n",
      "Epoch: 001 | ET: 46.90s | \t Train Loss: 0.370 | Train Acc: 83.88% \t Val. Loss: 0.357 |  Val. Acc: 84.93% \t | B. Val. Loss: 0.357 |  B. Val. Acc: 84.93%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.369 |  Val. Acc: 82.95% | B. Val. Loss: 0.357 |  B. Val. Acc: 84.93%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 13.83s | lr: 1.59e-04 | Val. Loss: 0.371 |  Val. Acc: 82.61% | B. Val. Loss: 0.357 |  B. Val. Acc: 84.93%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.18s | lr: 1.79e-04 | Val. Loss: 0.291 |  Val. Acc: 87.94% | B. Val. Loss: 0.291 |  B. Val. Acc: 87.94%\n",
      "Epoch: 002 | ET: 46.92s | \t Train Loss: 0.280 | Train Acc: 88.28% \t Val. Loss: 0.262 |  Val. Acc: 89.05% \t | B. Val. Loss: 0.262 |  B. Val. Acc: 89.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.47s | lr: 2.23e-04 | Val. Loss: 0.246 |  Val. Acc: 88.71% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.05%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 13.83s | lr: 2.48e-04 | Val. Loss: 0.297 |  Val. Acc: 88.47% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.05%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.26s | lr: 2.74e-04 | Val. Loss: 0.373 |  Val. Acc: 86.97% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.05%\n",
      "Epoch: 003 | ET: 46.76s | \t Train Loss: 0.255 | Train Acc: 89.91% \t Val. Loss: 0.222 |  Val. Acc: 90.94% \t | B. Val. Loss: 0.222 |  B. Val. Acc: 90.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.205 |  Val. Acc: 91.57% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.57%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.99s | lr: 3.52e-04 | Val. Loss: 0.192 |  Val. Acc: 92.64% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.64%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.54s | lr: 3.77e-04 | Val. Loss: 0.227 |  Val. Acc: 90.60% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.64%\n",
      "Epoch: 004 | ET: 46.87s | \t Train Loss: 0.223 | Train Acc: 90.41% \t Val. Loss: 0.213 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.192 |  B. Val. Acc: 92.64%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.47s | lr: 4.22e-04 | Val. Loss: 0.181 |  Val. Acc: 92.34% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.64%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.82s | lr: 4.42e-04 | Val. Loss: 0.193 |  Val. Acc: 91.67% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.64%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.17s | lr: 4.59e-04 | Val. Loss: 0.176 |  Val. Acc: 92.68% | B. Val. Loss: 0.176 |  B. Val. Acc: 92.68%\n",
      "Epoch: 005 | ET: 46.63s | \t Train Loss: 0.215 | Train Acc: 90.78% \t Val. Loss: 0.202 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.176 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.200 |  Val. Acc: 91.96% | B. Val. Loss: 0.176 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.83s | lr: 4.93e-04 | Val. Loss: 0.200 |  Val. Acc: 91.52% | B. Val. Loss: 0.176 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.18s | lr: 4.98e-04 | Val. Loss: 0.197 |  Val. Acc: 91.57% | B. Val. Loss: 0.176 |  B. Val. Acc: 92.68%\n",
      "Epoch: 006 | ET: 46.49s | \t Train Loss: 0.189 | Train Acc: 91.78% \t Val. Loss: 0.178 |  Val. Acc: 92.34% \t | B. Val. Loss: 0.176 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.47s | lr: 5.00e-04 | Val. Loss: 0.169 |  Val. Acc: 93.02% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.00s | lr: 4.98e-04 | Val. Loss: 0.199 |  Val. Acc: 90.84% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.34s | lr: 4.96e-04 | Val. Loss: 0.187 |  Val. Acc: 92.20% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "Epoch: 007 | ET: 46.62s | \t Train Loss: 0.196 | Train Acc: 91.83% \t Val. Loss: 0.182 |  Val. Acc: 92.64% \t | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.47s | lr: 4.90e-04 | Val. Loss: 0.171 |  Val. Acc: 92.59% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.80s | lr: 4.86e-04 | Val. Loss: 0.208 |  Val. Acc: 91.04% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.14s | lr: 4.81e-04 | Val. Loss: 0.176 |  Val. Acc: 92.49% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "Epoch: 008 | ET: 46.42s | \t Train Loss: 0.183 | Train Acc: 92.10% \t Val. Loss: 0.169 |  Val. Acc: 93.02% \t | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.55s | lr: 4.69e-04 | Val. Loss: 0.171 |  Val. Acc: 92.73% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.90s | lr: 4.62e-04 | Val. Loss: 0.185 |  Val. Acc: 90.94% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.25s | lr: 4.55e-04 | Val. Loss: 0.185 |  Val. Acc: 92.88% | B. Val. Loss: 0.169 |  B. Val. Acc: 93.02%\n",
      "Epoch: 009 | ET: 46.78s | \t Train Loss: 0.184 | Train Acc: 92.27% \t Val. Loss: 0.171 |  Val. Acc: 93.46% \t | B. Val. Loss: 0.169 |  B. Val. Acc: 93.46%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.163 |  Val. Acc: 93.80% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 14.02s | lr: 4.28e-04 | Val. Loss: 0.160 |  Val. Acc: 92.93% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.38s | lr: 4.18e-04 | Val. Loss: 0.167 |  Val. Acc: 93.56% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.80%\n",
      "Epoch: 010 | ET: 46.71s | \t Train Loss: 0.174 | Train Acc: 92.54% \t Val. Loss: 0.166 |  Val. Acc: 93.22% \t | B. Val. Loss: 0.160 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.49s | lr: 3.97e-04 | Val. Loss: 0.165 |  Val. Acc: 93.02% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.85s | lr: 3.85e-04 | Val. Loss: 0.159 |  Val. Acc: 93.12% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.21s | lr: 3.73e-04 | Val. Loss: 0.172 |  Val. Acc: 93.17% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "Epoch: 011 | ET: 46.54s | \t Train Loss: 0.185 | Train Acc: 92.39% \t Val. Loss: 0.170 |  Val. Acc: 92.30% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.165 |  Val. Acc: 93.17% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.83s | lr: 3.36e-04 | Val. Loss: 0.180 |  Val. Acc: 92.97% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.18s | lr: 3.23e-04 | Val. Loss: 0.164 |  Val. Acc: 93.17% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "Epoch: 012 | ET: 46.52s | \t Train Loss: 0.197 | Train Acc: 91.43% \t Val. Loss: 0.192 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.164 |  Val. Acc: 93.17% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.82s | lr: 2.82e-04 | Val. Loss: 0.170 |  Val. Acc: 92.97% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.16s | lr: 2.68e-04 | Val. Loss: 0.163 |  Val. Acc: 93.31% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "Epoch: 013 | ET: 46.51s | \t Train Loss: 0.197 | Train Acc: 91.80% \t Val. Loss: 0.190 |  Val. Acc: 92.39% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.167 |  Val. Acc: 92.97% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.91s | lr: 2.27e-04 | Val. Loss: 0.175 |  Val. Acc: 92.68% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.25s | lr: 2.14e-04 | Val. Loss: 0.169 |  Val. Acc: 92.88% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "Epoch: 014 | ET: 46.57s | \t Train Loss: 0.153 | Train Acc: 93.86% \t Val. Loss: 0.160 |  Val. Acc: 93.46% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.80%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.151 |  Val. Acc: 94.04% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.04%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 14.03s | lr: 1.74e-04 | Val. Loss: 0.154 |  Val. Acc: 93.51% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.04%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.39s | lr: 1.61e-04 | Val. Loss: 0.162 |  Val. Acc: 93.36% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.04%\n",
      "Epoch: 015 | ET: 46.92s | \t Train Loss: 0.145 | Train Acc: 93.84% \t Val. Loss: 0.150 |  Val. Acc: 94.19% \t | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.155 |  Val. Acc: 93.70% | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.84s | lr: 1.24e-04 | Val. Loss: 0.165 |  Val. Acc: 93.07% | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.19s | lr: 1.13e-04 | Val. Loss: 0.164 |  Val. Acc: 93.41% | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "Epoch: 016 | ET: 46.54s | \t Train Loss: 0.134 | Train Acc: 94.64% \t Val. Loss: 0.161 |  Val. Acc: 93.60% \t | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.47s | lr: 9.17e-05 | Val. Loss: 0.164 |  Val. Acc: 93.36% | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.83s | lr: 8.16e-05 | Val. Loss: 0.172 |  Val. Acc: 93.02% | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.18s | lr: 7.21e-05 | Val. Loss: 0.157 |  Val. Acc: 93.27% | B. Val. Loss: 0.150 |  B. Val. Acc: 94.19%\n",
      "Epoch: 017 | ET: 46.52s | \t Train Loss: 0.127 | Train Acc: 94.92% \t Val. Loss: 0.149 |  Val. Acc: 94.19% \t | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.155 |  Val. Acc: 93.51% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.83s | lr: 4.74e-05 | Val. Loss: 0.161 |  Val. Acc: 93.36% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.18s | lr: 4.04e-05 | Val. Loss: 0.159 |  Val. Acc: 93.80% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "Epoch: 018 | ET: 46.53s | \t Train Loss: 0.119 | Train Acc: 95.10% \t Val. Loss: 0.166 |  Val. Acc: 93.17% \t | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.157 |  Val. Acc: 93.60% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.83s | lr: 2.37e-05 | Val. Loss: 0.163 |  Val. Acc: 93.60% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.19s | lr: 1.95e-05 | Val. Loss: 0.159 |  Val. Acc: 93.99% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "Epoch: 019 | ET: 46.57s | \t Train Loss: 0.112 | Train Acc: 95.64% \t Val. Loss: 0.163 |  Val. Acc: 93.36% \t | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.160 |  Val. Acc: 93.70% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.84s | lr: 1.15e-05 | Val. Loss: 0.162 |  Val. Acc: 93.60% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.18s | lr: 1.04e-05 | Val. Loss: 0.165 |  Val. Acc: 93.65% | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "Epoch: 020 | ET: 46.51s | \t Train Loss: 0.107 | Train Acc: 95.81% \t Val. Loss: 0.164 |  Val. Acc: 93.75% \t | B. Val. Loss: 0.149 |  B. Val. Acc: 94.19%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    0    3    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.442 |  Val. Acc: 81.15% | B. Val. Loss: 0.442 |  B. Val. Acc: 81.15%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.92s | lr: 1.07e-04 | Val. Loss: 0.412 |  Val. Acc: 81.54% | B. Val. Loss: 0.412 |  B. Val. Acc: 81.54%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.44s | lr: 1.15e-04 | Val. Loss: 0.378 |  Val. Acc: 83.87% | B. Val. Loss: 0.378 |  B. Val. Acc: 83.87%\n",
      "Epoch: 001 | ET: 47.13s | \t Train Loss: 0.366 | Train Acc: 85.09% \t Val. Loss: 0.361 |  Val. Acc: 85.37% \t | B. Val. Loss: 0.361 |  B. Val. Acc: 85.37%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.47s | lr: 1.41e-04 | Val. Loss: 0.308 |  Val. Acc: 86.77% | B. Val. Loss: 0.308 |  B. Val. Acc: 86.77%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 13.99s | lr: 1.59e-04 | Val. Loss: 0.332 |  Val. Acc: 86.77% | B. Val. Loss: 0.308 |  B. Val. Acc: 86.77%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.34s | lr: 1.79e-04 | Val. Loss: 0.346 |  Val. Acc: 87.02% | B. Val. Loss: 0.308 |  B. Val. Acc: 87.02%\n",
      "Epoch: 002 | ET: 47.02s | \t Train Loss: 0.282 | Train Acc: 88.58% \t Val. Loss: 0.270 |  Val. Acc: 89.58% \t | B. Val. Loss: 0.270 |  B. Val. Acc: 89.58%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.47s | lr: 2.23e-04 | Val. Loss: 0.245 |  Val. Acc: 90.12% | B. Val. Loss: 0.245 |  B. Val. Acc: 90.12%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.03s | lr: 2.48e-04 | Val. Loss: 0.302 |  Val. Acc: 88.86% | B. Val. Loss: 0.245 |  B. Val. Acc: 90.12%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.38s | lr: 2.74e-04 | Val. Loss: 0.286 |  Val. Acc: 88.95% | B. Val. Loss: 0.245 |  B. Val. Acc: 90.12%\n",
      "Epoch: 003 | ET: 46.68s | \t Train Loss: 0.384 | Train Acc: 87.72% \t Val. Loss: 0.363 |  Val. Acc: 88.08% \t | B. Val. Loss: 0.245 |  B. Val. Acc: 90.12%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.237 |  Val. Acc: 89.53% | B. Val. Loss: 0.237 |  B. Val. Acc: 90.12%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.82s | lr: 3.52e-04 | Val. Loss: 0.254 |  Val. Acc: 90.79% | B. Val. Loss: 0.237 |  B. Val. Acc: 90.79%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.49s | lr: 3.77e-04 | Val. Loss: 0.219 |  Val. Acc: 90.12% | B. Val. Loss: 0.219 |  B. Val. Acc: 90.79%\n",
      "Epoch: 004 | ET: 47.01s | \t Train Loss: 0.232 | Train Acc: 90.80% \t Val. Loss: 0.213 |  Val. Acc: 91.76% \t | B. Val. Loss: 0.213 |  B. Val. Acc: 91.76%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.47s | lr: 4.22e-04 | Val. Loss: 0.209 |  Val. Acc: 90.89% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.81s | lr: 4.42e-04 | Val. Loss: 0.215 |  Val. Acc: 92.54% | B. Val. Loss: 0.209 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.36s | lr: 4.59e-04 | Val. Loss: 0.186 |  Val. Acc: 92.15% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.54%\n",
      "Epoch: 005 | ET: 46.70s | \t Train Loss: 0.252 | Train Acc: 89.14% \t Val. Loss: 0.231 |  Val. Acc: 90.02% \t | B. Val. Loss: 0.186 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.175 |  Val. Acc: 92.59% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.59%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.00s | lr: 4.93e-04 | Val. Loss: 0.189 |  Val. Acc: 92.83% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.83%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.56s | lr: 4.98e-04 | Val. Loss: 0.201 |  Val. Acc: 92.39% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.83%\n",
      "Epoch: 006 | ET: 46.88s | \t Train Loss: 0.216 | Train Acc: 91.21% \t Val. Loss: 0.201 |  Val. Acc: 91.67% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.83%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.181 |  Val. Acc: 92.88% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.88%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.02s | lr: 4.98e-04 | Val. Loss: 0.165 |  Val. Acc: 93.31% | B. Val. Loss: 0.165 |  B. Val. Acc: 93.31%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.57s | lr: 4.96e-04 | Val. Loss: 0.172 |  Val. Acc: 92.54% | B. Val. Loss: 0.165 |  B. Val. Acc: 93.31%\n",
      "Epoch: 007 | ET: 46.87s | \t Train Loss: 0.207 | Train Acc: 91.94% \t Val. Loss: 0.199 |  Val. Acc: 92.83% \t | B. Val. Loss: 0.165 |  B. Val. Acc: 93.31%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.47s | lr: 4.90e-04 | Val. Loss: 0.164 |  Val. Acc: 93.36% | B. Val. Loss: 0.164 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.01s | lr: 4.86e-04 | Val. Loss: 0.187 |  Val. Acc: 92.59% | B. Val. Loss: 0.164 |  B. Val. Acc: 93.36%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.37s | lr: 4.81e-04 | Val. Loss: 0.368 |  Val. Acc: 86.72% | B. Val. Loss: 0.164 |  B. Val. Acc: 93.36%\n",
      "Epoch: 008 | ET: 46.66s | \t Train Loss: 0.201 | Train Acc: 91.18% \t Val. Loss: 0.172 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.164 |  B. Val. Acc: 93.36%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.47s | lr: 4.69e-04 | Val. Loss: 0.160 |  Val. Acc: 93.75% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 14.02s | lr: 4.62e-04 | Val. Loss: 0.189 |  Val. Acc: 92.49% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.37s | lr: 4.55e-04 | Val. Loss: 0.187 |  Val. Acc: 93.22% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "Epoch: 009 | ET: 46.76s | \t Train Loss: 0.195 | Train Acc: 91.60% \t Val. Loss: 0.185 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.47s | lr: 4.38e-04 | Val. Loss: 0.167 |  Val. Acc: 93.07% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.82s | lr: 4.28e-04 | Val. Loss: 0.179 |  Val. Acc: 92.49% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.17s | lr: 4.18e-04 | Val. Loss: 0.325 |  Val. Acc: 89.68% | B. Val. Loss: 0.160 |  B. Val. Acc: 93.75%\n",
      "Epoch: 010 | ET: 46.48s | \t Train Loss: 0.173 | Train Acc: 92.30% \t Val. Loss: 0.157 |  Val. Acc: 93.12% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.48s | lr: 3.97e-04 | Val. Loss: 0.159 |  Val. Acc: 93.46% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.84s | lr: 3.85e-04 | Val. Loss: 0.163 |  Val. Acc: 93.56% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.19s | lr: 3.73e-04 | Val. Loss: 0.161 |  Val. Acc: 93.51% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "Epoch: 011 | ET: 46.55s | \t Train Loss: 0.265 | Train Acc: 90.69% \t Val. Loss: 0.245 |  Val. Acc: 91.33% \t | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.158 |  Val. Acc: 93.17% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.83s | lr: 3.36e-04 | Val. Loss: 0.169 |  Val. Acc: 92.54% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.20s | lr: 3.23e-04 | Val. Loss: 0.160 |  Val. Acc: 93.36% | B. Val. Loss: 0.157 |  B. Val. Acc: 93.75%\n",
      "Epoch: 012 | ET: 46.74s | \t Train Loss: 0.160 | Train Acc: 93.00% \t Val. Loss: 0.151 |  Val. Acc: 94.23% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.47s | lr: 2.96e-04 | Val. Loss: 0.153 |  Val. Acc: 93.65% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.83s | lr: 2.82e-04 | Val. Loss: 0.190 |  Val. Acc: 91.72% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.18s | lr: 2.68e-04 | Val. Loss: 0.165 |  Val. Acc: 93.90% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "Epoch: 013 | ET: 46.45s | \t Train Loss: 0.160 | Train Acc: 93.18% \t Val. Loss: 0.161 |  Val. Acc: 93.41% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.157 |  Val. Acc: 93.46% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.82s | lr: 2.27e-04 | Val. Loss: 0.167 |  Val. Acc: 93.75% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.16s | lr: 2.14e-04 | Val. Loss: 0.161 |  Val. Acc: 93.75% | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "Epoch: 014 | ET: 46.46s | \t Train Loss: 0.152 | Train Acc: 93.72% \t Val. Loss: 0.152 |  Val. Acc: 93.94% \t | B. Val. Loss: 0.151 |  B. Val. Acc: 94.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.47s | lr: 1.87e-04 | Val. Loss: 0.147 |  Val. Acc: 94.33% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 14.02s | lr: 1.74e-04 | Val. Loss: 0.172 |  Val. Acc: 92.30% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.46s | lr: 1.61e-04 | Val. Loss: 0.158 |  Val. Acc: 93.46% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "Epoch: 015 | ET: 46.76s | \t Train Loss: 0.169 | Train Acc: 93.03% \t Val. Loss: 0.174 |  Val. Acc: 93.60% \t | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.152 |  Val. Acc: 93.75% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.82s | lr: 1.24e-04 | Val. Loss: 0.165 |  Val. Acc: 93.46% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.19s | lr: 1.13e-04 | Val. Loss: 0.150 |  Val. Acc: 93.85% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "Epoch: 016 | ET: 46.50s | \t Train Loss: 0.135 | Train Acc: 94.18% \t Val. Loss: 0.150 |  Val. Acc: 94.33% \t | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.47s | lr: 9.17e-05 | Val. Loss: 0.147 |  Val. Acc: 94.23% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.83s | lr: 8.16e-05 | Val. Loss: 0.148 |  Val. Acc: 94.23% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.18s | lr: 7.21e-05 | Val. Loss: 0.156 |  Val. Acc: 92.88% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "Epoch: 017 | ET: 46.50s | \t Train Loss: 0.125 | Train Acc: 95.10% \t Val. Loss: 0.152 |  Val. Acc: 93.51% \t | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.47s | lr: 5.51e-05 | Val. Loss: 0.149 |  Val. Acc: 93.90% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.82s | lr: 4.74e-05 | Val. Loss: 0.158 |  Val. Acc: 93.56% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.18s | lr: 4.04e-05 | Val. Loss: 0.152 |  Val. Acc: 94.09% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "Epoch: 018 | ET: 46.50s | \t Train Loss: 0.112 | Train Acc: 95.63% \t Val. Loss: 0.150 |  Val. Acc: 94.14% \t | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.47s | lr: 2.86e-05 | Val. Loss: 0.153 |  Val. Acc: 93.41% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.83s | lr: 2.37e-05 | Val. Loss: 0.155 |  Val. Acc: 94.04% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.20s | lr: 1.95e-05 | Val. Loss: 0.155 |  Val. Acc: 94.19% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "Epoch: 019 | ET: 46.54s | \t Train Loss: 0.105 | Train Acc: 96.10% \t Val. Loss: 0.156 |  Val. Acc: 93.80% \t | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.47s | lr: 1.34e-05 | Val. Loss: 0.158 |  Val. Acc: 93.17% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.83s | lr: 1.15e-05 | Val. Loss: 0.153 |  Val. Acc: 93.94% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.19s | lr: 1.04e-05 | Val. Loss: 0.154 |  Val. Acc: 93.70% | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "Epoch: 020 | ET: 46.53s | \t Train Loss: 0.105 | Train Acc: 95.81% \t Val. Loss: 0.153 |  Val. Acc: 93.80% \t | B. Val. Loss: 0.147 |  B. Val. Acc: 94.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    0    4    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.56s | lr: 1.02e-04 | Val. Loss: 0.436 |  Val. Acc: 80.77% | B. Val. Loss: 0.436 |  B. Val. Acc: 80.77%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 14.00s | lr: 1.07e-04 | Val. Loss: 0.420 |  Val. Acc: 79.60% | B. Val. Loss: 0.420 |  B. Val. Acc: 80.77%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.35s | lr: 1.15e-04 | Val. Loss: 0.400 |  Val. Acc: 82.56% | B. Val. Loss: 0.400 |  B. Val. Acc: 82.56%\n",
      "Epoch: 001 | ET: 47.07s | \t Train Loss: 0.325 | Train Acc: 86.10% \t Val. Loss: 0.295 |  Val. Acc: 88.03% \t | B. Val. Loss: 0.295 |  B. Val. Acc: 88.03%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.273 |  Val. Acc: 89.53% | B. Val. Loss: 0.273 |  B. Val. Acc: 89.53%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.02s | lr: 1.59e-04 | Val. Loss: 0.291 |  Val. Acc: 88.13% | B. Val. Loss: 0.273 |  B. Val. Acc: 89.53%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.36s | lr: 1.79e-04 | Val. Loss: 0.254 |  Val. Acc: 89.53% | B. Val. Loss: 0.254 |  B. Val. Acc: 89.53%\n",
      "Epoch: 002 | ET: 46.80s | \t Train Loss: 0.263 | Train Acc: 89.17% \t Val. Loss: 0.252 |  Val. Acc: 90.46% \t | B. Val. Loss: 0.252 |  B. Val. Acc: 90.46%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.228 |  Val. Acc: 91.04% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.04%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.02s | lr: 2.48e-04 | Val. Loss: 0.234 |  Val. Acc: 90.41% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.04%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.39s | lr: 2.74e-04 | Val. Loss: 0.217 |  Val. Acc: 91.04% | B. Val. Loss: 0.217 |  B. Val. Acc: 91.04%\n",
      "Epoch: 003 | ET: 46.70s | \t Train Loss: 0.298 | Train Acc: 85.81% \t Val. Loss: 0.286 |  Val. Acc: 86.92% \t | B. Val. Loss: 0.217 |  B. Val. Acc: 91.04%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.219 |  Val. Acc: 91.13% | B. Val. Loss: 0.217 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.98s | lr: 3.52e-04 | Val. Loss: 0.233 |  Val. Acc: 91.38% | B. Val. Loss: 0.217 |  B. Val. Acc: 91.38%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.49s | lr: 3.77e-04 | Val. Loss: 0.401 |  Val. Acc: 79.51% | B. Val. Loss: 0.217 |  B. Val. Acc: 91.38%\n",
      "Epoch: 004 | ET: 46.99s | \t Train Loss: 0.220 | Train Acc: 90.52% \t Val. Loss: 0.209 |  Val. Acc: 91.86% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.86%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.47s | lr: 4.22e-04 | Val. Loss: 0.179 |  Val. Acc: 92.68% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.00s | lr: 4.42e-04 | Val. Loss: 0.179 |  Val. Acc: 92.88% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.88%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.55s | lr: 4.59e-04 | Val. Loss: 0.200 |  Val. Acc: 90.55% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.88%\n",
      "Epoch: 005 | ET: 46.96s | \t Train Loss: 0.217 | Train Acc: 91.02% \t Val. Loss: 0.208 |  Val. Acc: 92.49% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 92.88%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.47s | lr: 4.85e-04 | Val. Loss: 0.177 |  Val. Acc: 92.30% | B. Val. Loss: 0.177 |  B. Val. Acc: 92.88%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.82s | lr: 4.93e-04 | Val. Loss: 0.247 |  Val. Acc: 89.58% | B. Val. Loss: 0.177 |  B. Val. Acc: 92.88%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.17s | lr: 4.98e-04 | Val. Loss: 0.182 |  Val. Acc: 91.62% | B. Val. Loss: 0.177 |  B. Val. Acc: 92.88%\n",
      "Epoch: 006 | ET: 46.49s | \t Train Loss: 0.205 | Train Acc: 91.76% \t Val. Loss: 0.194 |  Val. Acc: 92.44% \t | B. Val. Loss: 0.177 |  B. Val. Acc: 92.88%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.166 |  Val. Acc: 93.07% | B. Val. Loss: 0.166 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.04s | lr: 4.98e-04 | Val. Loss: 0.241 |  Val. Acc: 89.44% | B. Val. Loss: 0.166 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.38s | lr: 4.96e-04 | Val. Loss: 0.224 |  Val. Acc: 92.30% | B. Val. Loss: 0.166 |  B. Val. Acc: 93.07%\n",
      "Epoch: 007 | ET: 46.71s | \t Train Loss: 0.208 | Train Acc: 91.25% \t Val. Loss: 0.197 |  Val. Acc: 92.01% \t | B. Val. Loss: 0.166 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.164 |  Val. Acc: 93.27% | B. Val. Loss: 0.164 |  B. Val. Acc: 93.27%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.00s | lr: 4.86e-04 | Val. Loss: 0.171 |  Val. Acc: 92.49% | B. Val. Loss: 0.164 |  B. Val. Acc: 93.27%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.36s | lr: 4.81e-04 | Val. Loss: 0.167 |  Val. Acc: 93.17% | B. Val. Loss: 0.164 |  B. Val. Acc: 93.27%\n",
      "Epoch: 008 | ET: 46.69s | \t Train Loss: 0.181 | Train Acc: 92.07% \t Val. Loss: 0.166 |  Val. Acc: 92.97% \t | B. Val. Loss: 0.164 |  B. Val. Acc: 93.27%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.47s | lr: 4.69e-04 | Val. Loss: 0.163 |  Val. Acc: 93.07% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.27%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.82s | lr: 4.62e-04 | Val. Loss: 0.227 |  Val. Acc: 91.47% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.27%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.16s | lr: 4.55e-04 | Val. Loss: 0.187 |  Val. Acc: 92.20% | B. Val. Loss: 0.163 |  B. Val. Acc: 93.27%\n",
      "Epoch: 009 | ET: 46.68s | \t Train Loss: 0.175 | Train Acc: 92.49% \t Val. Loss: 0.161 |  Val. Acc: 93.46% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.46%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.167 |  Val. Acc: 92.44% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.46%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.87s | lr: 4.28e-04 | Val. Loss: 0.168 |  Val. Acc: 92.54% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.46%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.24s | lr: 4.18e-04 | Val. Loss: 0.186 |  Val. Acc: 91.47% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.46%\n",
      "Epoch: 010 | ET: 46.62s | \t Train Loss: 0.173 | Train Acc: 92.40% \t Val. Loss: 0.164 |  Val. Acc: 93.46% \t | B. Val. Loss: 0.161 |  B. Val. Acc: 93.46%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.56s | lr: 3.97e-04 | Val. Loss: 0.161 |  Val. Acc: 93.56% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.10s | lr: 3.85e-04 | Val. Loss: 0.178 |  Val. Acc: 92.54% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.45s | lr: 3.73e-04 | Val. Loss: 0.175 |  Val. Acc: 92.78% | B. Val. Loss: 0.161 |  B. Val. Acc: 93.56%\n",
      "Epoch: 011 | ET: 46.79s | \t Train Loss: 0.163 | Train Acc: 92.96% \t Val. Loss: 0.159 |  Val. Acc: 93.02% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.163 |  Val. Acc: 93.31% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.84s | lr: 3.36e-04 | Val. Loss: 0.169 |  Val. Acc: 92.25% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.19s | lr: 3.23e-04 | Val. Loss: 0.190 |  Val. Acc: 92.54% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "Epoch: 012 | ET: 46.54s | \t Train Loss: 0.205 | Train Acc: 91.97% \t Val. Loss: 0.198 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.206 |  Val. Acc: 90.41% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.83s | lr: 2.82e-04 | Val. Loss: 0.162 |  Val. Acc: 93.46% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.20s | lr: 2.68e-04 | Val. Loss: 0.167 |  Val. Acc: 93.36% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "Epoch: 013 | ET: 46.53s | \t Train Loss: 0.168 | Train Acc: 93.44% \t Val. Loss: 0.182 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.164 |  Val. Acc: 93.02% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.82s | lr: 2.27e-04 | Val. Loss: 0.178 |  Val. Acc: 93.36% | B. Val. Loss: 0.159 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.17s | lr: 2.14e-04 | Val. Loss: 0.155 |  Val. Acc: 93.02% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.56%\n",
      "Epoch: 014 | ET: 46.52s | \t Train Loss: 0.148 | Train Acc: 93.71% \t Val. Loss: 0.161 |  Val. Acc: 93.36% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.56%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.171 |  Val. Acc: 92.68% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.56%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.84s | lr: 1.74e-04 | Val. Loss: 0.158 |  Val. Acc: 93.65% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.65%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.39s | lr: 1.61e-04 | Val. Loss: 0.162 |  Val. Acc: 93.85% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.85%\n",
      "Epoch: 015 | ET: 46.92s | \t Train Loss: 0.147 | Train Acc: 93.82% \t Val. Loss: 0.165 |  Val. Acc: 93.02% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.85%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.156 |  Val. Acc: 93.90% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 14.00s | lr: 1.24e-04 | Val. Loss: 0.164 |  Val. Acc: 93.60% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.44s | lr: 1.13e-04 | Val. Loss: 0.165 |  Val. Acc: 93.41% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "Epoch: 016 | ET: 46.77s | \t Train Loss: 0.155 | Train Acc: 93.76% \t Val. Loss: 0.196 |  Val. Acc: 91.67% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.48s | lr: 9.17e-05 | Val. Loss: 0.165 |  Val. Acc: 93.12% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.84s | lr: 8.16e-05 | Val. Loss: 0.186 |  Val. Acc: 92.30% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.19s | lr: 7.21e-05 | Val. Loss: 0.169 |  Val. Acc: 92.93% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "Epoch: 017 | ET: 46.53s | \t Train Loss: 0.135 | Train Acc: 94.23% \t Val. Loss: 0.163 |  Val. Acc: 93.65% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.166 |  Val. Acc: 93.36% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.84s | lr: 4.74e-05 | Val. Loss: 0.181 |  Val. Acc: 92.78% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.20s | lr: 4.04e-05 | Val. Loss: 0.170 |  Val. Acc: 92.73% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "Epoch: 018 | ET: 46.57s | \t Train Loss: 0.113 | Train Acc: 95.63% \t Val. Loss: 0.178 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.171 |  Val. Acc: 93.12% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.84s | lr: 2.37e-05 | Val. Loss: 0.175 |  Val. Acc: 93.02% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.22s | lr: 1.95e-05 | Val. Loss: 0.187 |  Val. Acc: 92.05% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "Epoch: 019 | ET: 46.56s | \t Train Loss: 0.104 | Train Acc: 95.81% \t Val. Loss: 0.177 |  Val. Acc: 92.93% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.171 |  Val. Acc: 93.02% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.83s | lr: 1.15e-05 | Val. Loss: 0.174 |  Val. Acc: 93.22% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.19s | lr: 1.04e-05 | Val. Loss: 0.173 |  Val. Acc: 93.31% | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "Epoch: 020 | ET: 46.51s | \t Train Loss: 0.099 | Train Acc: 96.24% \t Val. Loss: 0.174 |  Val. Acc: 93.07% \t | B. Val. Loss: 0.155 |  B. Val. Acc: 93.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    1    0    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.406 |  Val. Acc: 82.02% | B. Val. Loss: 0.406 |  B. Val. Acc: 82.02%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 14.03s | lr: 1.07e-04 | Val. Loss: 0.412 |  Val. Acc: 81.00% | B. Val. Loss: 0.406 |  B. Val. Acc: 82.02%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.48s | lr: 1.15e-04 | Val. Loss: 0.365 |  Val. Acc: 84.00% | B. Val. Loss: 0.365 |  B. Val. Acc: 84.00%\n",
      "Epoch: 001 | ET: 47.47s | \t Train Loss: 0.351 | Train Acc: 84.64% \t Val. Loss: 0.341 |  Val. Acc: 84.83% \t | B. Val. Loss: 0.341 |  B. Val. Acc: 84.83%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.305 |  Val. Acc: 87.30% | B. Val. Loss: 0.305 |  B. Val. Acc: 87.30%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.05s | lr: 1.59e-04 | Val. Loss: 0.310 |  Val. Acc: 86.04% | B. Val. Loss: 0.305 |  B. Val. Acc: 87.30%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.40s | lr: 1.79e-04 | Val. Loss: 0.283 |  Val. Acc: 88.41% | B. Val. Loss: 0.283 |  B. Val. Acc: 88.41%\n",
      "Epoch: 002 | ET: 47.12s | \t Train Loss: 0.279 | Train Acc: 88.85% \t Val. Loss: 0.256 |  Val. Acc: 88.90% \t | B. Val. Loss: 0.256 |  B. Val. Acc: 88.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.270 |  Val. Acc: 89.00% | B. Val. Loss: 0.256 |  B. Val. Acc: 89.00%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.02s | lr: 2.48e-04 | Val. Loss: 0.254 |  Val. Acc: 89.19% | B. Val. Loss: 0.254 |  B. Val. Acc: 89.19%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.57s | lr: 2.74e-04 | Val. Loss: 0.246 |  Val. Acc: 89.82% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.82%\n",
      "Epoch: 003 | ET: 47.09s | \t Train Loss: 0.300 | Train Acc: 87.64% \t Val. Loss: 0.300 |  Val. Acc: 87.93% \t | B. Val. Loss: 0.246 |  B. Val. Acc: 89.82%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.244 |  Val. Acc: 90.16% | B. Val. Loss: 0.244 |  B. Val. Acc: 90.16%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.02s | lr: 3.52e-04 | Val. Loss: 0.228 |  Val. Acc: 90.26% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.26%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.57s | lr: 3.77e-04 | Val. Loss: 0.235 |  Val. Acc: 90.31% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.31%\n",
      "Epoch: 004 | ET: 47.28s | \t Train Loss: 0.241 | Train Acc: 90.96% \t Val. Loss: 0.232 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 91.47%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.48s | lr: 4.22e-04 | Val. Loss: 0.209 |  Val. Acc: 91.03% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.84s | lr: 4.42e-04 | Val. Loss: 0.249 |  Val. Acc: 90.31% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.27s | lr: 4.59e-04 | Val. Loss: 0.239 |  Val. Acc: 90.45% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "Epoch: 005 | ET: 46.58s | \t Train Loss: 0.224 | Train Acc: 90.54% \t Val. Loss: 0.228 |  Val. Acc: 90.16% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.218 |  Val. Acc: 91.18% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.83s | lr: 4.93e-04 | Val. Loss: 0.242 |  Val. Acc: 89.92% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.17s | lr: 4.98e-04 | Val. Loss: 0.214 |  Val. Acc: 90.89% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "Epoch: 006 | ET: 46.46s | \t Train Loss: 0.240 | Train Acc: 90.31% \t Val. Loss: 0.231 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.47%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.47s | lr: 5.00e-04 | Val. Loss: 0.227 |  Val. Acc: 91.81% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.01s | lr: 4.98e-04 | Val. Loss: 0.212 |  Val. Acc: 91.37% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.34s | lr: 4.96e-04 | Val. Loss: 0.304 |  Val. Acc: 86.48% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.81%\n",
      "Epoch: 007 | ET: 46.85s | \t Train Loss: 0.200 | Train Acc: 91.51% \t Val. Loss: 0.200 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.200 |  B. Val. Acc: 91.95%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.47s | lr: 4.90e-04 | Val. Loss: 0.223 |  Val. Acc: 91.32% | B. Val. Loss: 0.200 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.81s | lr: 4.86e-04 | Val. Loss: 0.252 |  Val. Acc: 90.55% | B. Val. Loss: 0.200 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.17s | lr: 4.81e-04 | Val. Loss: 0.193 |  Val. Acc: 92.20% | B. Val. Loss: 0.193 |  B. Val. Acc: 92.20%\n",
      "Epoch: 008 | ET: 46.68s | \t Train Loss: 0.195 | Train Acc: 91.29% \t Val. Loss: 0.200 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.193 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.48s | lr: 4.69e-04 | Val. Loss: 0.196 |  Val. Acc: 92.15% | B. Val. Loss: 0.193 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.82s | lr: 4.62e-04 | Val. Loss: 0.190 |  Val. Acc: 92.15% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.17s | lr: 4.55e-04 | Val. Loss: 0.276 |  Val. Acc: 89.24% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "Epoch: 009 | ET: 46.45s | \t Train Loss: 0.194 | Train Acc: 91.88% \t Val. Loss: 0.199 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.47s | lr: 4.38e-04 | Val. Loss: 0.195 |  Val. Acc: 92.00% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.80s | lr: 4.28e-04 | Val. Loss: 0.189 |  Val. Acc: 91.95% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.17s | lr: 4.18e-04 | Val. Loss: 0.179 |  Val. Acc: 92.68% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.68%\n",
      "Epoch: 010 | ET: 46.79s | \t Train Loss: 0.195 | Train Acc: 91.86% \t Val. Loss: 0.209 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.48s | lr: 3.97e-04 | Val. Loss: 0.183 |  Val. Acc: 92.87% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.06s | lr: 3.85e-04 | Val. Loss: 0.245 |  Val. Acc: 90.50% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.41s | lr: 3.73e-04 | Val. Loss: 0.191 |  Val. Acc: 92.68% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "Epoch: 011 | ET: 46.75s | \t Train Loss: 0.218 | Train Acc: 91.66% \t Val. Loss: 0.227 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.191 |  Val. Acc: 91.86% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.81s | lr: 3.36e-04 | Val. Loss: 0.191 |  Val. Acc: 92.24% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.15s | lr: 3.23e-04 | Val. Loss: 0.207 |  Val. Acc: 92.34% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "Epoch: 012 | ET: 46.44s | \t Train Loss: 0.171 | Train Acc: 92.66% \t Val. Loss: 0.191 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.181 |  Val. Acc: 92.68% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.83s | lr: 2.82e-04 | Val. Loss: 0.227 |  Val. Acc: 91.27% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.17s | lr: 2.68e-04 | Val. Loss: 0.191 |  Val. Acc: 92.34% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "Epoch: 013 | ET: 46.48s | \t Train Loss: 0.196 | Train Acc: 91.89% \t Val. Loss: 0.226 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.205 |  Val. Acc: 91.76% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.82s | lr: 2.27e-04 | Val. Loss: 0.185 |  Val. Acc: 92.73% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.16s | lr: 2.14e-04 | Val. Loss: 0.190 |  Val. Acc: 92.39% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "Epoch: 014 | ET: 46.49s | \t Train Loss: 0.150 | Train Acc: 93.77% \t Val. Loss: 0.182 |  Val. Acc: 92.68% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.184 |  Val. Acc: 92.34% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.82s | lr: 1.74e-04 | Val. Loss: 0.199 |  Val. Acc: 91.71% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.17s | lr: 1.61e-04 | Val. Loss: 0.185 |  Val. Acc: 92.78% | B. Val. Loss: 0.179 |  B. Val. Acc: 92.87%\n",
      "Epoch: 015 | ET: 46.70s | \t Train Loss: 0.145 | Train Acc: 93.93% \t Val. Loss: 0.191 |  Val. Acc: 93.02% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.188 |  Val. Acc: 92.29% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.83s | lr: 1.24e-04 | Val. Loss: 0.198 |  Val. Acc: 92.05% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.24s | lr: 1.13e-04 | Val. Loss: 0.191 |  Val. Acc: 91.71% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "Epoch: 016 | ET: 46.54s | \t Train Loss: 0.131 | Train Acc: 94.86% \t Val. Loss: 0.181 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.48s | lr: 9.17e-05 | Val. Loss: 0.194 |  Val. Acc: 92.34% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.82s | lr: 8.16e-05 | Val. Loss: 0.193 |  Val. Acc: 92.24% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.17s | lr: 7.21e-05 | Val. Loss: 0.228 |  Val. Acc: 90.64% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "Epoch: 017 | ET: 46.48s | \t Train Loss: 0.121 | Train Acc: 94.91% \t Val. Loss: 0.194 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.47s | lr: 5.51e-05 | Val. Loss: 0.196 |  Val. Acc: 92.34% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.84s | lr: 4.74e-05 | Val. Loss: 0.208 |  Val. Acc: 92.34% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.19s | lr: 4.04e-05 | Val. Loss: 0.199 |  Val. Acc: 92.10% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "Epoch: 018 | ET: 46.51s | \t Train Loss: 0.106 | Train Acc: 95.87% \t Val. Loss: 0.201 |  Val. Acc: 92.29% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.205 |  Val. Acc: 92.24% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.83s | lr: 2.37e-05 | Val. Loss: 0.207 |  Val. Acc: 91.95% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.18s | lr: 1.95e-05 | Val. Loss: 0.210 |  Val. Acc: 92.39% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "Epoch: 019 | ET: 46.52s | \t Train Loss: 0.118 | Train Acc: 95.12% \t Val. Loss: 0.221 |  Val. Acc: 91.03% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.207 |  Val. Acc: 92.00% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.82s | lr: 1.15e-05 | Val. Loss: 0.217 |  Val. Acc: 92.44% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.17s | lr: 1.04e-05 | Val. Loss: 0.215 |  Val. Acc: 92.39% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "Epoch: 020 | ET: 46.51s | \t Train Loss: 0.097 | Train Acc: 96.33% \t Val. Loss: 0.212 |  Val. Acc: 92.34% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.02%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    1    1    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.414 |  Val. Acc: 81.05% | B. Val. Loss: 0.414 |  B. Val. Acc: 81.05%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.93s | lr: 1.07e-04 | Val. Loss: 0.431 |  Val. Acc: 81.10% | B. Val. Loss: 0.414 |  B. Val. Acc: 81.10%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.55s | lr: 1.15e-04 | Val. Loss: 0.341 |  Val. Acc: 85.22% | B. Val. Loss: 0.341 |  B. Val. Acc: 85.22%\n",
      "Epoch: 001 | ET: 47.12s | \t Train Loss: 0.436 | Train Acc: 78.80% \t Val. Loss: 0.385 |  Val. Acc: 81.82% \t | B. Val. Loss: 0.341 |  B. Val. Acc: 85.22%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.313 |  Val. Acc: 86.28% | B. Val. Loss: 0.313 |  B. Val. Acc: 86.28%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.04s | lr: 1.59e-04 | Val. Loss: 0.300 |  Val. Acc: 87.11% | B. Val. Loss: 0.300 |  B. Val. Acc: 87.11%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.60s | lr: 1.79e-04 | Val. Loss: 0.428 |  Val. Acc: 81.39% | B. Val. Loss: 0.300 |  B. Val. Acc: 87.11%\n",
      "Epoch: 002 | ET: 46.92s | \t Train Loss: 0.355 | Train Acc: 83.48% \t Val. Loss: 0.310 |  Val. Acc: 86.96% \t | B. Val. Loss: 0.300 |  B. Val. Acc: 87.11%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.50s | lr: 2.23e-04 | Val. Loss: 0.327 |  Val. Acc: 85.41% | B. Val. Loss: 0.300 |  B. Val. Acc: 87.11%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 13.87s | lr: 2.48e-04 | Val. Loss: 0.345 |  Val. Acc: 83.57% | B. Val. Loss: 0.300 |  B. Val. Acc: 87.11%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.24s | lr: 2.74e-04 | Val. Loss: 0.348 |  Val. Acc: 82.65% | B. Val. Loss: 0.300 |  B. Val. Acc: 87.11%\n",
      "Epoch: 003 | ET: 46.72s | \t Train Loss: 0.245 | Train Acc: 89.74% \t Val. Loss: 0.251 |  Val. Acc: 89.24% \t | B. Val. Loss: 0.251 |  B. Val. Acc: 89.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.234 |  Val. Acc: 89.24% | B. Val. Loss: 0.234 |  B. Val. Acc: 89.24%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.81s | lr: 3.52e-04 | Val. Loss: 0.273 |  Val. Acc: 88.90% | B. Val. Loss: 0.234 |  B. Val. Acc: 89.24%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.15s | lr: 3.77e-04 | Val. Loss: 0.249 |  Val. Acc: 89.72% | B. Val. Loss: 0.234 |  B. Val. Acc: 89.72%\n",
      "Epoch: 004 | ET: 46.81s | \t Train Loss: 0.226 | Train Acc: 90.85% \t Val. Loss: 0.228 |  Val. Acc: 90.69% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 90.69%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.47s | lr: 4.22e-04 | Val. Loss: 0.221 |  Val. Acc: 91.32% | B. Val. Loss: 0.221 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.00s | lr: 4.42e-04 | Val. Loss: 0.234 |  Val. Acc: 90.50% | B. Val. Loss: 0.221 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.35s | lr: 4.59e-04 | Val. Loss: 0.237 |  Val. Acc: 89.97% | B. Val. Loss: 0.221 |  B. Val. Acc: 91.32%\n",
      "Epoch: 005 | ET: 46.65s | \t Train Loss: 0.214 | Train Acc: 91.38% \t Val. Loss: 0.224 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.221 |  B. Val. Acc: 91.32%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.213 |  Val. Acc: 91.13% | B. Val. Loss: 0.213 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.91s | lr: 4.93e-04 | Val. Loss: 0.219 |  Val. Acc: 90.45% | B. Val. Loss: 0.213 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.26s | lr: 4.98e-04 | Val. Loss: 0.206 |  Val. Acc: 91.13% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.32%\n",
      "Epoch: 006 | ET: 46.57s | \t Train Loss: 0.206 | Train Acc: 91.22% \t Val. Loss: 0.212 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.206 |  B. Val. Acc: 91.32%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.225 |  Val. Acc: 90.79% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.85s | lr: 4.98e-04 | Val. Loss: 0.214 |  Val. Acc: 91.42% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.38s | lr: 4.96e-04 | Val. Loss: 0.194 |  Val. Acc: 92.10% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "Epoch: 007 | ET: 46.87s | \t Train Loss: 0.222 | Train Acc: 91.19% \t Val. Loss: 0.231 |  Val. Acc: 90.89% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.202 |  Val. Acc: 91.81% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.83s | lr: 4.86e-04 | Val. Loss: 0.217 |  Val. Acc: 91.18% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.18s | lr: 4.81e-04 | Val. Loss: 0.214 |  Val. Acc: 90.84% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "Epoch: 008 | ET: 46.49s | \t Train Loss: 0.207 | Train Acc: 91.22% \t Val. Loss: 0.210 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.48s | lr: 4.69e-04 | Val. Loss: 0.203 |  Val. Acc: 91.47% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.82s | lr: 4.62e-04 | Val. Loss: 0.277 |  Val. Acc: 91.42% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.17s | lr: 4.55e-04 | Val. Loss: 0.196 |  Val. Acc: 92.58% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.58%\n",
      "Epoch: 009 | ET: 46.63s | \t Train Loss: 0.174 | Train Acc: 92.29% \t Val. Loss: 0.189 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.189 |  B. Val. Acc: 92.58%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.189 |  Val. Acc: 91.57% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.58%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.84s | lr: 4.28e-04 | Val. Loss: 0.186 |  Val. Acc: 92.44% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.58%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.18s | lr: 4.18e-04 | Val. Loss: 0.207 |  Val. Acc: 92.44% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.58%\n",
      "Epoch: 010 | ET: 46.50s | \t Train Loss: 0.184 | Train Acc: 92.37% \t Val. Loss: 0.193 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.186 |  B. Val. Acc: 92.58%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.48s | lr: 3.97e-04 | Val. Loss: 0.185 |  Val. Acc: 92.92% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.92%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.05s | lr: 3.85e-04 | Val. Loss: 0.186 |  Val. Acc: 92.15% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.92%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.48s | lr: 3.73e-04 | Val. Loss: 0.182 |  Val. Acc: 92.87% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "Epoch: 011 | ET: 46.77s | \t Train Loss: 0.172 | Train Acc: 93.03% \t Val. Loss: 0.187 |  Val. Acc: 92.87% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.186 |  Val. Acc: 92.58% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.87s | lr: 3.36e-04 | Val. Loss: 0.197 |  Val. Acc: 92.15% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.25s | lr: 3.23e-04 | Val. Loss: 0.208 |  Val. Acc: 91.66% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "Epoch: 012 | ET: 46.66s | \t Train Loss: 0.167 | Train Acc: 93.02% \t Val. Loss: 0.197 |  Val. Acc: 92.49% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.50s | lr: 2.96e-04 | Val. Loss: 0.188 |  Val. Acc: 92.73% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.88s | lr: 2.82e-04 | Val. Loss: 0.206 |  Val. Acc: 91.32% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.26s | lr: 2.68e-04 | Val. Loss: 0.206 |  Val. Acc: 91.61% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.92%\n",
      "Epoch: 013 | ET: 46.79s | \t Train Loss: 0.154 | Train Acc: 93.49% \t Val. Loss: 0.181 |  Val. Acc: 92.97% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.49s | lr: 2.41e-04 | Val. Loss: 0.190 |  Val. Acc: 92.58% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.86s | lr: 2.27e-04 | Val. Loss: 0.209 |  Val. Acc: 91.08% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.25s | lr: 2.14e-04 | Val. Loss: 0.202 |  Val. Acc: 92.73% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 014 | ET: 46.62s | \t Train Loss: 0.149 | Train Acc: 93.71% \t Val. Loss: 0.183 |  Val. Acc: 92.63% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.49s | lr: 1.87e-04 | Val. Loss: 0.183 |  Val. Acc: 92.68% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.86s | lr: 1.74e-04 | Val. Loss: 0.195 |  Val. Acc: 92.00% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.24s | lr: 1.61e-04 | Val. Loss: 0.194 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 015 | ET: 46.62s | \t Train Loss: 0.147 | Train Acc: 93.80% \t Val. Loss: 0.182 |  Val. Acc: 92.39% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.49s | lr: 1.36e-04 | Val. Loss: 0.185 |  Val. Acc: 92.68% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.87s | lr: 1.24e-04 | Val. Loss: 0.199 |  Val. Acc: 91.76% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.24s | lr: 1.13e-04 | Val. Loss: 0.198 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 016 | ET: 46.63s | \t Train Loss: 0.138 | Train Acc: 94.58% \t Val. Loss: 0.182 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.51s | lr: 9.17e-05 | Val. Loss: 0.184 |  Val. Acc: 92.49% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.94s | lr: 8.16e-05 | Val. Loss: 0.211 |  Val. Acc: 92.34% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.29s | lr: 7.21e-05 | Val. Loss: 0.201 |  Val. Acc: 92.39% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 017 | ET: 46.61s | \t Train Loss: 0.124 | Train Acc: 95.09% \t Val. Loss: 0.188 |  Val. Acc: 92.83% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.187 |  Val. Acc: 92.44% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.84s | lr: 4.74e-05 | Val. Loss: 0.201 |  Val. Acc: 92.29% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.20s | lr: 4.04e-05 | Val. Loss: 0.194 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 018 | ET: 46.52s | \t Train Loss: 0.113 | Train Acc: 95.37% \t Val. Loss: 0.205 |  Val. Acc: 92.24% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.191 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.84s | lr: 2.37e-05 | Val. Loss: 0.194 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.20s | lr: 1.95e-05 | Val. Loss: 0.200 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 019 | ET: 46.50s | \t Train Loss: 0.105 | Train Acc: 95.72% \t Val. Loss: 0.206 |  Val. Acc: 92.29% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.195 |  Val. Acc: 91.81% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.83s | lr: 1.15e-05 | Val. Loss: 0.200 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.18s | lr: 1.04e-05 | Val. Loss: 0.198 |  Val. Acc: 92.00% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "Epoch: 020 | ET: 46.47s | \t Train Loss: 0.103 | Train Acc: 95.99% \t Val. Loss: 0.201 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    1    2    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.482 |  Val. Acc: 80.22% | B. Val. Loss: 0.482 |  B. Val. Acc: 80.22%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.95s | lr: 1.07e-04 | Val. Loss: 0.408 |  Val. Acc: 81.73% | B. Val. Loss: 0.408 |  B. Val. Acc: 81.73%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.49s | lr: 1.15e-04 | Val. Loss: 0.419 |  Val. Acc: 78.57% | B. Val. Loss: 0.408 |  B. Val. Acc: 81.73%\n",
      "Epoch: 001 | ET: 46.90s | \t Train Loss: 0.512 | Train Acc: 76.29% \t Val. Loss: 0.514 |  Val. Acc: 76.44% \t | B. Val. Loss: 0.408 |  B. Val. Acc: 81.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.306 |  Val. Acc: 86.96% | B. Val. Loss: 0.306 |  B. Val. Acc: 86.96%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.03s | lr: 1.59e-04 | Val. Loss: 0.314 |  Val. Acc: 86.91% | B. Val. Loss: 0.306 |  B. Val. Acc: 86.96%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.38s | lr: 1.79e-04 | Val. Loss: 0.330 |  Val. Acc: 85.41% | B. Val. Loss: 0.306 |  B. Val. Acc: 86.96%\n",
      "Epoch: 002 | ET: 46.71s | \t Train Loss: 0.387 | Train Acc: 82.90% \t Val. Loss: 0.334 |  Val. Acc: 85.26% \t | B. Val. Loss: 0.306 |  B. Val. Acc: 86.96%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.246 |  Val. Acc: 89.97% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.97%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.02s | lr: 2.48e-04 | Val. Loss: 0.290 |  Val. Acc: 88.12% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.97%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.38s | lr: 2.74e-04 | Val. Loss: 0.249 |  Val. Acc: 89.82% | B. Val. Loss: 0.246 |  B. Val. Acc: 89.97%\n",
      "Epoch: 003 | ET: 46.74s | \t Train Loss: 0.304 | Train Acc: 87.53% \t Val. Loss: 0.274 |  Val. Acc: 88.32% \t | B. Val. Loss: 0.246 |  B. Val. Acc: 89.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.49s | lr: 3.26e-04 | Val. Loss: 0.232 |  Val. Acc: 90.84% | B. Val. Loss: 0.232 |  B. Val. Acc: 90.84%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.06s | lr: 3.52e-04 | Val. Loss: 0.224 |  Val. Acc: 90.84% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.84%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.41s | lr: 3.77e-04 | Val. Loss: 0.265 |  Val. Acc: 89.19% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.84%\n",
      "Epoch: 004 | ET: 47.08s | \t Train Loss: 0.213 | Train Acc: 91.57% \t Val. Loss: 0.219 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.219 |  B. Val. Acc: 91.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.212 |  Val. Acc: 91.66% | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.06s | lr: 4.42e-04 | Val. Loss: 0.230 |  Val. Acc: 89.87% | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.43s | lr: 4.59e-04 | Val. Loss: 0.229 |  Val. Acc: 90.26% | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "Epoch: 005 | ET: 46.75s | \t Train Loss: 0.223 | Train Acc: 91.01% \t Val. Loss: 0.233 |  Val. Acc: 90.21% \t | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.213 |  Val. Acc: 90.26% | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.86s | lr: 4.93e-04 | Val. Loss: 0.313 |  Val. Acc: 88.95% | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.21s | lr: 4.98e-04 | Val. Loss: 0.232 |  Val. Acc: 90.40% | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "Epoch: 006 | ET: 46.68s | \t Train Loss: 0.207 | Train Acc: 91.49% \t Val. Loss: 0.219 |  Val. Acc: 90.89% \t | B. Val. Loss: 0.212 |  B. Val. Acc: 91.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.208 |  Val. Acc: 91.03% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.86s | lr: 4.98e-04 | Val. Loss: 0.251 |  Val. Acc: 90.21% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.23s | lr: 4.96e-04 | Val. Loss: 0.207 |  Val. Acc: 92.20% | B. Val. Loss: 0.207 |  B. Val. Acc: 92.20%\n",
      "Epoch: 007 | ET: 46.77s | \t Train Loss: 0.203 | Train Acc: 91.23% \t Val. Loss: 0.202 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.192 |  Val. Acc: 92.15% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.84s | lr: 4.86e-04 | Val. Loss: 0.189 |  Val. Acc: 92.44% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.40s | lr: 4.81e-04 | Val. Loss: 0.217 |  Val. Acc: 91.81% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.44%\n",
      "Epoch: 008 | ET: 46.99s | \t Train Loss: 0.182 | Train Acc: 92.18% \t Val. Loss: 0.190 |  Val. Acc: 92.68% \t | B. Val. Loss: 0.189 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.205 |  Val. Acc: 91.47% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.85s | lr: 4.62e-04 | Val. Loss: 0.271 |  Val. Acc: 89.87% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.21s | lr: 4.55e-04 | Val. Loss: 0.208 |  Val. Acc: 91.42% | B. Val. Loss: 0.189 |  B. Val. Acc: 92.68%\n",
      "Epoch: 009 | ET: 46.57s | \t Train Loss: 0.213 | Train Acc: 91.26% \t Val. Loss: 0.229 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.189 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.51s | lr: 4.38e-04 | Val. Loss: 0.185 |  Val. Acc: 92.58% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.88s | lr: 4.28e-04 | Val. Loss: 0.180 |  Val. Acc: 92.97% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.42s | lr: 4.18e-04 | Val. Loss: 0.194 |  Val. Acc: 92.87% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "Epoch: 010 | ET: 46.77s | \t Train Loss: 0.169 | Train Acc: 92.88% \t Val. Loss: 0.185 |  Val. Acc: 92.24% \t | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.48s | lr: 3.97e-04 | Val. Loss: 0.201 |  Val. Acc: 90.89% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.84s | lr: 3.85e-04 | Val. Loss: 0.210 |  Val. Acc: 92.00% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.19s | lr: 3.73e-04 | Val. Loss: 0.189 |  Val. Acc: 92.78% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "Epoch: 011 | ET: 46.51s | \t Train Loss: 0.228 | Train Acc: 89.33% \t Val. Loss: 0.238 |  Val. Acc: 88.80% \t | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.193 |  Val. Acc: 92.63% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.91s | lr: 3.36e-04 | Val. Loss: 0.193 |  Val. Acc: 91.57% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.28s | lr: 3.23e-04 | Val. Loss: 0.194 |  Val. Acc: 92.44% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "Epoch: 012 | ET: 46.67s | \t Train Loss: 0.176 | Train Acc: 92.26% \t Val. Loss: 0.205 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.186 |  Val. Acc: 92.83% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.84s | lr: 2.82e-04 | Val. Loss: 0.200 |  Val. Acc: 92.05% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.21s | lr: 2.68e-04 | Val. Loss: 0.179 |  Val. Acc: 93.07% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 013 | ET: 46.81s | \t Train Loss: 0.173 | Train Acc: 93.18% \t Val. Loss: 0.195 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.49s | lr: 2.41e-04 | Val. Loss: 0.189 |  Val. Acc: 92.68% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.85s | lr: 2.27e-04 | Val. Loss: 0.196 |  Val. Acc: 91.23% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.22s | lr: 2.14e-04 | Val. Loss: 0.193 |  Val. Acc: 92.29% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 014 | ET: 46.59s | \t Train Loss: 0.172 | Train Acc: 92.29% \t Val. Loss: 0.200 |  Val. Acc: 92.24% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.49s | lr: 1.87e-04 | Val. Loss: 0.188 |  Val. Acc: 92.54% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.85s | lr: 1.74e-04 | Val. Loss: 0.216 |  Val. Acc: 89.48% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.22s | lr: 1.61e-04 | Val. Loss: 0.188 |  Val. Acc: 92.73% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 015 | ET: 46.59s | \t Train Loss: 0.174 | Train Acc: 93.18% \t Val. Loss: 0.211 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.49s | lr: 1.36e-04 | Val. Loss: 0.191 |  Val. Acc: 92.24% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.86s | lr: 1.24e-04 | Val. Loss: 0.208 |  Val. Acc: 92.58% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.24s | lr: 1.13e-04 | Val. Loss: 0.183 |  Val. Acc: 92.39% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 016 | ET: 46.61s | \t Train Loss: 0.128 | Train Acc: 94.75% \t Val. Loss: 0.186 |  Val. Acc: 92.49% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.49s | lr: 9.17e-05 | Val. Loss: 0.192 |  Val. Acc: 92.24% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.87s | lr: 8.16e-05 | Val. Loss: 0.193 |  Val. Acc: 92.24% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.23s | lr: 7.21e-05 | Val. Loss: 0.195 |  Val. Acc: 93.07% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 017 | ET: 46.71s | \t Train Loss: 0.123 | Train Acc: 95.08% \t Val. Loss: 0.193 |  Val. Acc: 92.49% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.199 |  Val. Acc: 92.54% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.86s | lr: 4.74e-05 | Val. Loss: 0.209 |  Val. Acc: 92.87% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.23s | lr: 4.04e-05 | Val. Loss: 0.204 |  Val. Acc: 92.54% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 018 | ET: 46.63s | \t Train Loss: 0.119 | Train Acc: 95.12% \t Val. Loss: 0.207 |  Val. Acc: 92.97% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.202 |  Val. Acc: 92.00% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.85s | lr: 2.37e-05 | Val. Loss: 0.206 |  Val. Acc: 91.81% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.22s | lr: 1.95e-05 | Val. Loss: 0.201 |  Val. Acc: 92.05% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 019 | ET: 46.57s | \t Train Loss: 0.107 | Train Acc: 95.72% \t Val. Loss: 0.212 |  Val. Acc: 92.58% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.49s | lr: 1.34e-05 | Val. Loss: 0.203 |  Val. Acc: 92.44% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.85s | lr: 1.15e-05 | Val. Loss: 0.212 |  Val. Acc: 92.54% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.23s | lr: 1.04e-05 | Val. Loss: 0.204 |  Val. Acc: 92.00% | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "Epoch: 020 | ET: 46.60s | \t Train Loss: 0.101 | Train Acc: 96.07% \t Val. Loss: 0.207 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.179 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    1    3    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.419 |  Val. Acc: 81.29% | B. Val. Loss: 0.419 |  B. Val. Acc: 81.29%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.94s | lr: 1.07e-04 | Val. Loss: 0.415 |  Val. Acc: 81.73% | B. Val. Loss: 0.415 |  B. Val. Acc: 81.73%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.49s | lr: 1.15e-04 | Val. Loss: 0.443 |  Val. Acc: 81.29% | B. Val. Loss: 0.415 |  B. Val. Acc: 81.73%\n",
      "Epoch: 001 | ET: 47.12s | \t Train Loss: 0.377 | Train Acc: 82.89% \t Val. Loss: 0.358 |  Val. Acc: 83.62% \t | B. Val. Loss: 0.358 |  B. Val. Acc: 83.62%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.50s | lr: 1.41e-04 | Val. Loss: 0.326 |  Val. Acc: 85.31% | B. Val. Loss: 0.326 |  B. Val. Acc: 85.31%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.06s | lr: 1.59e-04 | Val. Loss: 0.318 |  Val. Acc: 86.04% | B. Val. Loss: 0.318 |  B. Val. Acc: 86.04%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.62s | lr: 1.79e-04 | Val. Loss: 0.308 |  Val. Acc: 87.74% | B. Val. Loss: 0.308 |  B. Val. Acc: 87.74%\n",
      "Epoch: 002 | ET: 47.42s | \t Train Loss: 0.276 | Train Acc: 88.53% \t Val. Loss: 0.252 |  Val. Acc: 89.38% \t | B. Val. Loss: 0.252 |  B. Val. Acc: 89.38%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.266 |  Val. Acc: 88.75% | B. Val. Loss: 0.252 |  B. Val. Acc: 89.38%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 13.83s | lr: 2.48e-04 | Val. Loss: 0.328 |  Val. Acc: 87.15% | B. Val. Loss: 0.252 |  B. Val. Acc: 89.38%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.18s | lr: 2.74e-04 | Val. Loss: 0.249 |  Val. Acc: 89.43% | B. Val. Loss: 0.249 |  B. Val. Acc: 89.43%\n",
      "Epoch: 003 | ET: 46.86s | \t Train Loss: 0.261 | Train Acc: 89.79% \t Val. Loss: 0.269 |  Val. Acc: 89.48% \t | B. Val. Loss: 0.249 |  B. Val. Acc: 89.48%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.48s | lr: 3.26e-04 | Val. Loss: 0.248 |  Val. Acc: 88.95% | B. Val. Loss: 0.248 |  B. Val. Acc: 89.48%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.83s | lr: 3.52e-04 | Val. Loss: 0.291 |  Val. Acc: 86.82% | B. Val. Loss: 0.248 |  B. Val. Acc: 89.48%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.18s | lr: 3.77e-04 | Val. Loss: 0.254 |  Val. Acc: 89.97% | B. Val. Loss: 0.248 |  B. Val. Acc: 89.97%\n",
      "Epoch: 004 | ET: 46.86s | \t Train Loss: 0.246 | Train Acc: 90.94% \t Val. Loss: 0.249 |  Val. Acc: 90.60% \t | B. Val. Loss: 0.248 |  B. Val. Acc: 90.60%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.48s | lr: 4.22e-04 | Val. Loss: 0.216 |  Val. Acc: 91.61% | B. Val. Loss: 0.216 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.03s | lr: 4.42e-04 | Val. Loss: 0.239 |  Val. Acc: 90.40% | B. Val. Loss: 0.216 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.39s | lr: 4.59e-04 | Val. Loss: 0.211 |  Val. Acc: 91.57% | B. Val. Loss: 0.211 |  B. Val. Acc: 91.61%\n",
      "Epoch: 005 | ET: 46.67s | \t Train Loss: 0.224 | Train Acc: 90.17% \t Val. Loss: 0.220 |  Val. Acc: 90.69% \t | B. Val. Loss: 0.211 |  B. Val. Acc: 91.61%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.215 |  Val. Acc: 91.61% | B. Val. Loss: 0.211 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.82s | lr: 4.93e-04 | Val. Loss: 0.204 |  Val. Acc: 91.90% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.36s | lr: 4.98e-04 | Val. Loss: 0.232 |  Val. Acc: 90.55% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.90%\n",
      "Epoch: 006 | ET: 46.87s | \t Train Loss: 0.191 | Train Acc: 91.91% \t Val. Loss: 0.192 |  Val. Acc: 92.24% \t | B. Val. Loss: 0.192 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.195 |  Val. Acc: 92.39% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.03s | lr: 4.98e-04 | Val. Loss: 0.216 |  Val. Acc: 90.69% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.38s | lr: 4.96e-04 | Val. Loss: 0.202 |  Val. Acc: 91.86% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.39%\n",
      "Epoch: 007 | ET: 46.82s | \t Train Loss: 0.195 | Train Acc: 91.58% \t Val. Loss: 0.194 |  Val. Acc: 91.76% \t | B. Val. Loss: 0.192 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.49s | lr: 4.90e-04 | Val. Loss: 0.192 |  Val. Acc: 92.63% | B. Val. Loss: 0.192 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.06s | lr: 4.86e-04 | Val. Loss: 0.187 |  Val. Acc: 92.44% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.41s | lr: 4.81e-04 | Val. Loss: 0.189 |  Val. Acc: 91.66% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.63%\n",
      "Epoch: 008 | ET: 46.75s | \t Train Loss: 0.183 | Train Acc: 91.97% \t Val. Loss: 0.194 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.50s | lr: 4.69e-04 | Val. Loss: 0.220 |  Val. Acc: 92.44% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.87s | lr: 4.62e-04 | Val. Loss: 0.256 |  Val. Acc: 91.47% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.24s | lr: 4.55e-04 | Val. Loss: 0.182 |  Val. Acc: 92.83% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.83%\n",
      "Epoch: 009 | ET: 46.78s | \t Train Loss: 0.189 | Train Acc: 91.11% \t Val. Loss: 0.210 |  Val. Acc: 91.08% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.83%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.193 |  Val. Acc: 92.10% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.83%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.84s | lr: 4.28e-04 | Val. Loss: 0.183 |  Val. Acc: 92.87% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.40s | lr: 4.18e-04 | Val. Loss: 0.201 |  Val. Acc: 90.40% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.87%\n",
      "Epoch: 010 | ET: 46.86s | \t Train Loss: 0.166 | Train Acc: 92.84% \t Val. Loss: 0.184 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.190 |  Val. Acc: 92.54% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.87s | lr: 3.85e-04 | Val. Loss: 0.180 |  Val. Acc: 92.39% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.23s | lr: 3.73e-04 | Val. Loss: 0.191 |  Val. Acc: 92.54% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "Epoch: 011 | ET: 46.58s | \t Train Loss: 0.179 | Train Acc: 92.62% \t Val. Loss: 0.192 |  Val. Acc: 92.29% \t | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.188 |  Val. Acc: 92.49% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.85s | lr: 3.36e-04 | Val. Loss: 0.182 |  Val. Acc: 92.24% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.22s | lr: 3.23e-04 | Val. Loss: 0.186 |  Val. Acc: 92.15% | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "Epoch: 012 | ET: 46.55s | \t Train Loss: 0.176 | Train Acc: 92.32% \t Val. Loss: 0.204 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.180 |  B. Val. Acc: 92.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.49s | lr: 2.96e-04 | Val. Loss: 0.178 |  Val. Acc: 92.83% | B. Val. Loss: 0.178 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.85s | lr: 2.82e-04 | Val. Loss: 0.186 |  Val. Acc: 92.20% | B. Val. Loss: 0.178 |  B. Val. Acc: 92.87%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.29s | lr: 2.68e-04 | Val. Loss: 0.177 |  Val. Acc: 93.07% | B. Val. Loss: 0.177 |  B. Val. Acc: 93.07%\n",
      "Epoch: 013 | ET: 46.89s | \t Train Loss: 0.154 | Train Acc: 93.70% \t Val. Loss: 0.174 |  Val. Acc: 93.02% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.50s | lr: 2.41e-04 | Val. Loss: 0.187 |  Val. Acc: 92.54% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.89s | lr: 2.27e-04 | Val. Loss: 0.190 |  Val. Acc: 91.86% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.27s | lr: 2.14e-04 | Val. Loss: 0.183 |  Val. Acc: 92.58% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 014 | ET: 46.69s | \t Train Loss: 0.153 | Train Acc: 93.58% \t Val. Loss: 0.187 |  Val. Acc: 92.63% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.50s | lr: 1.87e-04 | Val. Loss: 0.191 |  Val. Acc: 92.58% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.87s | lr: 1.74e-04 | Val. Loss: 0.179 |  Val. Acc: 92.68% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.24s | lr: 1.61e-04 | Val. Loss: 0.186 |  Val. Acc: 92.58% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 015 | ET: 46.67s | \t Train Loss: 0.140 | Train Acc: 94.20% \t Val. Loss: 0.191 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.51s | lr: 1.36e-04 | Val. Loss: 0.189 |  Val. Acc: 92.73% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.90s | lr: 1.24e-04 | Val. Loss: 0.182 |  Val. Acc: 92.68% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.28s | lr: 1.13e-04 | Val. Loss: 0.181 |  Val. Acc: 92.68% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 016 | ET: 46.72s | \t Train Loss: 0.137 | Train Acc: 94.31% \t Val. Loss: 0.198 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.50s | lr: 9.17e-05 | Val. Loss: 0.185 |  Val. Acc: 92.39% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.88s | lr: 8.16e-05 | Val. Loss: 0.195 |  Val. Acc: 91.81% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.28s | lr: 7.21e-05 | Val. Loss: 0.224 |  Val. Acc: 92.44% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 017 | ET: 46.74s | \t Train Loss: 0.123 | Train Acc: 94.96% \t Val. Loss: 0.203 |  Val. Acc: 92.78% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.50s | lr: 5.51e-05 | Val. Loss: 0.188 |  Val. Acc: 92.34% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.88s | lr: 4.74e-05 | Val. Loss: 0.199 |  Val. Acc: 92.73% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.26s | lr: 4.04e-05 | Val. Loss: 0.199 |  Val. Acc: 92.29% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 018 | ET: 46.72s | \t Train Loss: 0.113 | Train Acc: 95.44% \t Val. Loss: 0.200 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.50s | lr: 2.86e-05 | Val. Loss: 0.195 |  Val. Acc: 92.39% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.95s | lr: 2.37e-05 | Val. Loss: 0.206 |  Val. Acc: 92.54% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.34s | lr: 1.95e-05 | Val. Loss: 0.199 |  Val. Acc: 91.90% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 019 | ET: 46.73s | \t Train Loss: 0.104 | Train Acc: 96.16% \t Val. Loss: 0.197 |  Val. Acc: 92.24% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.49s | lr: 1.34e-05 | Val. Loss: 0.196 |  Val. Acc: 92.24% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.87s | lr: 1.15e-05 | Val. Loss: 0.199 |  Val. Acc: 92.15% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.34s | lr: 1.04e-05 | Val. Loss: 0.201 |  Val. Acc: 92.10% | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "Epoch: 020 | ET: 46.85s | \t Train Loss: 0.100 | Train Acc: 95.98% \t Val. Loss: 0.199 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.174 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    1    4    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.50s | lr: 1.02e-04 | Val. Loss: 0.457 |  Val. Acc: 79.01% | B. Val. Loss: 0.457 |  B. Val. Acc: 79.01%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.96s | lr: 1.07e-04 | Val. Loss: 0.412 |  Val. Acc: 81.29% | B. Val. Loss: 0.412 |  B. Val. Acc: 81.29%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.55s | lr: 1.15e-04 | Val. Loss: 0.405 |  Val. Acc: 83.52% | B. Val. Loss: 0.405 |  B. Val. Acc: 83.52%\n",
      "Epoch: 001 | ET: 47.32s | \t Train Loss: 0.347 | Train Acc: 85.04% \t Val. Loss: 0.328 |  Val. Acc: 86.33% \t | B. Val. Loss: 0.328 |  B. Val. Acc: 86.33%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.306 |  Val. Acc: 86.62% | B. Val. Loss: 0.306 |  B. Val. Acc: 86.62%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.03s | lr: 1.59e-04 | Val. Loss: 0.299 |  Val. Acc: 86.62% | B. Val. Loss: 0.299 |  B. Val. Acc: 86.62%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.40s | lr: 1.79e-04 | Val. Loss: 0.344 |  Val. Acc: 84.44% | B. Val. Loss: 0.299 |  B. Val. Acc: 86.62%\n",
      "Epoch: 002 | ET: 46.98s | \t Train Loss: 0.260 | Train Acc: 89.14% \t Val. Loss: 0.255 |  Val. Acc: 89.63% \t | B. Val. Loss: 0.255 |  B. Val. Acc: 89.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.58s | lr: 2.23e-04 | Val. Loss: 0.257 |  Val. Acc: 89.68% | B. Val. Loss: 0.255 |  B. Val. Acc: 89.68%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.17s | lr: 2.48e-04 | Val. Loss: 0.241 |  Val. Acc: 89.14% | B. Val. Loss: 0.241 |  B. Val. Acc: 89.68%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.53s | lr: 2.74e-04 | Val. Loss: 0.253 |  Val. Acc: 89.97% | B. Val. Loss: 0.241 |  B. Val. Acc: 89.97%\n",
      "Epoch: 003 | ET: 47.11s | \t Train Loss: 0.336 | Train Acc: 86.40% \t Val. Loss: 0.292 |  Val. Acc: 88.66% \t | B. Val. Loss: 0.241 |  B. Val. Acc: 89.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.49s | lr: 3.26e-04 | Val. Loss: 0.238 |  Val. Acc: 90.26% | B. Val. Loss: 0.238 |  B. Val. Acc: 90.26%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.03s | lr: 3.52e-04 | Val. Loss: 0.415 |  Val. Acc: 82.89% | B. Val. Loss: 0.238 |  B. Val. Acc: 90.26%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.39s | lr: 3.77e-04 | Val. Loss: 0.271 |  Val. Acc: 89.34% | B. Val. Loss: 0.238 |  B. Val. Acc: 90.26%\n",
      "Epoch: 004 | ET: 46.71s | \t Train Loss: 0.272 | Train Acc: 89.18% \t Val. Loss: 0.262 |  Val. Acc: 90.01% \t | B. Val. Loss: 0.238 |  B. Val. Acc: 90.26%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.49s | lr: 4.22e-04 | Val. Loss: 0.208 |  Val. Acc: 91.13% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.05s | lr: 4.42e-04 | Val. Loss: 0.233 |  Val. Acc: 90.11% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.41s | lr: 4.59e-04 | Val. Loss: 0.206 |  Val. Acc: 90.98% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.13%\n",
      "Epoch: 005 | ET: 46.95s | \t Train Loss: 0.210 | Train Acc: 91.37% \t Val. Loss: 0.207 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.206 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.54s | lr: 4.85e-04 | Val. Loss: 0.288 |  Val. Acc: 86.57% | B. Val. Loss: 0.206 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.92s | lr: 4.93e-04 | Val. Loss: 0.195 |  Val. Acc: 92.44% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.51s | lr: 4.98e-04 | Val. Loss: 0.219 |  Val. Acc: 91.52% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "Epoch: 006 | ET: 46.85s | \t Train Loss: 0.235 | Train Acc: 90.34% \t Val. Loss: 0.232 |  Val. Acc: 90.21% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.207 |  Val. Acc: 92.10% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.86s | lr: 4.98e-04 | Val. Loss: 0.285 |  Val. Acc: 87.30% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.25s | lr: 4.96e-04 | Val. Loss: 0.201 |  Val. Acc: 90.74% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "Epoch: 007 | ET: 46.69s | \t Train Loss: 0.246 | Train Acc: 89.71% \t Val. Loss: 0.252 |  Val. Acc: 89.72% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.49s | lr: 4.90e-04 | Val. Loss: 0.195 |  Val. Acc: 92.15% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.84s | lr: 4.86e-04 | Val. Loss: 0.234 |  Val. Acc: 90.69% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.31s | lr: 4.81e-04 | Val. Loss: 0.216 |  Val. Acc: 91.13% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.44%\n",
      "Epoch: 008 | ET: 46.84s | \t Train Loss: 0.186 | Train Acc: 92.23% \t Val. Loss: 0.195 |  Val. Acc: 92.63% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.190 |  Val. Acc: 92.39% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.83s | lr: 4.62e-04 | Val. Loss: 0.195 |  Val. Acc: 91.81% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.20s | lr: 4.55e-04 | Val. Loss: 0.192 |  Val. Acc: 92.00% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.63%\n",
      "Epoch: 009 | ET: 46.52s | \t Train Loss: 0.182 | Train Acc: 92.83% \t Val. Loss: 0.206 |  Val. Acc: 92.29% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.188 |  Val. Acc: 93.17% | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 14.10s | lr: 4.28e-04 | Val. Loss: 0.205 |  Val. Acc: 91.52% | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.45s | lr: 4.18e-04 | Val. Loss: 0.244 |  Val. Acc: 90.26% | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "Epoch: 010 | ET: 46.77s | \t Train Loss: 0.182 | Train Acc: 92.32% \t Val. Loss: 0.199 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.49s | lr: 3.97e-04 | Val. Loss: 0.188 |  Val. Acc: 92.63% | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.82s | lr: 3.85e-04 | Val. Loss: 0.212 |  Val. Acc: 92.68% | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.16s | lr: 3.73e-04 | Val. Loss: 0.197 |  Val. Acc: 91.57% | B. Val. Loss: 0.188 |  B. Val. Acc: 93.17%\n",
      "Epoch: 011 | ET: 46.46s | \t Train Loss: 0.167 | Train Acc: 92.88% \t Val. Loss: 0.187 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 93.17%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.184 |  Val. Acc: 92.78% | B. Val. Loss: 0.184 |  B. Val. Acc: 93.17%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.84s | lr: 3.36e-04 | Val. Loss: 0.195 |  Val. Acc: 92.44% | B. Val. Loss: 0.184 |  B. Val. Acc: 93.17%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.18s | lr: 3.23e-04 | Val. Loss: 0.190 |  Val. Acc: 92.00% | B. Val. Loss: 0.184 |  B. Val. Acc: 93.17%\n",
      "Epoch: 012 | ET: 46.65s | \t Train Loss: 0.157 | Train Acc: 93.58% \t Val. Loss: 0.181 |  Val. Acc: 93.21% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.184 |  Val. Acc: 92.44% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.82s | lr: 2.82e-04 | Val. Loss: 0.209 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.17s | lr: 2.68e-04 | Val. Loss: 0.186 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 013 | ET: 46.44s | \t Train Loss: 0.150 | Train Acc: 93.61% \t Val. Loss: 0.181 |  Val. Acc: 92.58% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.187 |  Val. Acc: 92.63% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.89s | lr: 2.27e-04 | Val. Loss: 0.189 |  Val. Acc: 92.05% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.24s | lr: 2.14e-04 | Val. Loss: 0.181 |  Val. Acc: 92.83% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 014 | ET: 46.60s | \t Train Loss: 0.153 | Train Acc: 93.32% \t Val. Loss: 0.194 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.49s | lr: 1.87e-04 | Val. Loss: 0.192 |  Val. Acc: 92.73% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.85s | lr: 1.74e-04 | Val. Loss: 0.181 |  Val. Acc: 92.58% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.21s | lr: 1.61e-04 | Val. Loss: 0.191 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 015 | ET: 46.53s | \t Train Loss: 0.143 | Train Acc: 94.10% \t Val. Loss: 0.191 |  Val. Acc: 92.63% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.195 |  Val. Acc: 92.87% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.86s | lr: 1.24e-04 | Val. Loss: 0.204 |  Val. Acc: 92.29% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.23s | lr: 1.13e-04 | Val. Loss: 0.192 |  Val. Acc: 92.34% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 016 | ET: 46.56s | \t Train Loss: 0.132 | Train Acc: 94.73% \t Val. Loss: 0.181 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.49s | lr: 9.17e-05 | Val. Loss: 0.188 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.84s | lr: 8.16e-05 | Val. Loss: 0.196 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.20s | lr: 7.21e-05 | Val. Loss: 0.191 |  Val. Acc: 92.49% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 017 | ET: 46.53s | \t Train Loss: 0.130 | Train Acc: 94.57% \t Val. Loss: 0.217 |  Val. Acc: 92.63% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.200 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.84s | lr: 4.74e-05 | Val. Loss: 0.196 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.20s | lr: 4.04e-05 | Val. Loss: 0.201 |  Val. Acc: 92.78% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 018 | ET: 46.51s | \t Train Loss: 0.115 | Train Acc: 95.26% \t Val. Loss: 0.207 |  Val. Acc: 92.39% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.200 |  Val. Acc: 92.58% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.86s | lr: 2.37e-05 | Val. Loss: 0.205 |  Val. Acc: 92.63% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.23s | lr: 1.95e-05 | Val. Loss: 0.204 |  Val. Acc: 92.58% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 019 | ET: 46.56s | \t Train Loss: 0.116 | Train Acc: 95.32% \t Val. Loss: 0.216 |  Val. Acc: 92.49% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.56s | lr: 1.34e-05 | Val. Loss: 0.202 |  Val. Acc: 92.68% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.92s | lr: 1.15e-05 | Val. Loss: 0.209 |  Val. Acc: 92.58% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.28s | lr: 1.04e-05 | Val. Loss: 0.209 |  Val. Acc: 92.49% | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "Epoch: 020 | ET: 46.65s | \t Train Loss: 0.108 | Train Acc: 95.80% \t Val. Loss: 0.210 |  Val. Acc: 92.39% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 93.21%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    2    0    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.50s | lr: 1.02e-04 | Val. Loss: 0.471 |  Val. Acc: 80.56% | B. Val. Loss: 0.471 |  B. Val. Acc: 80.56%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.96s | lr: 1.07e-04 | Val. Loss: 0.615 |  Val. Acc: 72.52% | B. Val. Loss: 0.471 |  B. Val. Acc: 80.56%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.33s | lr: 1.15e-04 | Val. Loss: 0.415 |  Val. Acc: 80.95% | B. Val. Loss: 0.415 |  B. Val. Acc: 80.95%\n",
      "Epoch: 001 | ET: 47.14s | \t Train Loss: 0.384 | Train Acc: 82.36% \t Val. Loss: 0.397 |  Val. Acc: 82.06% \t | B. Val. Loss: 0.397 |  B. Val. Acc: 82.06%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.51s | lr: 1.41e-04 | Val. Loss: 0.331 |  Val. Acc: 86.77% | B. Val. Loss: 0.331 |  B. Val. Acc: 86.77%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.06s | lr: 1.59e-04 | Val. Loss: 0.318 |  Val. Acc: 86.96% | B. Val. Loss: 0.318 |  B. Val. Acc: 86.96%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.62s | lr: 1.79e-04 | Val. Loss: 0.317 |  Val. Acc: 87.59% | B. Val. Loss: 0.317 |  B. Val. Acc: 87.59%\n",
      "Epoch: 002 | ET: 47.28s | \t Train Loss: 0.335 | Train Acc: 86.37% \t Val. Loss: 0.342 |  Val. Acc: 86.52% \t | B. Val. Loss: 0.317 |  B. Val. Acc: 87.59%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.49s | lr: 2.23e-04 | Val. Loss: 0.285 |  Val. Acc: 88.03% | B. Val. Loss: 0.285 |  B. Val. Acc: 88.03%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.17s | lr: 2.48e-04 | Val. Loss: 0.287 |  Val. Acc: 88.12% | B. Val. Loss: 0.285 |  B. Val. Acc: 88.12%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.74s | lr: 2.74e-04 | Val. Loss: 0.342 |  Val. Acc: 88.51% | B. Val. Loss: 0.285 |  B. Val. Acc: 88.51%\n",
      "Epoch: 003 | ET: 47.37s | \t Train Loss: 0.297 | Train Acc: 87.24% \t Val. Loss: 0.308 |  Val. Acc: 86.62% \t | B. Val. Loss: 0.285 |  B. Val. Acc: 88.51%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.49s | lr: 3.26e-04 | Val. Loss: 0.256 |  Val. Acc: 90.16% | B. Val. Loss: 0.256 |  B. Val. Acc: 90.16%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.13s | lr: 3.52e-04 | Val. Loss: 0.412 |  Val. Acc: 82.45% | B. Val. Loss: 0.256 |  B. Val. Acc: 90.16%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.49s | lr: 3.77e-04 | Val. Loss: 0.252 |  Val. Acc: 89.77% | B. Val. Loss: 0.252 |  B. Val. Acc: 90.16%\n",
      "Epoch: 004 | ET: 46.98s | \t Train Loss: 0.206 | Train Acc: 91.15% \t Val. Loss: 0.224 |  Val. Acc: 90.55% \t | B. Val. Loss: 0.224 |  B. Val. Acc: 90.55%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.49s | lr: 4.22e-04 | Val. Loss: 0.229 |  Val. Acc: 90.50% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.55%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.85s | lr: 4.42e-04 | Val. Loss: 0.257 |  Val. Acc: 90.35% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.55%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.20s | lr: 4.59e-04 | Val. Loss: 0.226 |  Val. Acc: 90.98% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.98%\n",
      "Epoch: 005 | ET: 46.90s | \t Train Loss: 0.193 | Train Acc: 91.97% \t Val. Loss: 0.217 |  Val. Acc: 91.08% \t | B. Val. Loss: 0.217 |  B. Val. Acc: 91.08%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.208 |  Val. Acc: 91.71% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.04s | lr: 4.93e-04 | Val. Loss: 0.232 |  Val. Acc: 90.16% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.42s | lr: 4.98e-04 | Val. Loss: 0.243 |  Val. Acc: 90.84% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.71%\n",
      "Epoch: 006 | ET: 46.74s | \t Train Loss: 0.185 | Train Acc: 92.00% \t Val. Loss: 0.210 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.208 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.204 |  Val. Acc: 91.52% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.83s | lr: 4.98e-04 | Val. Loss: 0.230 |  Val. Acc: 90.31% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.19s | lr: 4.96e-04 | Val. Loss: 0.229 |  Val. Acc: 90.06% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "Epoch: 007 | ET: 46.52s | \t Train Loss: 0.173 | Train Acc: 92.62% \t Val. Loss: 0.216 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.49s | lr: 4.90e-04 | Val. Loss: 0.214 |  Val. Acc: 91.32% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.85s | lr: 4.86e-04 | Val. Loss: 0.229 |  Val. Acc: 91.52% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.20s | lr: 4.81e-04 | Val. Loss: 0.243 |  Val. Acc: 89.82% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "Epoch: 008 | ET: 46.52s | \t Train Loss: 0.178 | Train Acc: 92.85% \t Val. Loss: 0.206 |  Val. Acc: 91.03% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.48s | lr: 4.69e-04 | Val. Loss: 0.210 |  Val. Acc: 91.52% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.83s | lr: 4.62e-04 | Val. Loss: 0.253 |  Val. Acc: 89.24% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.26s | lr: 4.55e-04 | Val. Loss: 0.201 |  Val. Acc: 91.27% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "Epoch: 009 | ET: 46.54s | \t Train Loss: 0.187 | Train Acc: 92.25% \t Val. Loss: 0.216 |  Val. Acc: 91.03% \t | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.204 |  Val. Acc: 91.08% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.82s | lr: 4.28e-04 | Val. Loss: 0.226 |  Val. Acc: 90.31% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.16s | lr: 4.18e-04 | Val. Loss: 0.250 |  Val. Acc: 90.31% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "Epoch: 010 | ET: 46.43s | \t Train Loss: 0.183 | Train Acc: 91.60% \t Val. Loss: 0.221 |  Val. Acc: 90.60% \t | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.210 |  Val. Acc: 90.84% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.85s | lr: 3.85e-04 | Val. Loss: 0.207 |  Val. Acc: 90.98% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.19s | lr: 3.73e-04 | Val. Loss: 0.207 |  Val. Acc: 91.03% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "Epoch: 011 | ET: 46.44s | \t Train Loss: 0.157 | Train Acc: 93.29% \t Val. Loss: 0.208 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.201 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.199 |  Val. Acc: 91.52% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.82s | lr: 3.36e-04 | Val. Loss: 0.238 |  Val. Acc: 91.18% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.17s | lr: 3.23e-04 | Val. Loss: 0.307 |  Val. Acc: 84.25% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.71%\n",
      "Epoch: 012 | ET: 46.45s | \t Train Loss: 0.183 | Train Acc: 92.98% \t Val. Loss: 0.227 |  Val. Acc: 91.52% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.215 |  Val. Acc: 91.81% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 14.03s | lr: 2.82e-04 | Val. Loss: 0.207 |  Val. Acc: 90.89% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.40s | lr: 2.68e-04 | Val. Loss: 0.216 |  Val. Acc: 91.03% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.81%\n",
      "Epoch: 013 | ET: 46.77s | \t Train Loss: 0.168 | Train Acc: 92.72% \t Val. Loss: 0.216 |  Val. Acc: 91.08% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 91.81%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.51s | lr: 2.41e-04 | Val. Loss: 0.209 |  Val. Acc: 92.24% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 14.07s | lr: 2.27e-04 | Val. Loss: 0.204 |  Val. Acc: 91.61% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.42s | lr: 2.14e-04 | Val. Loss: 0.202 |  Val. Acc: 91.47% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "Epoch: 014 | ET: 46.76s | \t Train Loss: 0.143 | Train Acc: 93.82% \t Val. Loss: 0.196 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.55s | lr: 1.87e-04 | Val. Loss: 0.205 |  Val. Acc: 91.61% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.89s | lr: 1.74e-04 | Val. Loss: 0.206 |  Val. Acc: 91.52% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.25s | lr: 1.61e-04 | Val. Loss: 0.235 |  Val. Acc: 91.66% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "Epoch: 015 | ET: 46.52s | \t Train Loss: 0.150 | Train Acc: 93.95% \t Val. Loss: 0.216 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.47s | lr: 1.36e-04 | Val. Loss: 0.197 |  Val. Acc: 91.95% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.82s | lr: 1.24e-04 | Val. Loss: 0.206 |  Val. Acc: 91.18% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.16s | lr: 1.13e-04 | Val. Loss: 0.222 |  Val. Acc: 91.27% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "Epoch: 016 | ET: 46.44s | \t Train Loss: 0.123 | Train Acc: 95.18% \t Val. Loss: 0.209 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.49s | lr: 9.17e-05 | Val. Loss: 0.203 |  Val. Acc: 91.27% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.83s | lr: 8.16e-05 | Val. Loss: 0.210 |  Val. Acc: 92.05% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.19s | lr: 7.21e-05 | Val. Loss: 0.210 |  Val. Acc: 91.86% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "Epoch: 017 | ET: 46.47s | \t Train Loss: 0.115 | Train Acc: 95.49% \t Val. Loss: 0.197 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.210 |  Val. Acc: 91.81% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.84s | lr: 4.74e-05 | Val. Loss: 0.209 |  Val. Acc: 91.42% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.21s | lr: 4.04e-05 | Val. Loss: 0.223 |  Val. Acc: 91.71% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "Epoch: 018 | ET: 46.50s | \t Train Loss: 0.106 | Train Acc: 95.76% \t Val. Loss: 0.219 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.215 |  Val. Acc: 91.42% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.83s | lr: 2.37e-05 | Val. Loss: 0.220 |  Val. Acc: 91.37% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.17s | lr: 1.95e-05 | Val. Loss: 0.226 |  Val. Acc: 91.27% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "Epoch: 019 | ET: 46.45s | \t Train Loss: 0.099 | Train Acc: 96.20% \t Val. Loss: 0.229 |  Val. Acc: 91.42% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.49s | lr: 1.34e-05 | Val. Loss: 0.217 |  Val. Acc: 91.66% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.83s | lr: 1.15e-05 | Val. Loss: 0.222 |  Val. Acc: 91.52% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.18s | lr: 1.04e-05 | Val. Loss: 0.229 |  Val. Acc: 91.18% | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "Epoch: 020 | ET: 46.55s | \t Train Loss: 0.100 | Train Acc: 96.04% \t Val. Loss: 0.232 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    2    1    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.468 |  Val. Acc: 77.07% | B. Val. Loss: 0.468 |  B. Val. Acc: 77.07%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.96s | lr: 1.07e-04 | Val. Loss: 0.426 |  Val. Acc: 82.36% | B. Val. Loss: 0.426 |  B. Val. Acc: 82.36%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.53s | lr: 1.15e-04 | Val. Loss: 0.369 |  Val. Acc: 85.41% | B. Val. Loss: 0.369 |  B. Val. Acc: 85.41%\n",
      "Epoch: 001 | ET: 47.36s | \t Train Loss: 0.332 | Train Acc: 85.61% \t Val. Loss: 0.333 |  Val. Acc: 85.60% \t | B. Val. Loss: 0.333 |  B. Val. Acc: 85.60%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.315 |  Val. Acc: 86.86% | B. Val. Loss: 0.315 |  B. Val. Acc: 86.86%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.05s | lr: 1.59e-04 | Val. Loss: 0.305 |  Val. Acc: 87.78% | B. Val. Loss: 0.305 |  B. Val. Acc: 87.78%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.61s | lr: 1.79e-04 | Val. Loss: 0.279 |  Val. Acc: 88.22% | B. Val. Loss: 0.279 |  B. Val. Acc: 88.22%\n",
      "Epoch: 002 | ET: 47.43s | \t Train Loss: 0.300 | Train Acc: 88.34% \t Val. Loss: 0.316 |  Val. Acc: 88.66% \t | B. Val. Loss: 0.279 |  B. Val. Acc: 88.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.49s | lr: 2.23e-04 | Val. Loss: 0.321 |  Val. Acc: 89.38% | B. Val. Loss: 0.279 |  B. Val. Acc: 89.38%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.04s | lr: 2.48e-04 | Val. Loss: 0.420 |  Val. Acc: 79.11% | B. Val. Loss: 0.279 |  B. Val. Acc: 89.38%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.41s | lr: 2.74e-04 | Val. Loss: 0.429 |  Val. Acc: 81.48% | B. Val. Loss: 0.279 |  B. Val. Acc: 89.38%\n",
      "Epoch: 003 | ET: 47.02s | \t Train Loss: 0.233 | Train Acc: 90.60% \t Val. Loss: 0.249 |  Val. Acc: 90.16% \t | B. Val. Loss: 0.249 |  B. Val. Acc: 90.16%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.50s | lr: 3.26e-04 | Val. Loss: 0.230 |  Val. Acc: 90.94% | B. Val. Loss: 0.230 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.05s | lr: 3.52e-04 | Val. Loss: 0.235 |  Val. Acc: 90.55% | B. Val. Loss: 0.230 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.42s | lr: 3.77e-04 | Val. Loss: 0.231 |  Val. Acc: 90.50% | B. Val. Loss: 0.230 |  B. Val. Acc: 90.94%\n",
      "Epoch: 004 | ET: 46.90s | \t Train Loss: 0.252 | Train Acc: 90.66% \t Val. Loss: 0.267 |  Val. Acc: 90.40% \t | B. Val. Loss: 0.230 |  B. Val. Acc: 90.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.56s | lr: 4.22e-04 | Val. Loss: 0.209 |  Val. Acc: 91.23% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.14s | lr: 4.42e-04 | Val. Loss: 0.232 |  Val. Acc: 90.64% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.50s | lr: 4.59e-04 | Val. Loss: 0.250 |  Val. Acc: 89.05% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "Epoch: 005 | ET: 46.84s | \t Train Loss: 0.198 | Train Acc: 91.14% \t Val. Loss: 0.213 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.210 |  Val. Acc: 90.89% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.84s | lr: 4.93e-04 | Val. Loss: 0.222 |  Val. Acc: 90.69% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.22s | lr: 4.98e-04 | Val. Loss: 0.218 |  Val. Acc: 90.69% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "Epoch: 006 | ET: 46.58s | \t Train Loss: 0.188 | Train Acc: 91.77% \t Val. Loss: 0.209 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.207 |  Val. Acc: 91.13% | B. Val. Loss: 0.207 |  B. Val. Acc: 91.23%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.85s | lr: 4.98e-04 | Val. Loss: 0.221 |  Val. Acc: 91.08% | B. Val. Loss: 0.207 |  B. Val. Acc: 91.23%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.23s | lr: 4.96e-04 | Val. Loss: 0.233 |  Val. Acc: 89.72% | B. Val. Loss: 0.207 |  B. Val. Acc: 91.23%\n",
      "Epoch: 007 | ET: 46.60s | \t Train Loss: 0.178 | Train Acc: 92.05% \t Val. Loss: 0.205 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.205 |  B. Val. Acc: 91.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.214 |  Val. Acc: 91.37% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.03s | lr: 4.86e-04 | Val. Loss: 0.266 |  Val. Acc: 90.35% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.39s | lr: 4.81e-04 | Val. Loss: 0.223 |  Val. Acc: 90.40% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.37%\n",
      "Epoch: 008 | ET: 46.72s | \t Train Loss: 0.239 | Train Acc: 88.89% \t Val. Loss: 0.263 |  Val. Acc: 87.20% \t | B. Val. Loss: 0.205 |  B. Val. Acc: 91.37%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.50s | lr: 4.69e-04 | Val. Loss: 0.221 |  Val. Acc: 90.31% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.85s | lr: 4.62e-04 | Val. Loss: 0.241 |  Val. Acc: 91.37% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.21s | lr: 4.55e-04 | Val. Loss: 0.222 |  Val. Acc: 91.42% | B. Val. Loss: 0.205 |  B. Val. Acc: 91.42%\n",
      "Epoch: 009 | ET: 46.72s | \t Train Loss: 0.174 | Train Acc: 92.63% \t Val. Loss: 0.206 |  Val. Acc: 90.50% \t | B. Val. Loss: 0.205 |  B. Val. Acc: 91.42%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.56s | lr: 4.38e-04 | Val. Loss: 0.201 |  Val. Acc: 91.23% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.90s | lr: 4.28e-04 | Val. Loss: 0.227 |  Val. Acc: 90.89% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.25s | lr: 4.18e-04 | Val. Loss: 0.225 |  Val. Acc: 91.03% | B. Val. Loss: 0.201 |  B. Val. Acc: 91.42%\n",
      "Epoch: 010 | ET: 46.54s | \t Train Loss: 0.230 | Train Acc: 91.09% \t Val. Loss: 0.275 |  Val. Acc: 90.06% \t | B. Val. Loss: 0.201 |  B. Val. Acc: 91.42%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.47s | lr: 3.97e-04 | Val. Loss: 0.199 |  Val. Acc: 91.57% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.57%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.02s | lr: 3.85e-04 | Val. Loss: 0.204 |  Val. Acc: 90.79% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.57%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.37s | lr: 3.73e-04 | Val. Loss: 0.205 |  Val. Acc: 91.13% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.57%\n",
      "Epoch: 011 | ET: 46.67s | \t Train Loss: 0.167 | Train Acc: 93.00% \t Val. Loss: 0.224 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 91.57%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.47s | lr: 3.49e-04 | Val. Loss: 0.209 |  Val. Acc: 91.42% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.57%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.80s | lr: 3.36e-04 | Val. Loss: 0.203 |  Val. Acc: 91.66% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.33s | lr: 3.23e-04 | Val. Loss: 0.213 |  Val. Acc: 91.57% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.66%\n",
      "Epoch: 012 | ET: 46.66s | \t Train Loss: 0.168 | Train Acc: 92.78% \t Val. Loss: 0.202 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 91.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.201 |  Val. Acc: 91.76% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 14.02s | lr: 2.82e-04 | Val. Loss: 0.216 |  Val. Acc: 91.61% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.39s | lr: 2.68e-04 | Val. Loss: 0.208 |  Val. Acc: 91.37% | B. Val. Loss: 0.199 |  B. Val. Acc: 91.76%\n",
      "Epoch: 013 | ET: 46.68s | \t Train Loss: 0.153 | Train Acc: 93.46% \t Val. Loss: 0.195 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.76%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.49s | lr: 2.41e-04 | Val. Loss: 0.208 |  Val. Acc: 90.98% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.84s | lr: 2.27e-04 | Val. Loss: 0.222 |  Val. Acc: 90.55% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.19s | lr: 2.14e-04 | Val. Loss: 0.206 |  Val. Acc: 91.37% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.76%\n",
      "Epoch: 014 | ET: 46.46s | \t Train Loss: 0.146 | Train Acc: 93.60% \t Val. Loss: 0.194 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 91.76%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.47s | lr: 1.87e-04 | Val. Loss: 0.207 |  Val. Acc: 91.66% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.91s | lr: 1.74e-04 | Val. Loss: 0.206 |  Val. Acc: 90.94% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.25s | lr: 1.61e-04 | Val. Loss: 0.198 |  Val. Acc: 91.57% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.76%\n",
      "Epoch: 015 | ET: 46.52s | \t Train Loss: 0.137 | Train Acc: 94.21% \t Val. Loss: 0.198 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 91.76%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.47s | lr: 1.36e-04 | Val. Loss: 0.201 |  Val. Acc: 91.86% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 14.00s | lr: 1.24e-04 | Val. Loss: 0.209 |  Val. Acc: 90.84% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.36s | lr: 1.13e-04 | Val. Loss: 0.216 |  Val. Acc: 91.42% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.86%\n",
      "Epoch: 016 | ET: 46.65s | \t Train Loss: 0.126 | Train Acc: 95.06% \t Val. Loss: 0.207 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 91.86%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.48s | lr: 9.17e-05 | Val. Loss: 0.206 |  Val. Acc: 91.95% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 14.03s | lr: 8.16e-05 | Val. Loss: 0.222 |  Val. Acc: 91.52% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.38s | lr: 7.21e-05 | Val. Loss: 0.235 |  Val. Acc: 89.92% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "Epoch: 017 | ET: 46.72s | \t Train Loss: 0.114 | Train Acc: 95.35% \t Val. Loss: 0.207 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.216 |  Val. Acc: 91.27% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.83s | lr: 4.74e-05 | Val. Loss: 0.218 |  Val. Acc: 91.52% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.19s | lr: 4.04e-05 | Val. Loss: 0.223 |  Val. Acc: 91.71% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.95%\n",
      "Epoch: 018 | ET: 46.66s | \t Train Loss: 0.107 | Train Acc: 95.75% \t Val. Loss: 0.212 |  Val. Acc: 92.29% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.213 |  Val. Acc: 91.95% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.84s | lr: 2.37e-05 | Val. Loss: 0.224 |  Val. Acc: 91.08% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.19s | lr: 1.95e-05 | Val. Loss: 0.223 |  Val. Acc: 91.90% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "Epoch: 019 | ET: 46.47s | \t Train Loss: 0.098 | Train Acc: 96.09% \t Val. Loss: 0.226 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.47s | lr: 1.34e-05 | Val. Loss: 0.215 |  Val. Acc: 91.76% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.83s | lr: 1.15e-05 | Val. Loss: 0.223 |  Val. Acc: 91.86% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.18s | lr: 1.04e-05 | Val. Loss: 0.226 |  Val. Acc: 91.61% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "Epoch: 020 | ET: 46.46s | \t Train Loss: 0.098 | Train Acc: 96.09% \t Val. Loss: 0.229 |  Val. Acc: 91.76% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    2    2    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.430 |  Val. Acc: 79.93% | B. Val. Loss: 0.430 |  B. Val. Acc: 79.93%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.94s | lr: 1.07e-04 | Val. Loss: 0.445 |  Val. Acc: 79.88% | B. Val. Loss: 0.430 |  B. Val. Acc: 79.93%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.30s | lr: 1.15e-04 | Val. Loss: 0.383 |  Val. Acc: 84.15% | B. Val. Loss: 0.383 |  B. Val. Acc: 84.15%\n",
      "Epoch: 001 | ET: 47.09s | \t Train Loss: 0.351 | Train Acc: 84.39% \t Val. Loss: 0.349 |  Val. Acc: 84.78% \t | B. Val. Loss: 0.349 |  B. Val. Acc: 84.78%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.333 |  Val. Acc: 86.19% | B. Val. Loss: 0.333 |  B. Val. Acc: 86.19%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.00s | lr: 1.59e-04 | Val. Loss: 0.555 |  Val. Acc: 76.15% | B. Val. Loss: 0.333 |  B. Val. Acc: 86.19%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.40s | lr: 1.79e-04 | Val. Loss: 0.324 |  Val. Acc: 85.46% | B. Val. Loss: 0.324 |  B. Val. Acc: 86.19%\n",
      "Epoch: 002 | ET: 46.98s | \t Train Loss: 0.252 | Train Acc: 89.33% \t Val. Loss: 0.267 |  Val. Acc: 88.27% \t | B. Val. Loss: 0.267 |  B. Val. Acc: 88.27%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.275 |  Val. Acc: 89.77% | B. Val. Loss: 0.267 |  B. Val. Acc: 89.77%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.04s | lr: 2.48e-04 | Val. Loss: 0.403 |  Val. Acc: 82.02% | B. Val. Loss: 0.267 |  B. Val. Acc: 89.77%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.41s | lr: 2.74e-04 | Val. Loss: 0.253 |  Val. Acc: 88.80% | B. Val. Loss: 0.253 |  B. Val. Acc: 89.77%\n",
      "Epoch: 003 | ET: 47.06s | \t Train Loss: 0.244 | Train Acc: 90.34% \t Val. Loss: 0.272 |  Val. Acc: 89.87% \t | B. Val. Loss: 0.253 |  B. Val. Acc: 89.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.48s | lr: 3.26e-04 | Val. Loss: 0.240 |  Val. Acc: 90.60% | B. Val. Loss: 0.240 |  B. Val. Acc: 90.60%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.02s | lr: 3.52e-04 | Val. Loss: 0.338 |  Val. Acc: 87.69% | B. Val. Loss: 0.240 |  B. Val. Acc: 90.60%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.40s | lr: 3.77e-04 | Val. Loss: 0.245 |  Val. Acc: 90.45% | B. Val. Loss: 0.240 |  B. Val. Acc: 90.60%\n",
      "Epoch: 004 | ET: 46.84s | \t Train Loss: 0.219 | Train Acc: 90.78% \t Val. Loss: 0.232 |  Val. Acc: 90.26% \t | B. Val. Loss: 0.232 |  B. Val. Acc: 90.60%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.228 |  Val. Acc: 91.37% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.06s | lr: 4.42e-04 | Val. Loss: 0.244 |  Val. Acc: 90.69% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.43s | lr: 4.59e-04 | Val. Loss: 0.247 |  Val. Acc: 88.32% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "Epoch: 005 | ET: 46.87s | \t Train Loss: 0.211 | Train Acc: 91.40% \t Val. Loss: 0.239 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.236 |  Val. Acc: 91.23% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.89s | lr: 4.93e-04 | Val. Loss: 0.325 |  Val. Acc: 85.17% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.27s | lr: 4.98e-04 | Val. Loss: 0.256 |  Val. Acc: 90.69% | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "Epoch: 006 | ET: 46.65s | \t Train Loss: 0.246 | Train Acc: 89.19% \t Val. Loss: 0.253 |  Val. Acc: 89.48% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 91.37%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.220 |  Val. Acc: 90.84% | B. Val. Loss: 0.220 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.85s | lr: 4.98e-04 | Val. Loss: 0.230 |  Val. Acc: 91.18% | B. Val. Loss: 0.220 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.22s | lr: 4.96e-04 | Val. Loss: 0.229 |  Val. Acc: 90.50% | B. Val. Loss: 0.220 |  B. Val. Acc: 91.37%\n",
      "Epoch: 007 | ET: 46.58s | \t Train Loss: 0.187 | Train Acc: 92.26% \t Val. Loss: 0.230 |  Val. Acc: 91.08% \t | B. Val. Loss: 0.220 |  B. Val. Acc: 91.37%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.225 |  Val. Acc: 90.31% | B. Val. Loss: 0.220 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.84s | lr: 4.86e-04 | Val. Loss: 0.209 |  Val. Acc: 91.37% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.20s | lr: 4.81e-04 | Val. Loss: 0.238 |  Val. Acc: 91.13% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.37%\n",
      "Epoch: 008 | ET: 46.73s | \t Train Loss: 0.189 | Train Acc: 91.49% \t Val. Loss: 0.209 |  Val. Acc: 91.52% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.52%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.48s | lr: 4.69e-04 | Val. Loss: 0.225 |  Val. Acc: 90.50% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.84s | lr: 4.62e-04 | Val. Loss: 0.216 |  Val. Acc: 91.37% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.19s | lr: 4.55e-04 | Val. Loss: 0.224 |  Val. Acc: 90.84% | B. Val. Loss: 0.209 |  B. Val. Acc: 91.52%\n",
      "Epoch: 009 | ET: 46.75s | \t Train Loss: 0.182 | Train Acc: 92.22% \t Val. Loss: 0.219 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 91.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.204 |  Val. Acc: 91.23% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.84s | lr: 4.28e-04 | Val. Loss: 0.212 |  Val. Acc: 90.55% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.19s | lr: 4.18e-04 | Val. Loss: 0.205 |  Val. Acc: 91.90% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.90%\n",
      "Epoch: 010 | ET: 46.67s | \t Train Loss: 0.183 | Train Acc: 92.54% \t Val. Loss: 0.222 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.47s | lr: 3.97e-04 | Val. Loss: 0.207 |  Val. Acc: 91.95% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.10s | lr: 3.85e-04 | Val. Loss: 0.202 |  Val. Acc: 92.00% | B. Val. Loss: 0.202 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.65s | lr: 3.73e-04 | Val. Loss: 0.200 |  Val. Acc: 91.57% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "Epoch: 011 | ET: 46.96s | \t Train Loss: 0.170 | Train Acc: 92.74% \t Val. Loss: 0.214 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.209 |  Val. Acc: 91.13% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.82s | lr: 3.36e-04 | Val. Loss: 0.252 |  Val. Acc: 90.60% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.18s | lr: 3.23e-04 | Val. Loss: 0.244 |  Val. Acc: 91.47% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "Epoch: 012 | ET: 46.49s | \t Train Loss: 0.174 | Train Acc: 92.44% \t Val. Loss: 0.210 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.211 |  Val. Acc: 91.52% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.83s | lr: 2.82e-04 | Val. Loss: 0.211 |  Val. Acc: 91.23% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.19s | lr: 2.68e-04 | Val. Loss: 0.201 |  Val. Acc: 91.90% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "Epoch: 013 | ET: 46.55s | \t Train Loss: 0.161 | Train Acc: 93.38% \t Val. Loss: 0.204 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.206 |  Val. Acc: 91.32% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.84s | lr: 2.27e-04 | Val. Loss: 0.202 |  Val. Acc: 91.81% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.21s | lr: 2.14e-04 | Val. Loss: 0.222 |  Val. Acc: 90.94% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.00%\n",
      "Epoch: 014 | ET: 46.79s | \t Train Loss: 0.151 | Train Acc: 93.76% \t Val. Loss: 0.208 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.200 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.50s | lr: 1.87e-04 | Val. Loss: 0.203 |  Val. Acc: 91.76% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.87s | lr: 1.74e-04 | Val. Loss: 0.201 |  Val. Acc: 91.66% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.22s | lr: 1.61e-04 | Val. Loss: 0.205 |  Val. Acc: 92.05% | B. Val. Loss: 0.200 |  B. Val. Acc: 92.10%\n",
      "Epoch: 015 | ET: 46.55s | \t Train Loss: 0.142 | Train Acc: 94.32% \t Val. Loss: 0.199 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.209 |  Val. Acc: 91.37% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.86s | lr: 1.24e-04 | Val. Loss: 0.231 |  Val. Acc: 90.16% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.21s | lr: 1.13e-04 | Val. Loss: 0.214 |  Val. Acc: 91.71% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "Epoch: 016 | ET: 46.62s | \t Train Loss: 0.133 | Train Acc: 94.60% \t Val. Loss: 0.199 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.48s | lr: 9.17e-05 | Val. Loss: 0.215 |  Val. Acc: 91.18% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.83s | lr: 8.16e-05 | Val. Loss: 0.204 |  Val. Acc: 91.52% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.20s | lr: 7.21e-05 | Val. Loss: 0.202 |  Val. Acc: 91.66% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "Epoch: 017 | ET: 46.53s | \t Train Loss: 0.125 | Train Acc: 95.12% \t Val. Loss: 0.210 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.211 |  Val. Acc: 92.05% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.83s | lr: 4.74e-05 | Val. Loss: 0.214 |  Val. Acc: 91.66% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.19s | lr: 4.04e-05 | Val. Loss: 0.233 |  Val. Acc: 91.13% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.10%\n",
      "Epoch: 018 | ET: 46.78s | \t Train Loss: 0.116 | Train Acc: 95.32% \t Val. Loss: 0.213 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.50s | lr: 2.86e-05 | Val. Loss: 0.216 |  Val. Acc: 92.24% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 14.07s | lr: 2.37e-05 | Val. Loss: 0.218 |  Val. Acc: 91.81% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.43s | lr: 1.95e-05 | Val. Loss: 0.220 |  Val. Acc: 91.71% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "Epoch: 019 | ET: 46.83s | \t Train Loss: 0.110 | Train Acc: 95.44% \t Val. Loss: 0.217 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.50s | lr: 1.34e-05 | Val. Loss: 0.219 |  Val. Acc: 91.37% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.87s | lr: 1.15e-05 | Val. Loss: 0.221 |  Val. Acc: 91.52% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.23s | lr: 1.04e-05 | Val. Loss: 0.221 |  Val. Acc: 91.76% | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "Epoch: 020 | ET: 46.59s | \t Train Loss: 0.109 | Train Acc: 95.64% \t Val. Loss: 0.226 |  Val. Acc: 91.86% \t | B. Val. Loss: 0.199 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    2    3    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.50s | lr: 1.02e-04 | Val. Loss: 0.450 |  Val. Acc: 77.12% | B. Val. Loss: 0.450 |  B. Val. Acc: 77.12%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.94s | lr: 1.07e-04 | Val. Loss: 0.487 |  Val. Acc: 79.64% | B. Val. Loss: 0.450 |  B. Val. Acc: 79.64%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.55s | lr: 1.15e-04 | Val. Loss: 0.363 |  Val. Acc: 84.59% | B. Val. Loss: 0.363 |  B. Val. Acc: 84.59%\n",
      "Epoch: 001 | ET: 47.26s | \t Train Loss: 0.334 | Train Acc: 85.68% \t Val. Loss: 0.334 |  Val. Acc: 85.46% \t | B. Val. Loss: 0.334 |  B. Val. Acc: 85.46%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.59s | lr: 1.41e-04 | Val. Loss: 0.308 |  Val. Acc: 87.06% | B. Val. Loss: 0.308 |  B. Val. Acc: 87.06%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.19s | lr: 1.59e-04 | Val. Loss: 0.343 |  Val. Acc: 84.44% | B. Val. Loss: 0.308 |  B. Val. Acc: 87.06%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.55s | lr: 1.79e-04 | Val. Loss: 0.338 |  Val. Acc: 84.59% | B. Val. Loss: 0.308 |  B. Val. Acc: 87.06%\n",
      "Epoch: 002 | ET: 47.02s | \t Train Loss: 0.311 | Train Acc: 87.16% \t Val. Loss: 0.295 |  Val. Acc: 88.41% \t | B. Val. Loss: 0.295 |  B. Val. Acc: 88.41%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.49s | lr: 2.23e-04 | Val. Loss: 0.251 |  Val. Acc: 89.97% | B. Val. Loss: 0.251 |  B. Val. Acc: 89.97%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.03s | lr: 2.48e-04 | Val. Loss: 0.313 |  Val. Acc: 89.38% | B. Val. Loss: 0.251 |  B. Val. Acc: 89.97%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.39s | lr: 2.74e-04 | Val. Loss: 0.341 |  Val. Acc: 86.19% | B. Val. Loss: 0.251 |  B. Val. Acc: 89.97%\n",
      "Epoch: 003 | ET: 46.75s | \t Train Loss: 0.282 | Train Acc: 89.22% \t Val. Loss: 0.279 |  Val. Acc: 88.95% \t | B. Val. Loss: 0.251 |  B. Val. Acc: 89.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.48s | lr: 3.26e-04 | Val. Loss: 0.235 |  Val. Acc: 90.69% | B. Val. Loss: 0.235 |  B. Val. Acc: 90.69%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.05s | lr: 3.52e-04 | Val. Loss: 0.273 |  Val. Acc: 88.56% | B. Val. Loss: 0.235 |  B. Val. Acc: 90.69%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.42s | lr: 3.77e-04 | Val. Loss: 0.261 |  Val. Acc: 90.31% | B. Val. Loss: 0.235 |  B. Val. Acc: 90.69%\n",
      "Epoch: 004 | ET: 46.75s | \t Train Loss: 0.237 | Train Acc: 89.97% \t Val. Loss: 0.243 |  Val. Acc: 89.82% \t | B. Val. Loss: 0.235 |  B. Val. Acc: 90.69%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.209 |  Val. Acc: 90.94% | B. Val. Loss: 0.209 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.04s | lr: 4.42e-04 | Val. Loss: 0.325 |  Val. Acc: 87.74% | B. Val. Loss: 0.209 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.43s | lr: 4.59e-04 | Val. Loss: 0.227 |  Val. Acc: 90.55% | B. Val. Loss: 0.209 |  B. Val. Acc: 90.94%\n",
      "Epoch: 005 | ET: 46.83s | \t Train Loss: 0.217 | Train Acc: 91.07% \t Val. Loss: 0.240 |  Val. Acc: 90.50% \t | B. Val. Loss: 0.209 |  B. Val. Acc: 90.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.204 |  Val. Acc: 91.37% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.18s | lr: 4.93e-04 | Val. Loss: 0.237 |  Val. Acc: 90.94% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.37%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.56s | lr: 4.98e-04 | Val. Loss: 0.236 |  Val. Acc: 89.00% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.37%\n",
      "Epoch: 006 | ET: 46.86s | \t Train Loss: 0.184 | Train Acc: 92.34% \t Val. Loss: 0.208 |  Val. Acc: 90.69% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 91.37%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.210 |  Val. Acc: 91.52% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.02s | lr: 4.98e-04 | Val. Loss: 0.249 |  Val. Acc: 89.29% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.40s | lr: 4.96e-04 | Val. Loss: 0.233 |  Val. Acc: 89.09% | B. Val. Loss: 0.204 |  B. Val. Acc: 91.52%\n",
      "Epoch: 007 | ET: 46.71s | \t Train Loss: 0.172 | Train Acc: 92.52% \t Val. Loss: 0.204 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 91.52%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.49s | lr: 4.90e-04 | Val. Loss: 0.202 |  Val. Acc: 91.32% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.86s | lr: 4.86e-04 | Val. Loss: 0.217 |  Val. Acc: 91.18% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.22s | lr: 4.81e-04 | Val. Loss: 0.224 |  Val. Acc: 91.27% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.52%\n",
      "Epoch: 008 | ET: 46.54s | \t Train Loss: 0.209 | Train Acc: 92.31% \t Val. Loss: 0.230 |  Val. Acc: 90.35% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 91.52%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.217 |  Val. Acc: 90.01% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.85s | lr: 4.62e-04 | Val. Loss: 0.213 |  Val. Acc: 91.27% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.52%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.20s | lr: 4.55e-04 | Val. Loss: 0.209 |  Val. Acc: 91.86% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "Epoch: 009 | ET: 46.67s | \t Train Loss: 0.180 | Train Acc: 92.77% \t Val. Loss: 0.209 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.207 |  Val. Acc: 91.81% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.84s | lr: 4.28e-04 | Val. Loss: 0.206 |  Val. Acc: 91.57% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.19s | lr: 4.18e-04 | Val. Loss: 0.251 |  Val. Acc: 89.68% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "Epoch: 010 | ET: 46.49s | \t Train Loss: 0.166 | Train Acc: 93.17% \t Val. Loss: 0.207 |  Val. Acc: 91.52% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.48s | lr: 3.97e-04 | Val. Loss: 0.205 |  Val. Acc: 90.94% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.84s | lr: 3.85e-04 | Val. Loss: 0.216 |  Val. Acc: 91.90% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.42s | lr: 3.73e-04 | Val. Loss: 0.205 |  Val. Acc: 91.90% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.90%\n",
      "Epoch: 011 | ET: 46.84s | \t Train Loss: 0.154 | Train Acc: 93.51% \t Val. Loss: 0.218 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.198 |  Val. Acc: 91.27% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.84s | lr: 3.36e-04 | Val. Loss: 0.232 |  Val. Acc: 91.95% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.41s | lr: 3.23e-04 | Val. Loss: 0.203 |  Val. Acc: 91.66% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.95%\n",
      "Epoch: 012 | ET: 46.89s | \t Train Loss: 0.150 | Train Acc: 93.95% \t Val. Loss: 0.197 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.197 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.203 |  Val. Acc: 91.32% | B. Val. Loss: 0.197 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.84s | lr: 2.82e-04 | Val. Loss: 0.231 |  Val. Acc: 91.47% | B. Val. Loss: 0.197 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.19s | lr: 2.68e-04 | Val. Loss: 0.207 |  Val. Acc: 92.20% | B. Val. Loss: 0.197 |  B. Val. Acc: 92.20%\n",
      "Epoch: 013 | ET: 46.71s | \t Train Loss: 0.149 | Train Acc: 93.75% \t Val. Loss: 0.194 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.49s | lr: 2.41e-04 | Val. Loss: 0.200 |  Val. Acc: 91.61% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.84s | lr: 2.27e-04 | Val. Loss: 0.221 |  Val. Acc: 91.47% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.19s | lr: 2.14e-04 | Val. Loss: 0.204 |  Val. Acc: 91.76% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "Epoch: 014 | ET: 46.47s | \t Train Loss: 0.158 | Train Acc: 93.40% \t Val. Loss: 0.229 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.208 |  Val. Acc: 91.61% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.83s | lr: 1.74e-04 | Val. Loss: 0.207 |  Val. Acc: 91.61% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.17s | lr: 1.61e-04 | Val. Loss: 0.200 |  Val. Acc: 92.24% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "Epoch: 015 | ET: 46.70s | \t Train Loss: 0.141 | Train Acc: 94.34% \t Val. Loss: 0.205 |  Val. Acc: 91.42% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.196 |  Val. Acc: 92.05% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.83s | lr: 1.24e-04 | Val. Loss: 0.199 |  Val. Acc: 91.95% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.17s | lr: 1.13e-04 | Val. Loss: 0.243 |  Val. Acc: 91.76% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "Epoch: 016 | ET: 46.48s | \t Train Loss: 0.149 | Train Acc: 93.80% \t Val. Loss: 0.241 |  Val. Acc: 90.06% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.56s | lr: 9.17e-05 | Val. Loss: 0.202 |  Val. Acc: 91.81% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.90s | lr: 8.16e-05 | Val. Loss: 0.211 |  Val. Acc: 91.90% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.26s | lr: 7.21e-05 | Val. Loss: 0.217 |  Val. Acc: 91.66% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "Epoch: 017 | ET: 46.58s | \t Train Loss: 0.128 | Train Acc: 94.66% \t Val. Loss: 0.207 |  Val. Acc: 91.52% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.207 |  Val. Acc: 92.10% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.85s | lr: 4.74e-05 | Val. Loss: 0.223 |  Val. Acc: 92.00% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.20s | lr: 4.04e-05 | Val. Loss: 0.222 |  Val. Acc: 91.86% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "Epoch: 018 | ET: 46.53s | \t Train Loss: 0.113 | Train Acc: 95.70% \t Val. Loss: 0.217 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.218 |  Val. Acc: 92.00% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.87s | lr: 2.37e-05 | Val. Loss: 0.219 |  Val. Acc: 91.71% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.23s | lr: 1.95e-05 | Val. Loss: 0.223 |  Val. Acc: 92.05% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "Epoch: 019 | ET: 46.57s | \t Train Loss: 0.105 | Train Acc: 95.76% \t Val. Loss: 0.220 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.50s | lr: 1.34e-05 | Val. Loss: 0.217 |  Val. Acc: 91.66% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.87s | lr: 1.15e-05 | Val. Loss: 0.232 |  Val. Acc: 91.47% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.24s | lr: 1.04e-05 | Val. Loss: 0.233 |  Val. Acc: 91.57% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "Epoch: 020 | ET: 46.58s | \t Train Loss: 0.102 | Train Acc: 95.78% \t Val. Loss: 0.228 |  Val. Acc: 91.42% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    2    4    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.435 |  Val. Acc: 79.16% | B. Val. Loss: 0.435 |  B. Val. Acc: 79.16%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.95s | lr: 1.07e-04 | Val. Loss: 0.418 |  Val. Acc: 80.71% | B. Val. Loss: 0.418 |  B. Val. Acc: 80.71%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.51s | lr: 1.15e-04 | Val. Loss: 0.369 |  Val. Acc: 83.71% | B. Val. Loss: 0.369 |  B. Val. Acc: 83.71%\n",
      "Epoch: 001 | ET: 47.30s | \t Train Loss: 0.319 | Train Acc: 85.94% \t Val. Loss: 0.318 |  Val. Acc: 86.23% \t | B. Val. Loss: 0.318 |  B. Val. Acc: 86.23%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.319 |  Val. Acc: 87.49% | B. Val. Loss: 0.318 |  B. Val. Acc: 87.49%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.13s | lr: 1.59e-04 | Val. Loss: 0.301 |  Val. Acc: 87.59% | B. Val. Loss: 0.301 |  B. Val. Acc: 87.59%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.69s | lr: 1.79e-04 | Val. Loss: 0.356 |  Val. Acc: 83.28% | B. Val. Loss: 0.301 |  B. Val. Acc: 87.59%\n",
      "Epoch: 002 | ET: 47.14s | \t Train Loss: 0.255 | Train Acc: 89.52% \t Val. Loss: 0.265 |  Val. Acc: 89.38% \t | B. Val. Loss: 0.265 |  B. Val. Acc: 89.38%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.47s | lr: 2.23e-04 | Val. Loss: 0.250 |  Val. Acc: 90.31% | B. Val. Loss: 0.250 |  B. Val. Acc: 90.31%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.03s | lr: 2.48e-04 | Val. Loss: 0.273 |  Val. Acc: 89.77% | B. Val. Loss: 0.250 |  B. Val. Acc: 90.31%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.41s | lr: 2.74e-04 | Val. Loss: 0.265 |  Val. Acc: 90.31% | B. Val. Loss: 0.250 |  B. Val. Acc: 90.31%\n",
      "Epoch: 003 | ET: 46.76s | \t Train Loss: 0.217 | Train Acc: 90.91% \t Val. Loss: 0.237 |  Val. Acc: 90.31% \t | B. Val. Loss: 0.237 |  B. Val. Acc: 90.31%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.49s | lr: 3.26e-04 | Val. Loss: 0.235 |  Val. Acc: 90.60% | B. Val. Loss: 0.235 |  B. Val. Acc: 90.60%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.04s | lr: 3.52e-04 | Val. Loss: 0.252 |  Val. Acc: 89.43% | B. Val. Loss: 0.235 |  B. Val. Acc: 90.60%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.43s | lr: 3.77e-04 | Val. Loss: 0.235 |  Val. Acc: 90.16% | B. Val. Loss: 0.235 |  B. Val. Acc: 90.60%\n",
      "Epoch: 004 | ET: 46.97s | \t Train Loss: 0.196 | Train Acc: 91.98% \t Val. Loss: 0.221 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.221 |  B. Val. Acc: 90.98%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.51s | lr: 4.22e-04 | Val. Loss: 0.231 |  Val. Acc: 90.74% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.87s | lr: 4.42e-04 | Val. Loss: 0.225 |  Val. Acc: 90.69% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.24s | lr: 4.59e-04 | Val. Loss: 0.229 |  Val. Acc: 90.74% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.98%\n",
      "Epoch: 005 | ET: 46.57s | \t Train Loss: 0.279 | Train Acc: 89.97% \t Val. Loss: 0.289 |  Val. Acc: 89.24% \t | B. Val. Loss: 0.221 |  B. Val. Acc: 90.98%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.50s | lr: 4.85e-04 | Val. Loss: 0.210 |  Val. Acc: 91.08% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.08%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.07s | lr: 4.93e-04 | Val. Loss: 0.261 |  Val. Acc: 90.94% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.08%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.45s | lr: 4.98e-04 | Val. Loss: 0.228 |  Val. Acc: 90.55% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.08%\n",
      "Epoch: 006 | ET: 46.80s | \t Train Loss: 0.244 | Train Acc: 91.11% \t Val. Loss: 0.286 |  Val. Acc: 89.63% \t | B. Val. Loss: 0.210 |  B. Val. Acc: 91.08%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.57s | lr: 5.00e-04 | Val. Loss: 0.227 |  Val. Acc: 90.74% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.08%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.95s | lr: 4.98e-04 | Val. Loss: 0.231 |  Val. Acc: 90.64% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.08%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.33s | lr: 4.96e-04 | Val. Loss: 0.215 |  Val. Acc: 91.18% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.18%\n",
      "Epoch: 007 | ET: 46.83s | \t Train Loss: 0.189 | Train Acc: 92.10% \t Val. Loss: 0.222 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.210 |  B. Val. Acc: 91.18%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.49s | lr: 4.90e-04 | Val. Loss: 0.208 |  Val. Acc: 91.90% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.05s | lr: 4.86e-04 | Val. Loss: 0.288 |  Val. Acc: 89.05% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.43s | lr: 4.81e-04 | Val. Loss: 0.234 |  Val. Acc: 91.13% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.90%\n",
      "Epoch: 008 | ET: 46.81s | \t Train Loss: 0.173 | Train Acc: 92.55% \t Val. Loss: 0.212 |  Val. Acc: 91.76% \t | B. Val. Loss: 0.208 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.195 |  Val. Acc: 91.86% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.86s | lr: 4.62e-04 | Val. Loss: 0.236 |  Val. Acc: 91.52% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.24s | lr: 4.55e-04 | Val. Loss: 0.247 |  Val. Acc: 89.63% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "Epoch: 009 | ET: 46.58s | \t Train Loss: 0.182 | Train Acc: 92.09% \t Val. Loss: 0.212 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.50s | lr: 4.38e-04 | Val. Loss: 0.196 |  Val. Acc: 91.71% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.86s | lr: 4.28e-04 | Val. Loss: 0.202 |  Val. Acc: 91.37% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.24s | lr: 4.18e-04 | Val. Loss: 0.206 |  Val. Acc: 91.52% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "Epoch: 010 | ET: 46.59s | \t Train Loss: 0.172 | Train Acc: 92.58% \t Val. Loss: 0.200 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.202 |  Val. Acc: 91.03% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.88s | lr: 3.85e-04 | Val. Loss: 0.229 |  Val. Acc: 89.19% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.26s | lr: 3.73e-04 | Val. Loss: 0.208 |  Val. Acc: 90.79% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "Epoch: 011 | ET: 46.61s | \t Train Loss: 0.182 | Train Acc: 92.66% \t Val. Loss: 0.222 |  Val. Acc: 90.74% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.212 |  Val. Acc: 91.57% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.86s | lr: 3.36e-04 | Val. Loss: 0.199 |  Val. Acc: 91.71% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.24s | lr: 3.23e-04 | Val. Loss: 0.203 |  Val. Acc: 92.39% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.39%\n",
      "Epoch: 012 | ET: 46.84s | \t Train Loss: 0.175 | Train Acc: 92.84% \t Val. Loss: 0.209 |  Val. Acc: 90.69% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.202 |  Val. Acc: 91.18% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.82s | lr: 2.82e-04 | Val. Loss: 0.215 |  Val. Acc: 91.03% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.18s | lr: 2.68e-04 | Val. Loss: 0.201 |  Val. Acc: 92.10% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.39%\n",
      "Epoch: 013 | ET: 46.48s | \t Train Loss: 0.150 | Train Acc: 93.75% \t Val. Loss: 0.195 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.197 |  Val. Acc: 92.49% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 14.02s | lr: 2.27e-04 | Val. Loss: 0.204 |  Val. Acc: 92.44% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.39s | lr: 2.14e-04 | Val. Loss: 0.210 |  Val. Acc: 92.15% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "Epoch: 014 | ET: 46.71s | \t Train Loss: 0.146 | Train Acc: 93.76% \t Val. Loss: 0.203 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.49s | lr: 1.87e-04 | Val. Loss: 0.213 |  Val. Acc: 91.03% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.84s | lr: 1.74e-04 | Val. Loss: 0.210 |  Val. Acc: 91.32% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.22s | lr: 1.61e-04 | Val. Loss: 0.216 |  Val. Acc: 90.35% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "Epoch: 015 | ET: 46.54s | \t Train Loss: 0.145 | Train Acc: 93.37% \t Val. Loss: 0.200 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.198 |  Val. Acc: 92.63% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 14.05s | lr: 1.24e-04 | Val. Loss: 0.211 |  Val. Acc: 92.44% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.43s | lr: 1.13e-04 | Val. Loss: 0.198 |  Val. Acc: 91.81% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "Epoch: 016 | ET: 46.78s | \t Train Loss: 0.128 | Train Acc: 94.78% \t Val. Loss: 0.200 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.49s | lr: 9.17e-05 | Val. Loss: 0.196 |  Val. Acc: 92.20% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.86s | lr: 8.16e-05 | Val. Loss: 0.210 |  Val. Acc: 92.34% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.26s | lr: 7.21e-05 | Val. Loss: 0.199 |  Val. Acc: 92.05% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "Epoch: 017 | ET: 46.63s | \t Train Loss: 0.121 | Train Acc: 95.26% \t Val. Loss: 0.209 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.211 |  Val. Acc: 91.66% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.86s | lr: 4.74e-05 | Val. Loss: 0.225 |  Val. Acc: 92.54% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.32s | lr: 4.04e-05 | Val. Loss: 0.218 |  Val. Acc: 90.84% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "Epoch: 018 | ET: 46.66s | \t Train Loss: 0.111 | Train Acc: 95.86% \t Val. Loss: 0.220 |  Val. Acc: 92.34% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.206 |  Val. Acc: 92.00% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.87s | lr: 2.37e-05 | Val. Loss: 0.215 |  Val. Acc: 92.49% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.27s | lr: 1.95e-05 | Val. Loss: 0.221 |  Val. Acc: 92.00% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "Epoch: 019 | ET: 46.57s | \t Train Loss: 0.109 | Train Acc: 95.54% \t Val. Loss: 0.219 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.217 |  Val. Acc: 91.95% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.83s | lr: 1.15e-05 | Val. Loss: 0.219 |  Val. Acc: 92.00% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.21s | lr: 1.04e-05 | Val. Loss: 0.227 |  Val. Acc: 92.10% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "Epoch: 020 | ET: 46.53s | \t Train Loss: 0.101 | Train Acc: 96.10% \t Val. Loss: 0.218 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    3    0    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.51s | lr: 1.02e-04 | Val. Loss: 0.510 |  Val. Acc: 79.21% | B. Val. Loss: 0.510 |  B. Val. Acc: 79.21%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.97s | lr: 1.07e-04 | Val. Loss: 0.437 |  Val. Acc: 78.82% | B. Val. Loss: 0.437 |  B. Val. Acc: 79.21%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.32s | lr: 1.15e-04 | Val. Loss: 0.546 |  Val. Acc: 75.04% | B. Val. Loss: 0.437 |  B. Val. Acc: 79.21%\n",
      "Epoch: 001 | ET: 46.88s | \t Train Loss: 0.428 | Train Acc: 81.04% \t Val. Loss: 0.416 |  Val. Acc: 81.14% \t | B. Val. Loss: 0.416 |  B. Val. Acc: 81.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.367 |  Val. Acc: 84.05% | B. Val. Loss: 0.367 |  B. Val. Acc: 84.05%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.06s | lr: 1.59e-04 | Val. Loss: 0.396 |  Val. Acc: 81.73% | B. Val. Loss: 0.367 |  B. Val. Acc: 84.05%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.44s | lr: 1.79e-04 | Val. Loss: 0.346 |  Val. Acc: 85.17% | B. Val. Loss: 0.346 |  B. Val. Acc: 85.17%\n",
      "Epoch: 002 | ET: 47.23s | \t Train Loss: 0.321 | Train Acc: 85.96% \t Val. Loss: 0.313 |  Val. Acc: 87.01% \t | B. Val. Loss: 0.313 |  B. Val. Acc: 87.01%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.49s | lr: 2.23e-04 | Val. Loss: 0.297 |  Val. Acc: 88.41% | B. Val. Loss: 0.297 |  B. Val. Acc: 88.41%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.05s | lr: 2.48e-04 | Val. Loss: 0.331 |  Val. Acc: 86.72% | B. Val. Loss: 0.297 |  B. Val. Acc: 88.41%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.50s | lr: 2.74e-04 | Val. Loss: 0.275 |  Val. Acc: 88.95% | B. Val. Loss: 0.275 |  B. Val. Acc: 88.95%\n",
      "Epoch: 003 | ET: 47.23s | \t Train Loss: 0.261 | Train Acc: 89.72% \t Val. Loss: 0.270 |  Val. Acc: 89.92% \t | B. Val. Loss: 0.270 |  B. Val. Acc: 89.92%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.50s | lr: 3.26e-04 | Val. Loss: 0.258 |  Val. Acc: 90.55% | B. Val. Loss: 0.258 |  B. Val. Acc: 90.55%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.05s | lr: 3.52e-04 | Val. Loss: 0.255 |  Val. Acc: 90.16% | B. Val. Loss: 0.255 |  B. Val. Acc: 90.55%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.43s | lr: 3.77e-04 | Val. Loss: 0.236 |  Val. Acc: 90.69% | B. Val. Loss: 0.236 |  B. Val. Acc: 90.69%\n",
      "Epoch: 004 | ET: 46.95s | \t Train Loss: 0.257 | Train Acc: 89.51% \t Val. Loss: 0.261 |  Val. Acc: 88.80% \t | B. Val. Loss: 0.236 |  B. Val. Acc: 90.69%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.222 |  Val. Acc: 91.18% | B. Val. Loss: 0.222 |  B. Val. Acc: 91.18%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.07s | lr: 4.42e-04 | Val. Loss: 0.241 |  Val. Acc: 91.66% | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.67s | lr: 4.59e-04 | Val. Loss: 0.232 |  Val. Acc: 90.55% | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "Epoch: 005 | ET: 47.01s | \t Train Loss: 0.216 | Train Acc: 90.92% \t Val. Loss: 0.228 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.222 |  Val. Acc: 91.32% | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.86s | lr: 4.93e-04 | Val. Loss: 0.229 |  Val. Acc: 90.94% | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.22s | lr: 4.98e-04 | Val. Loss: 0.231 |  Val. Acc: 90.94% | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "Epoch: 006 | ET: 46.53s | \t Train Loss: 0.214 | Train Acc: 91.42% \t Val. Loss: 0.234 |  Val. Acc: 90.94% \t | B. Val. Loss: 0.222 |  B. Val. Acc: 91.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.203 |  Val. Acc: 90.89% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.87s | lr: 4.98e-04 | Val. Loss: 0.247 |  Val. Acc: 88.75% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.66%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.24s | lr: 4.96e-04 | Val. Loss: 0.203 |  Val. Acc: 91.71% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.71%\n",
      "Epoch: 007 | ET: 46.75s | \t Train Loss: 0.252 | Train Acc: 89.81% \t Val. Loss: 0.247 |  Val. Acc: 90.26% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.50s | lr: 4.90e-04 | Val. Loss: 0.203 |  Val. Acc: 91.23% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.88s | lr: 4.86e-04 | Val. Loss: 0.233 |  Val. Acc: 90.31% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.31s | lr: 4.81e-04 | Val. Loss: 0.293 |  Val. Acc: 90.16% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.71%\n",
      "Epoch: 008 | ET: 46.63s | \t Train Loss: 0.259 | Train Acc: 90.83% \t Val. Loss: 0.273 |  Val. Acc: 90.55% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.202 |  Val. Acc: 91.42% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.86s | lr: 4.62e-04 | Val. Loss: 0.295 |  Val. Acc: 89.82% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.21s | lr: 4.55e-04 | Val. Loss: 0.222 |  Val. Acc: 91.47% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "Epoch: 009 | ET: 46.53s | \t Train Loss: 0.193 | Train Acc: 92.35% \t Val. Loss: 0.205 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.212 |  Val. Acc: 90.79% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.85s | lr: 4.28e-04 | Val. Loss: 0.203 |  Val. Acc: 91.37% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.21s | lr: 4.18e-04 | Val. Loss: 0.235 |  Val. Acc: 90.11% | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "Epoch: 010 | ET: 46.54s | \t Train Loss: 0.181 | Train Acc: 92.16% \t Val. Loss: 0.207 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.202 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.49s | lr: 3.97e-04 | Val. Loss: 0.191 |  Val. Acc: 91.81% | B. Val. Loss: 0.191 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.05s | lr: 3.85e-04 | Val. Loss: 0.199 |  Val. Acc: 92.20% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.62s | lr: 3.73e-04 | Val. Loss: 0.190 |  Val. Acc: 92.00% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "Epoch: 011 | ET: 46.99s | \t Train Loss: 0.165 | Train Acc: 92.97% \t Val. Loss: 0.190 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.50s | lr: 3.49e-04 | Val. Loss: 0.203 |  Val. Acc: 91.81% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.89s | lr: 3.36e-04 | Val. Loss: 0.191 |  Val. Acc: 91.95% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.26s | lr: 3.23e-04 | Val. Loss: 0.193 |  Val. Acc: 91.95% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "Epoch: 012 | ET: 46.62s | \t Train Loss: 0.171 | Train Acc: 93.04% \t Val. Loss: 0.197 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.50s | lr: 2.96e-04 | Val. Loss: 0.191 |  Val. Acc: 92.00% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.89s | lr: 2.82e-04 | Val. Loss: 0.204 |  Val. Acc: 91.18% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.20%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.25s | lr: 2.68e-04 | Val. Loss: 0.185 |  Val. Acc: 92.49% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "Epoch: 013 | ET: 46.75s | \t Train Loss: 0.181 | Train Acc: 92.61% \t Val. Loss: 0.209 |  Val. Acc: 91.52% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.194 |  Val. Acc: 91.52% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.92s | lr: 2.27e-04 | Val. Loss: 0.201 |  Val. Acc: 91.18% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.27s | lr: 2.14e-04 | Val. Loss: 0.215 |  Val. Acc: 91.57% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "Epoch: 014 | ET: 46.57s | \t Train Loss: 0.165 | Train Acc: 93.20% \t Val. Loss: 0.196 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.190 |  Val. Acc: 91.76% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.85s | lr: 1.74e-04 | Val. Loss: 0.183 |  Val. Acc: 92.20% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.20s | lr: 1.61e-04 | Val. Loss: 0.198 |  Val. Acc: 92.05% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "Epoch: 015 | ET: 46.52s | \t Train Loss: 0.157 | Train Acc: 93.72% \t Val. Loss: 0.202 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.185 |  Val. Acc: 92.29% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.85s | lr: 1.24e-04 | Val. Loss: 0.188 |  Val. Acc: 92.20% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.20s | lr: 1.13e-04 | Val. Loss: 0.187 |  Val. Acc: 92.15% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "Epoch: 016 | ET: 46.49s | \t Train Loss: 0.138 | Train Acc: 94.41% \t Val. Loss: 0.197 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.49s | lr: 9.17e-05 | Val. Loss: 0.192 |  Val. Acc: 92.34% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.85s | lr: 8.16e-05 | Val. Loss: 0.192 |  Val. Acc: 91.81% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.21s | lr: 7.21e-05 | Val. Loss: 0.184 |  Val. Acc: 92.49% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "Epoch: 017 | ET: 46.49s | \t Train Loss: 0.126 | Train Acc: 95.02% \t Val. Loss: 0.196 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.47s | lr: 5.51e-05 | Val. Loss: 0.192 |  Val. Acc: 92.20% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.82s | lr: 4.74e-05 | Val. Loss: 0.228 |  Val. Acc: 91.76% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.16s | lr: 4.04e-05 | Val. Loss: 0.191 |  Val. Acc: 92.54% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "Epoch: 018 | ET: 46.67s | \t Train Loss: 0.119 | Train Acc: 95.25% \t Val. Loss: 0.195 |  Val. Acc: 92.34% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.194 |  Val. Acc: 92.29% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.85s | lr: 2.37e-05 | Val. Loss: 0.209 |  Val. Acc: 91.71% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.22s | lr: 1.95e-05 | Val. Loss: 0.203 |  Val. Acc: 92.05% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "Epoch: 019 | ET: 46.59s | \t Train Loss: 0.110 | Train Acc: 95.76% \t Val. Loss: 0.195 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.57s | lr: 1.34e-05 | Val. Loss: 0.196 |  Val. Acc: 92.05% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.96s | lr: 1.15e-05 | Val. Loss: 0.203 |  Val. Acc: 91.86% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.33s | lr: 1.04e-05 | Val. Loss: 0.203 |  Val. Acc: 92.34% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "Epoch: 020 | ET: 46.67s | \t Train Loss: 0.106 | Train Acc: 95.94% \t Val. Loss: 0.203 |  Val. Acc: 92.24% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    3    1    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.417 |  Val. Acc: 81.73% | B. Val. Loss: 0.417 |  B. Val. Acc: 81.73%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.96s | lr: 1.07e-04 | Val. Loss: 0.349 |  Val. Acc: 84.92% | B. Val. Loss: 0.349 |  B. Val. Acc: 84.92%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.54s | lr: 1.15e-04 | Val. Loss: 0.298 |  Val. Acc: 87.35% | B. Val. Loss: 0.298 |  B. Val. Acc: 87.35%\n",
      "Epoch: 001 | ET: 47.22s | \t Train Loss: 0.355 | Train Acc: 85.02% \t Val. Loss: 0.355 |  Val. Acc: 85.17% \t | B. Val. Loss: 0.298 |  B. Val. Acc: 87.35%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.51s | lr: 1.41e-04 | Val. Loss: 0.285 |  Val. Acc: 88.32% | B. Val. Loss: 0.285 |  B. Val. Acc: 88.32%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.10s | lr: 1.59e-04 | Val. Loss: 0.407 |  Val. Acc: 87.20% | B. Val. Loss: 0.285 |  B. Val. Acc: 88.32%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.49s | lr: 1.79e-04 | Val. Loss: 0.340 |  Val. Acc: 87.98% | B. Val. Loss: 0.285 |  B. Val. Acc: 88.32%\n",
      "Epoch: 002 | ET: 46.93s | \t Train Loss: 0.329 | Train Acc: 86.09% \t Val. Loss: 0.313 |  Val. Acc: 87.01% \t | B. Val. Loss: 0.285 |  B. Val. Acc: 88.32%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.51s | lr: 2.23e-04 | Val. Loss: 0.260 |  Val. Acc: 89.72% | B. Val. Loss: 0.260 |  B. Val. Acc: 89.72%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.09s | lr: 2.48e-04 | Val. Loss: 0.275 |  Val. Acc: 88.66% | B. Val. Loss: 0.260 |  B. Val. Acc: 89.72%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.45s | lr: 2.74e-04 | Val. Loss: 0.290 |  Val. Acc: 87.74% | B. Val. Loss: 0.260 |  B. Val. Acc: 89.72%\n",
      "Epoch: 003 | ET: 47.04s | \t Train Loss: 0.219 | Train Acc: 90.68% \t Val. Loss: 0.228 |  Val. Acc: 90.94% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 90.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.49s | lr: 3.26e-04 | Val. Loss: 0.254 |  Val. Acc: 90.94% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.85s | lr: 3.52e-04 | Val. Loss: 0.366 |  Val. Acc: 86.67% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.20s | lr: 3.77e-04 | Val. Loss: 0.244 |  Val. Acc: 90.50% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.94%\n",
      "Epoch: 004 | ET: 46.60s | \t Train Loss: 0.240 | Train Acc: 90.06% \t Val. Loss: 0.255 |  Val. Acc: 89.53% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 90.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.49s | lr: 4.22e-04 | Val. Loss: 0.215 |  Val. Acc: 90.94% | B. Val. Loss: 0.215 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.84s | lr: 4.42e-04 | Val. Loss: 0.247 |  Val. Acc: 90.50% | B. Val. Loss: 0.215 |  B. Val. Acc: 90.94%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.19s | lr: 4.59e-04 | Val. Loss: 0.235 |  Val. Acc: 90.69% | B. Val. Loss: 0.215 |  B. Val. Acc: 90.94%\n",
      "Epoch: 005 | ET: 46.47s | \t Train Loss: 0.333 | Train Acc: 88.80% \t Val. Loss: 0.363 |  Val. Acc: 88.37% \t | B. Val. Loss: 0.215 |  B. Val. Acc: 90.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.214 |  Val. Acc: 91.42% | B. Val. Loss: 0.214 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.05s | lr: 4.93e-04 | Val. Loss: 0.203 |  Val. Acc: 90.94% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.39s | lr: 4.98e-04 | Val. Loss: 0.220 |  Val. Acc: 90.69% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "Epoch: 006 | ET: 46.69s | \t Train Loss: 0.194 | Train Acc: 92.27% \t Val. Loss: 0.212 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.50s | lr: 5.00e-04 | Val. Loss: 0.196 |  Val. Acc: 91.71% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.04s | lr: 4.98e-04 | Val. Loss: 0.228 |  Val. Acc: 91.27% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.40s | lr: 4.96e-04 | Val. Loss: 0.200 |  Val. Acc: 91.23% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.71%\n",
      "Epoch: 007 | ET: 46.73s | \t Train Loss: 0.224 | Train Acc: 90.86% \t Val. Loss: 0.223 |  Val. Acc: 90.69% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.50s | lr: 4.90e-04 | Val. Loss: 0.195 |  Val. Acc: 91.52% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.86s | lr: 4.86e-04 | Val. Loss: 0.201 |  Val. Acc: 91.61% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.24s | lr: 4.81e-04 | Val. Loss: 0.210 |  Val. Acc: 91.57% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "Epoch: 008 | ET: 46.67s | \t Train Loss: 0.184 | Train Acc: 92.14% \t Val. Loss: 0.198 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.52s | lr: 4.69e-04 | Val. Loss: 0.207 |  Val. Acc: 91.32% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.90s | lr: 4.62e-04 | Val. Loss: 0.208 |  Val. Acc: 90.55% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.28s | lr: 4.55e-04 | Val. Loss: 0.205 |  Val. Acc: 91.23% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "Epoch: 009 | ET: 46.70s | \t Train Loss: 0.247 | Train Acc: 91.37% \t Val. Loss: 0.264 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.52s | lr: 4.38e-04 | Val. Loss: 0.189 |  Val. Acc: 91.61% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.90s | lr: 4.28e-04 | Val. Loss: 0.210 |  Val. Acc: 90.55% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.36s | lr: 4.18e-04 | Val. Loss: 0.211 |  Val. Acc: 90.98% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.71%\n",
      "Epoch: 010 | ET: 46.75s | \t Train Loss: 0.174 | Train Acc: 92.35% \t Val. Loss: 0.211 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.189 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.51s | lr: 3.97e-04 | Val. Loss: 0.188 |  Val. Acc: 92.39% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 14.07s | lr: 3.85e-04 | Val. Loss: 0.235 |  Val. Acc: 90.64% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.42s | lr: 3.73e-04 | Val. Loss: 0.195 |  Val. Acc: 91.57% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "Epoch: 011 | ET: 46.73s | \t Train Loss: 0.170 | Train Acc: 93.25% \t Val. Loss: 0.200 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.50s | lr: 3.49e-04 | Val. Loss: 0.192 |  Val. Acc: 91.57% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.88s | lr: 3.36e-04 | Val. Loss: 0.198 |  Val. Acc: 91.71% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.25s | lr: 3.23e-04 | Val. Loss: 0.196 |  Val. Acc: 91.52% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "Epoch: 012 | ET: 46.64s | \t Train Loss: 0.163 | Train Acc: 93.14% \t Val. Loss: 0.203 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.51s | lr: 2.96e-04 | Val. Loss: 0.207 |  Val. Acc: 91.61% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.89s | lr: 2.82e-04 | Val. Loss: 0.199 |  Val. Acc: 91.76% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.27s | lr: 2.68e-04 | Val. Loss: 0.199 |  Val. Acc: 91.52% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "Epoch: 013 | ET: 46.59s | \t Train Loss: 0.162 | Train Acc: 92.85% \t Val. Loss: 0.198 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.51s | lr: 2.41e-04 | Val. Loss: 0.193 |  Val. Acc: 92.20% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.88s | lr: 2.27e-04 | Val. Loss: 0.198 |  Val. Acc: 91.95% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.25s | lr: 2.14e-04 | Val. Loss: 0.195 |  Val. Acc: 92.00% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "Epoch: 014 | ET: 46.64s | \t Train Loss: 0.151 | Train Acc: 93.36% \t Val. Loss: 0.199 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.50s | lr: 1.87e-04 | Val. Loss: 0.187 |  Val. Acc: 92.39% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.85s | lr: 1.74e-04 | Val. Loss: 0.186 |  Val. Acc: 91.81% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.20s | lr: 1.61e-04 | Val. Loss: 0.200 |  Val. Acc: 91.81% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.39%\n",
      "Epoch: 015 | ET: 46.51s | \t Train Loss: 0.139 | Train Acc: 94.12% \t Val. Loss: 0.194 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.186 |  B. Val. Acc: 92.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.198 |  Val. Acc: 92.24% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.93s | lr: 1.24e-04 | Val. Loss: 0.214 |  Val. Acc: 91.81% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.39%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.28s | lr: 1.13e-04 | Val. Loss: 0.186 |  Val. Acc: 92.49% | B. Val. Loss: 0.186 |  B. Val. Acc: 92.49%\n",
      "Epoch: 016 | ET: 46.99s | \t Train Loss: 0.135 | Train Acc: 94.63% \t Val. Loss: 0.183 |  Val. Acc: 92.73% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.53s | lr: 9.17e-05 | Val. Loss: 0.188 |  Val. Acc: 92.68% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.88s | lr: 8.16e-05 | Val. Loss: 0.205 |  Val. Acc: 92.49% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.24s | lr: 7.21e-05 | Val. Loss: 0.206 |  Val. Acc: 92.24% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "Epoch: 017 | ET: 46.53s | \t Train Loss: 0.132 | Train Acc: 94.16% \t Val. Loss: 0.223 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.51s | lr: 5.51e-05 | Val. Loss: 0.196 |  Val. Acc: 92.24% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.87s | lr: 4.74e-05 | Val. Loss: 0.201 |  Val. Acc: 92.63% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.23s | lr: 4.04e-05 | Val. Loss: 0.197 |  Val. Acc: 92.15% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "Epoch: 018 | ET: 46.57s | \t Train Loss: 0.108 | Train Acc: 95.75% \t Val. Loss: 0.202 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.50s | lr: 2.86e-05 | Val. Loss: 0.199 |  Val. Acc: 92.39% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.86s | lr: 2.37e-05 | Val. Loss: 0.199 |  Val. Acc: 92.49% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.22s | lr: 1.95e-05 | Val. Loss: 0.199 |  Val. Acc: 92.05% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "Epoch: 019 | ET: 46.52s | \t Train Loss: 0.100 | Train Acc: 96.01% \t Val. Loss: 0.211 |  Val. Acc: 92.29% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.50s | lr: 1.34e-05 | Val. Loss: 0.207 |  Val. Acc: 92.34% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.85s | lr: 1.15e-05 | Val. Loss: 0.208 |  Val. Acc: 92.34% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.21s | lr: 1.04e-05 | Val. Loss: 0.206 |  Val. Acc: 92.44% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "Epoch: 020 | ET: 46.56s | \t Train Loss: 0.101 | Train Acc: 96.01% \t Val. Loss: 0.212 |  Val. Acc: 92.58% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.73%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    3    2    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.50s | lr: 1.02e-04 | Val. Loss: 0.435 |  Val. Acc: 79.01% | B. Val. Loss: 0.435 |  B. Val. Acc: 79.01%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 14.03s | lr: 1.07e-04 | Val. Loss: 0.402 |  Val. Acc: 82.02% | B. Val. Loss: 0.402 |  B. Val. Acc: 82.02%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.58s | lr: 1.15e-04 | Val. Loss: 0.348 |  Val. Acc: 85.41% | B. Val. Loss: 0.348 |  B. Val. Acc: 85.41%\n",
      "Epoch: 001 | ET: 47.29s | \t Train Loss: 0.326 | Train Acc: 85.82% \t Val. Loss: 0.342 |  Val. Acc: 85.99% \t | B. Val. Loss: 0.342 |  B. Val. Acc: 85.99%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.299 |  Val. Acc: 87.40% | B. Val. Loss: 0.299 |  B. Val. Acc: 87.40%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.06s | lr: 1.59e-04 | Val. Loss: 0.371 |  Val. Acc: 82.45% | B. Val. Loss: 0.299 |  B. Val. Acc: 87.40%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.41s | lr: 1.79e-04 | Val. Loss: 0.351 |  Val. Acc: 88.27% | B. Val. Loss: 0.299 |  B. Val. Acc: 88.27%\n",
      "Epoch: 002 | ET: 47.19s | \t Train Loss: 0.240 | Train Acc: 90.03% \t Val. Loss: 0.241 |  Val. Acc: 89.87% \t | B. Val. Loss: 0.241 |  B. Val. Acc: 89.87%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.47s | lr: 2.23e-04 | Val. Loss: 0.239 |  Val. Acc: 90.50% | B. Val. Loss: 0.239 |  B. Val. Acc: 90.50%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.01s | lr: 2.48e-04 | Val. Loss: 0.396 |  Val. Acc: 85.99% | B. Val. Loss: 0.239 |  B. Val. Acc: 90.50%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.35s | lr: 2.74e-04 | Val. Loss: 0.277 |  Val. Acc: 89.58% | B. Val. Loss: 0.239 |  B. Val. Acc: 90.50%\n",
      "Epoch: 003 | ET: 46.59s | \t Train Loss: 0.296 | Train Acc: 87.92% \t Val. Loss: 0.267 |  Val. Acc: 89.38% \t | B. Val. Loss: 0.239 |  B. Val. Acc: 90.50%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.46s | lr: 3.26e-04 | Val. Loss: 0.211 |  Val. Acc: 91.32% | B. Val. Loss: 0.211 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.00s | lr: 3.52e-04 | Val. Loss: 0.298 |  Val. Acc: 87.15% | B. Val. Loss: 0.211 |  B. Val. Acc: 91.32%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.33s | lr: 3.77e-04 | Val. Loss: 0.285 |  Val. Acc: 90.50% | B. Val. Loss: 0.211 |  B. Val. Acc: 91.32%\n",
      "Epoch: 004 | ET: 46.65s | \t Train Loss: 0.202 | Train Acc: 91.48% \t Val. Loss: 0.214 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.211 |  B. Val. Acc: 91.32%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.48s | lr: 4.22e-04 | Val. Loss: 0.196 |  Val. Acc: 91.81% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.02s | lr: 4.42e-04 | Val. Loss: 0.228 |  Val. Acc: 90.35% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.81%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.36s | lr: 4.59e-04 | Val. Loss: 0.249 |  Val. Acc: 89.38% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.81%\n",
      "Epoch: 005 | ET: 46.66s | \t Train Loss: 0.288 | Train Acc: 87.94% \t Val. Loss: 0.282 |  Val. Acc: 87.78% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 91.81%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.47s | lr: 4.85e-04 | Val. Loss: 0.195 |  Val. Acc: 92.00% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.02s | lr: 4.93e-04 | Val. Loss: 0.218 |  Val. Acc: 90.79% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.38s | lr: 4.98e-04 | Val. Loss: 0.193 |  Val. Acc: 91.47% | B. Val. Loss: 0.193 |  B. Val. Acc: 92.00%\n",
      "Epoch: 006 | ET: 46.78s | \t Train Loss: 0.230 | Train Acc: 89.74% \t Val. Loss: 0.258 |  Val. Acc: 88.75% \t | B. Val. Loss: 0.193 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.190 |  Val. Acc: 91.86% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.85s | lr: 4.98e-04 | Val. Loss: 0.374 |  Val. Acc: 86.38% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.23s | lr: 4.96e-04 | Val. Loss: 0.250 |  Val. Acc: 90.74% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "Epoch: 007 | ET: 46.55s | \t Train Loss: 0.207 | Train Acc: 91.34% \t Val. Loss: 0.228 |  Val. Acc: 90.94% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.191 |  Val. Acc: 91.90% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.83s | lr: 4.86e-04 | Val. Loss: 0.196 |  Val. Acc: 90.84% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.20s | lr: 4.81e-04 | Val. Loss: 0.216 |  Val. Acc: 91.08% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "Epoch: 008 | ET: 46.52s | \t Train Loss: 0.174 | Train Acc: 92.58% \t Val. Loss: 0.193 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.48s | lr: 4.69e-04 | Val. Loss: 0.183 |  Val. Acc: 92.24% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.99s | lr: 4.62e-04 | Val. Loss: 0.198 |  Val. Acc: 92.15% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.24%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.36s | lr: 4.55e-04 | Val. Loss: 0.191 |  Val. Acc: 91.90% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.24%\n",
      "Epoch: 009 | ET: 46.68s | \t Train Loss: 0.184 | Train Acc: 92.75% \t Val. Loss: 0.203 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.24%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.181 |  Val. Acc: 92.44% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 14.07s | lr: 4.28e-04 | Val. Loss: 0.220 |  Val. Acc: 91.27% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.43s | lr: 4.18e-04 | Val. Loss: 0.221 |  Val. Acc: 91.61% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "Epoch: 010 | ET: 46.78s | \t Train Loss: 0.177 | Train Acc: 92.79% \t Val. Loss: 0.203 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.48s | lr: 3.97e-04 | Val. Loss: 0.191 |  Val. Acc: 91.81% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.82s | lr: 3.85e-04 | Val. Loss: 0.198 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.19s | lr: 3.73e-04 | Val. Loss: 0.204 |  Val. Acc: 91.32% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "Epoch: 011 | ET: 46.51s | \t Train Loss: 0.162 | Train Acc: 93.23% \t Val. Loss: 0.191 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.55s | lr: 3.49e-04 | Val. Loss: 0.191 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.92s | lr: 3.36e-04 | Val. Loss: 0.199 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.26s | lr: 3.23e-04 | Val. Loss: 0.227 |  Val. Acc: 90.79% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "Epoch: 012 | ET: 46.55s | \t Train Loss: 0.161 | Train Acc: 93.82% \t Val. Loss: 0.189 |  Val. Acc: 92.10% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.48s | lr: 2.96e-04 | Val. Loss: 0.189 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.84s | lr: 2.82e-04 | Val. Loss: 0.189 |  Val. Acc: 92.39% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.19s | lr: 2.68e-04 | Val. Loss: 0.188 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "Epoch: 013 | ET: 46.47s | \t Train Loss: 0.157 | Train Acc: 93.82% \t Val. Loss: 0.187 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.44%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.48s | lr: 2.41e-04 | Val. Loss: 0.186 |  Val. Acc: 92.63% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 14.02s | lr: 2.27e-04 | Val. Loss: 0.198 |  Val. Acc: 91.71% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.38s | lr: 2.14e-04 | Val. Loss: 0.189 |  Val. Acc: 92.05% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "Epoch: 014 | ET: 46.71s | \t Train Loss: 0.149 | Train Acc: 94.21% \t Val. Loss: 0.183 |  Val. Acc: 92.34% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.51s | lr: 1.87e-04 | Val. Loss: 0.193 |  Val. Acc: 92.00% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.87s | lr: 1.74e-04 | Val. Loss: 0.194 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.24s | lr: 1.61e-04 | Val. Loss: 0.193 |  Val. Acc: 91.95% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "Epoch: 015 | ET: 46.60s | \t Train Loss: 0.167 | Train Acc: 93.43% \t Val. Loss: 0.222 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.186 |  Val. Acc: 92.29% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.85s | lr: 1.24e-04 | Val. Loss: 0.185 |  Val. Acc: 92.34% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.21s | lr: 1.13e-04 | Val. Loss: 0.196 |  Val. Acc: 92.00% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "Epoch: 016 | ET: 46.56s | \t Train Loss: 0.137 | Train Acc: 94.73% \t Val. Loss: 0.189 |  Val. Acc: 92.39% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.51s | lr: 9.17e-05 | Val. Loss: 0.186 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.87s | lr: 8.16e-05 | Val. Loss: 0.195 |  Val. Acc: 91.66% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.30s | lr: 7.21e-05 | Val. Loss: 0.205 |  Val. Acc: 91.76% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "Epoch: 017 | ET: 46.62s | \t Train Loss: 0.127 | Train Acc: 94.72% \t Val. Loss: 0.200 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.195 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.84s | lr: 4.74e-05 | Val. Loss: 0.200 |  Val. Acc: 92.44% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.63%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.19s | lr: 4.04e-05 | Val. Loss: 0.199 |  Val. Acc: 92.68% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "Epoch: 018 | ET: 46.71s | \t Train Loss: 0.117 | Train Acc: 95.40% \t Val. Loss: 0.200 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.47s | lr: 2.86e-05 | Val. Loss: 0.194 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.81s | lr: 2.37e-05 | Val. Loss: 0.195 |  Val. Acc: 92.54% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.14s | lr: 1.95e-05 | Val. Loss: 0.202 |  Val. Acc: 92.10% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "Epoch: 019 | ET: 46.45s | \t Train Loss: 0.106 | Train Acc: 95.90% \t Val. Loss: 0.204 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.48s | lr: 1.34e-05 | Val. Loss: 0.201 |  Val. Acc: 91.95% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.82s | lr: 1.15e-05 | Val. Loss: 0.199 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.17s | lr: 1.04e-05 | Val. Loss: 0.202 |  Val. Acc: 92.39% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "Epoch: 020 | ET: 46.46s | \t Train Loss: 0.101 | Train Acc: 96.15% \t Val. Loss: 0.202 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.68%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    3    3    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.50s | lr: 1.02e-04 | Val. Loss: 0.451 |  Val. Acc: 77.27% | B. Val. Loss: 0.451 |  B. Val. Acc: 77.27%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.93s | lr: 1.07e-04 | Val. Loss: 0.493 |  Val. Acc: 79.16% | B. Val. Loss: 0.451 |  B. Val. Acc: 79.16%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.48s | lr: 1.15e-04 | Val. Loss: 0.382 |  Val. Acc: 82.94% | B. Val. Loss: 0.382 |  B. Val. Acc: 82.94%\n",
      "Epoch: 001 | ET: 47.06s | \t Train Loss: 0.372 | Train Acc: 83.32% \t Val. Loss: 0.371 |  Val. Acc: 82.94% \t | B. Val. Loss: 0.371 |  B. Val. Acc: 82.94%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.58s | lr: 1.41e-04 | Val. Loss: 0.366 |  Val. Acc: 85.60% | B. Val. Loss: 0.366 |  B. Val. Acc: 85.60%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.13s | lr: 1.59e-04 | Val. Loss: 0.317 |  Val. Acc: 86.62% | B. Val. Loss: 0.317 |  B. Val. Acc: 86.62%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.69s | lr: 1.79e-04 | Val. Loss: 0.269 |  Val. Acc: 89.05% | B. Val. Loss: 0.269 |  B. Val. Acc: 89.05%\n",
      "Epoch: 002 | ET: 47.42s | \t Train Loss: 0.289 | Train Acc: 88.11% \t Val. Loss: 0.279 |  Val. Acc: 89.14% \t | B. Val. Loss: 0.269 |  B. Val. Acc: 89.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.49s | lr: 2.23e-04 | Val. Loss: 0.239 |  Val. Acc: 90.01% | B. Val. Loss: 0.239 |  B. Val. Acc: 90.01%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.05s | lr: 2.48e-04 | Val. Loss: 0.292 |  Val. Acc: 87.74% | B. Val. Loss: 0.239 |  B. Val. Acc: 90.01%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.42s | lr: 2.74e-04 | Val. Loss: 0.248 |  Val. Acc: 89.43% | B. Val. Loss: 0.239 |  B. Val. Acc: 90.01%\n",
      "Epoch: 003 | ET: 47.15s | \t Train Loss: 0.219 | Train Acc: 91.09% \t Val. Loss: 0.225 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.225 |  B. Val. Acc: 90.79%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.53s | lr: 3.26e-04 | Val. Loss: 0.224 |  Val. Acc: 90.98% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.09s | lr: 3.52e-04 | Val. Loss: 0.234 |  Val. Acc: 89.87% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.47s | lr: 3.77e-04 | Val. Loss: 0.231 |  Val. Acc: 90.35% | B. Val. Loss: 0.224 |  B. Val. Acc: 90.98%\n",
      "Epoch: 004 | ET: 46.83s | \t Train Loss: 0.224 | Train Acc: 91.02% \t Val. Loss: 0.232 |  Val. Acc: 90.55% \t | B. Val. Loss: 0.224 |  B. Val. Acc: 90.98%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.48s | lr: 4.22e-04 | Val. Loss: 0.198 |  Val. Acc: 91.42% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.04s | lr: 4.42e-04 | Val. Loss: 0.207 |  Val. Acc: 91.42% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.39s | lr: 4.59e-04 | Val. Loss: 0.209 |  Val. Acc: 90.79% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.42%\n",
      "Epoch: 005 | ET: 46.93s | \t Train Loss: 0.196 | Train Acc: 92.34% \t Val. Loss: 0.210 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.201 |  Val. Acc: 91.37% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.86s | lr: 4.93e-04 | Val. Loss: 0.259 |  Val. Acc: 89.87% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.24s | lr: 4.98e-04 | Val. Loss: 0.229 |  Val. Acc: 89.77% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "Epoch: 006 | ET: 46.57s | \t Train Loss: 0.286 | Train Acc: 88.49% \t Val. Loss: 0.295 |  Val. Acc: 88.08% \t | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.57s | lr: 5.00e-04 | Val. Loss: 0.203 |  Val. Acc: 91.57% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.91s | lr: 4.98e-04 | Val. Loss: 0.205 |  Val. Acc: 91.18% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.27s | lr: 4.96e-04 | Val. Loss: 0.235 |  Val. Acc: 90.84% | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "Epoch: 007 | ET: 46.57s | \t Train Loss: 0.279 | Train Acc: 87.58% \t Val. Loss: 0.298 |  Val. Acc: 86.23% \t | B. Val. Loss: 0.198 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.48s | lr: 4.90e-04 | Val. Loss: 0.183 |  Val. Acc: 92.00% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.03s | lr: 4.86e-04 | Val. Loss: 0.212 |  Val. Acc: 91.08% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.37s | lr: 4.81e-04 | Val. Loss: 0.218 |  Val. Acc: 90.55% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "Epoch: 008 | ET: 46.65s | \t Train Loss: 0.217 | Train Acc: 90.99% \t Val. Loss: 0.230 |  Val. Acc: 90.55% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.48s | lr: 4.69e-04 | Val. Loss: 0.195 |  Val. Acc: 91.81% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.82s | lr: 4.62e-04 | Val. Loss: 0.193 |  Val. Acc: 91.71% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.19s | lr: 4.55e-04 | Val. Loss: 0.202 |  Val. Acc: 91.32% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "Epoch: 009 | ET: 46.43s | \t Train Loss: 0.199 | Train Acc: 91.85% \t Val. Loss: 0.226 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.47s | lr: 4.38e-04 | Val. Loss: 0.189 |  Val. Acc: 91.95% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.83s | lr: 4.28e-04 | Val. Loss: 0.257 |  Val. Acc: 88.61% | B. Val. Loss: 0.183 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.17s | lr: 4.18e-04 | Val. Loss: 0.181 |  Val. Acc: 92.29% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "Epoch: 010 | ET: 46.64s | \t Train Loss: 0.169 | Train Acc: 92.57% \t Val. Loss: 0.190 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.49s | lr: 3.97e-04 | Val. Loss: 0.192 |  Val. Acc: 92.10% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.84s | lr: 3.85e-04 | Val. Loss: 0.196 |  Val. Acc: 91.81% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.19s | lr: 3.73e-04 | Val. Loss: 0.215 |  Val. Acc: 91.90% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "Epoch: 011 | ET: 46.48s | \t Train Loss: 0.202 | Train Acc: 92.16% \t Val. Loss: 0.243 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.48s | lr: 3.49e-04 | Val. Loss: 0.199 |  Val. Acc: 91.81% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.82s | lr: 3.36e-04 | Val. Loss: 0.194 |  Val. Acc: 92.24% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.26s | lr: 3.23e-04 | Val. Loss: 0.199 |  Val. Acc: 91.47% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "Epoch: 012 | ET: 46.53s | \t Train Loss: 0.156 | Train Acc: 93.42% \t Val. Loss: 0.191 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.47s | lr: 2.96e-04 | Val. Loss: 0.197 |  Val. Acc: 91.71% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.84s | lr: 2.82e-04 | Val. Loss: 0.202 |  Val. Acc: 91.61% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.18s | lr: 2.68e-04 | Val. Loss: 0.189 |  Val. Acc: 92.05% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "Epoch: 013 | ET: 46.45s | \t Train Loss: 0.157 | Train Acc: 93.60% \t Val. Loss: 0.191 |  Val. Acc: 91.86% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.50s | lr: 2.41e-04 | Val. Loss: 0.201 |  Val. Acc: 91.66% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.85s | lr: 2.27e-04 | Val. Loss: 0.220 |  Val. Acc: 90.16% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.20s | lr: 2.14e-04 | Val. Loss: 0.191 |  Val. Acc: 91.71% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "Epoch: 014 | ET: 46.54s | \t Train Loss: 0.153 | Train Acc: 93.69% \t Val. Loss: 0.192 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.185 |  Val. Acc: 92.34% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.34%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 14.03s | lr: 1.74e-04 | Val. Loss: 0.184 |  Val. Acc: 92.29% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.34%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.39s | lr: 1.61e-04 | Val. Loss: 0.185 |  Val. Acc: 92.49% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "Epoch: 015 | ET: 46.86s | \t Train Loss: 0.146 | Train Acc: 93.82% \t Val. Loss: 0.203 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.194 |  Val. Acc: 92.10% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.86s | lr: 1.24e-04 | Val. Loss: 0.201 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.22s | lr: 1.13e-04 | Val. Loss: 0.190 |  Val. Acc: 92.44% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "Epoch: 016 | ET: 46.52s | \t Train Loss: 0.142 | Train Acc: 94.11% \t Val. Loss: 0.195 |  Val. Acc: 92.20% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.49s | lr: 9.17e-05 | Val. Loss: 0.190 |  Val. Acc: 92.44% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.86s | lr: 8.16e-05 | Val. Loss: 0.208 |  Val. Acc: 92.34% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.20s | lr: 7.21e-05 | Val. Loss: 0.194 |  Val. Acc: 92.05% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.49%\n",
      "Epoch: 017 | ET: 46.76s | \t Train Loss: 0.123 | Train Acc: 94.97% \t Val. Loss: 0.203 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.194 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.81s | lr: 4.74e-05 | Val. Loss: 0.201 |  Val. Acc: 92.00% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.16s | lr: 4.04e-05 | Val. Loss: 0.212 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "Epoch: 018 | ET: 46.41s | \t Train Loss: 0.113 | Train Acc: 95.53% \t Val. Loss: 0.206 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.199 |  Val. Acc: 92.10% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.83s | lr: 2.37e-05 | Val. Loss: 0.199 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.16s | lr: 1.95e-05 | Val. Loss: 0.201 |  Val. Acc: 92.29% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "Epoch: 019 | ET: 46.41s | \t Train Loss: 0.103 | Train Acc: 96.03% \t Val. Loss: 0.209 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.49s | lr: 1.34e-05 | Val. Loss: 0.201 |  Val. Acc: 92.20% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.82s | lr: 1.15e-05 | Val. Loss: 0.208 |  Val. Acc: 92.39% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.16s | lr: 1.04e-05 | Val. Loss: 0.205 |  Val. Acc: 92.15% | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "Epoch: 020 | ET: 46.43s | \t Train Loss: 0.104 | Train Acc: 96.05% \t Val. Loss: 0.205 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.181 |  B. Val. Acc: 92.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    3    4    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.438 |  Val. Acc: 78.33% | B. Val. Loss: 0.438 |  B. Val. Acc: 78.33%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.94s | lr: 1.07e-04 | Val. Loss: 0.405 |  Val. Acc: 82.40% | B. Val. Loss: 0.405 |  B. Val. Acc: 82.40%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.50s | lr: 1.15e-04 | Val. Loss: 0.360 |  Val. Acc: 84.39% | B. Val. Loss: 0.360 |  B. Val. Acc: 84.39%\n",
      "Epoch: 001 | ET: 47.23s | \t Train Loss: 0.451 | Train Acc: 82.45% \t Val. Loss: 0.495 |  Val. Acc: 80.32% \t | B. Val. Loss: 0.360 |  B. Val. Acc: 84.39%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.295 |  Val. Acc: 87.59% | B. Val. Loss: 0.295 |  B. Val. Acc: 87.59%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.03s | lr: 1.59e-04 | Val. Loss: 0.292 |  Val. Acc: 88.12% | B. Val. Loss: 0.292 |  B. Val. Acc: 88.12%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.65s | lr: 1.79e-04 | Val. Loss: 0.310 |  Val. Acc: 87.64% | B. Val. Loss: 0.292 |  B. Val. Acc: 88.12%\n",
      "Epoch: 002 | ET: 47.17s | \t Train Loss: 0.252 | Train Acc: 89.93% \t Val. Loss: 0.249 |  Val. Acc: 90.35% \t | B. Val. Loss: 0.249 |  B. Val. Acc: 90.35%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.243 |  Val. Acc: 89.92% | B. Val. Loss: 0.243 |  B. Val. Acc: 90.35%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 13.82s | lr: 2.48e-04 | Val. Loss: 0.271 |  Val. Acc: 90.16% | B. Val. Loss: 0.243 |  B. Val. Acc: 90.35%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.18s | lr: 2.74e-04 | Val. Loss: 0.391 |  Val. Acc: 85.99% | B. Val. Loss: 0.243 |  B. Val. Acc: 90.35%\n",
      "Epoch: 003 | ET: 46.46s | \t Train Loss: 0.333 | Train Acc: 86.33% \t Val. Loss: 0.309 |  Val. Acc: 87.25% \t | B. Val. Loss: 0.243 |  B. Val. Acc: 90.35%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.226 |  Val. Acc: 91.13% | B. Val. Loss: 0.226 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.04s | lr: 3.52e-04 | Val. Loss: 0.414 |  Val. Acc: 89.63% | B. Val. Loss: 0.226 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.40s | lr: 3.77e-04 | Val. Loss: 0.310 |  Val. Acc: 90.06% | B. Val. Loss: 0.226 |  B. Val. Acc: 91.13%\n",
      "Epoch: 004 | ET: 46.76s | \t Train Loss: 0.283 | Train Acc: 89.83% \t Val. Loss: 0.302 |  Val. Acc: 89.43% \t | B. Val. Loss: 0.226 |  B. Val. Acc: 91.13%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.210 |  Val. Acc: 91.13% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 13.85s | lr: 4.42e-04 | Val. Loss: 0.218 |  Val. Acc: 91.61% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.41s | lr: 4.59e-04 | Val. Loss: 0.222 |  Val. Acc: 91.08% | B. Val. Loss: 0.210 |  B. Val. Acc: 91.61%\n",
      "Epoch: 005 | ET: 46.76s | \t Train Loss: 0.199 | Train Acc: 91.88% \t Val. Loss: 0.204 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 91.61%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.190 |  Val. Acc: 91.86% | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.03s | lr: 4.93e-04 | Val. Loss: 0.237 |  Val. Acc: 90.45% | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.40s | lr: 4.98e-04 | Val. Loss: 0.220 |  Val. Acc: 91.71% | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "Epoch: 006 | ET: 46.76s | \t Train Loss: 0.196 | Train Acc: 91.85% \t Val. Loss: 0.212 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.195 |  Val. Acc: 91.57% | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.85s | lr: 4.98e-04 | Val. Loss: 0.251 |  Val. Acc: 90.64% | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.23s | lr: 4.96e-04 | Val. Loss: 0.208 |  Val. Acc: 91.37% | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "Epoch: 007 | ET: 46.58s | \t Train Loss: 0.184 | Train Acc: 92.28% \t Val. Loss: 0.192 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 91.86%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.59s | lr: 4.90e-04 | Val. Loss: 0.175 |  Val. Acc: 92.97% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.14s | lr: 4.86e-04 | Val. Loss: 0.199 |  Val. Acc: 91.66% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.49s | lr: 4.81e-04 | Val. Loss: 0.212 |  Val. Acc: 91.71% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 008 | ET: 46.83s | \t Train Loss: 0.185 | Train Acc: 92.04% \t Val. Loss: 0.203 |  Val. Acc: 91.03% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.182 |  Val. Acc: 92.29% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.84s | lr: 4.62e-04 | Val. Loss: 0.188 |  Val. Acc: 92.05% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.21s | lr: 4.55e-04 | Val. Loss: 0.222 |  Val. Acc: 90.60% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 009 | ET: 46.50s | \t Train Loss: 0.198 | Train Acc: 91.93% \t Val. Loss: 0.209 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.186 |  Val. Acc: 92.39% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.84s | lr: 4.28e-04 | Val. Loss: 0.202 |  Val. Acc: 91.61% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.19s | lr: 4.18e-04 | Val. Loss: 0.206 |  Val. Acc: 92.15% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 010 | ET: 46.49s | \t Train Loss: 0.196 | Train Acc: 92.27% \t Val. Loss: 0.216 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.186 |  Val. Acc: 92.10% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.86s | lr: 3.85e-04 | Val. Loss: 0.185 |  Val. Acc: 91.95% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.23s | lr: 3.73e-04 | Val. Loss: 0.208 |  Val. Acc: 91.27% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 011 | ET: 46.59s | \t Train Loss: 0.158 | Train Acc: 93.20% \t Val. Loss: 0.179 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.183 |  Val. Acc: 92.24% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.84s | lr: 3.36e-04 | Val. Loss: 0.196 |  Val. Acc: 91.42% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.22s | lr: 3.23e-04 | Val. Loss: 0.184 |  Val. Acc: 92.34% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 012 | ET: 46.55s | \t Train Loss: 0.165 | Train Acc: 92.78% \t Val. Loss: 0.197 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.50s | lr: 2.96e-04 | Val. Loss: 0.186 |  Val. Acc: 92.63% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.90s | lr: 2.82e-04 | Val. Loss: 0.211 |  Val. Acc: 91.08% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.33s | lr: 2.68e-04 | Val. Loss: 0.208 |  Val. Acc: 91.23% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 013 | ET: 46.62s | \t Train Loss: 0.162 | Train Acc: 93.20% \t Val. Loss: 0.191 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.50s | lr: 2.41e-04 | Val. Loss: 0.181 |  Val. Acc: 92.54% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.84s | lr: 2.27e-04 | Val. Loss: 0.186 |  Val. Acc: 92.39% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.19s | lr: 2.14e-04 | Val. Loss: 0.185 |  Val. Acc: 92.39% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 014 | ET: 46.51s | \t Train Loss: 0.156 | Train Acc: 93.69% \t Val. Loss: 0.185 |  Val. Acc: 92.34% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.48s | lr: 1.87e-04 | Val. Loss: 0.186 |  Val. Acc: 92.63% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.83s | lr: 1.74e-04 | Val. Loss: 0.189 |  Val. Acc: 92.68% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.20s | lr: 1.61e-04 | Val. Loss: 0.185 |  Val. Acc: 92.20% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 015 | ET: 46.48s | \t Train Loss: 0.137 | Train Acc: 94.44% \t Val. Loss: 0.183 |  Val. Acc: 92.54% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.191 |  Val. Acc: 92.20% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.84s | lr: 1.24e-04 | Val. Loss: 0.186 |  Val. Acc: 92.44% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.18s | lr: 1.13e-04 | Val. Loss: 0.175 |  Val. Acc: 92.83% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 016 | ET: 46.46s | \t Train Loss: 0.131 | Train Acc: 94.56% \t Val. Loss: 0.176 |  Val. Acc: 92.87% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.50s | lr: 9.17e-05 | Val. Loss: 0.187 |  Val. Acc: 92.58% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.85s | lr: 8.16e-05 | Val. Loss: 0.188 |  Val. Acc: 92.49% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.20s | lr: 7.21e-05 | Val. Loss: 0.195 |  Val. Acc: 92.10% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 017 | ET: 46.51s | \t Train Loss: 0.126 | Train Acc: 94.96% \t Val. Loss: 0.192 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.187 |  Val. Acc: 92.44% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.82s | lr: 4.74e-05 | Val. Loss: 0.188 |  Val. Acc: 92.54% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.18s | lr: 4.04e-05 | Val. Loss: 0.201 |  Val. Acc: 92.63% | B. Val. Loss: 0.175 |  B. Val. Acc: 92.97%\n",
      "Epoch: 018 | ET: 46.61s | \t Train Loss: 0.110 | Train Acc: 95.81% \t Val. Loss: 0.199 |  Val. Acc: 93.07% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.193 |  Val. Acc: 92.44% | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.92s | lr: 2.37e-05 | Val. Loss: 0.198 |  Val. Acc: 92.54% | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.27s | lr: 1.95e-05 | Val. Loss: 0.204 |  Val. Acc: 92.83% | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "Epoch: 019 | ET: 46.60s | \t Train Loss: 0.101 | Train Acc: 96.27% \t Val. Loss: 0.197 |  Val. Acc: 92.63% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.50s | lr: 1.34e-05 | Val. Loss: 0.193 |  Val. Acc: 92.54% | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.86s | lr: 1.15e-05 | Val. Loss: 0.199 |  Val. Acc: 92.68% | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.25s | lr: 1.04e-05 | Val. Loss: 0.202 |  Val. Acc: 92.39% | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "Epoch: 020 | ET: 46.60s | \t Train Loss: 0.099 | Train Acc: 96.15% \t Val. Loss: 0.202 |  Val. Acc: 92.44% \t | B. Val. Loss: 0.175 |  B. Val. Acc: 93.07%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    4    0    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.497 |  Val. Acc: 78.14% | B. Val. Loss: 0.497 |  B. Val. Acc: 78.14%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.93s | lr: 1.07e-04 | Val. Loss: 0.433 |  Val. Acc: 81.43% | B. Val. Loss: 0.433 |  B. Val. Acc: 81.43%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.47s | lr: 1.15e-04 | Val. Loss: 0.373 |  Val. Acc: 83.08% | B. Val. Loss: 0.373 |  B. Val. Acc: 83.08%\n",
      "Epoch: 001 | ET: 47.00s | \t Train Loss: 0.652 | Train Acc: 75.16% \t Val. Loss: 0.625 |  Val. Acc: 77.02% \t | B. Val. Loss: 0.373 |  B. Val. Acc: 83.08%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.48s | lr: 1.41e-04 | Val. Loss: 0.326 |  Val. Acc: 86.14% | B. Val. Loss: 0.326 |  B. Val. Acc: 86.14%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.07s | lr: 1.59e-04 | Val. Loss: 0.377 |  Val. Acc: 83.13% | B. Val. Loss: 0.326 |  B. Val. Acc: 86.14%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.43s | lr: 1.79e-04 | Val. Loss: 0.384 |  Val. Acc: 85.89% | B. Val. Loss: 0.326 |  B. Val. Acc: 86.14%\n",
      "Epoch: 002 | ET: 46.95s | \t Train Loss: 0.255 | Train Acc: 89.31% \t Val. Loss: 0.262 |  Val. Acc: 88.56% \t | B. Val. Loss: 0.262 |  B. Val. Acc: 88.56%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.47s | lr: 2.23e-04 | Val. Loss: 0.258 |  Val. Acc: 89.09% | B. Val. Loss: 0.258 |  B. Val. Acc: 89.09%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.10s | lr: 2.48e-04 | Val. Loss: 0.256 |  Val. Acc: 89.43% | B. Val. Loss: 0.256 |  B. Val. Acc: 89.43%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.63s | lr: 2.74e-04 | Val. Loss: 0.274 |  Val. Acc: 89.09% | B. Val. Loss: 0.256 |  B. Val. Acc: 89.43%\n",
      "Epoch: 003 | ET: 46.93s | \t Train Loss: 0.252 | Train Acc: 90.31% \t Val. Loss: 0.280 |  Val. Acc: 89.24% \t | B. Val. Loss: 0.256 |  B. Val. Acc: 89.43%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.48s | lr: 3.26e-04 | Val. Loss: 0.256 |  Val. Acc: 88.95% | B. Val. Loss: 0.256 |  B. Val. Acc: 89.43%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 13.85s | lr: 3.52e-04 | Val. Loss: 0.274 |  Val. Acc: 89.63% | B. Val. Loss: 0.256 |  B. Val. Acc: 89.63%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.42s | lr: 3.77e-04 | Val. Loss: 0.252 |  Val. Acc: 89.05% | B. Val. Loss: 0.252 |  B. Val. Acc: 89.63%\n",
      "Epoch: 004 | ET: 46.74s | \t Train Loss: 0.248 | Train Acc: 90.68% \t Val. Loss: 0.279 |  Val. Acc: 89.38% \t | B. Val. Loss: 0.252 |  B. Val. Acc: 89.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.51s | lr: 4.22e-04 | Val. Loss: 0.221 |  Val. Acc: 90.55% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.55%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.09s | lr: 4.42e-04 | Val. Loss: 0.369 |  Val. Acc: 88.61% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.55%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.46s | lr: 4.59e-04 | Val. Loss: 0.243 |  Val. Acc: 89.68% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.55%\n",
      "Epoch: 005 | ET: 46.80s | \t Train Loss: 0.194 | Train Acc: 92.15% \t Val. Loss: 0.217 |  Val. Acc: 90.21% \t | B. Val. Loss: 0.217 |  B. Val. Acc: 90.55%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.49s | lr: 4.85e-04 | Val. Loss: 0.203 |  Val. Acc: 90.98% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.06s | lr: 4.93e-04 | Val. Loss: 0.221 |  Val. Acc: 90.16% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.46s | lr: 4.98e-04 | Val. Loss: 0.233 |  Val. Acc: 89.87% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "Epoch: 006 | ET: 46.84s | \t Train Loss: 0.246 | Train Acc: 90.60% \t Val. Loss: 0.244 |  Val. Acc: 90.26% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.50s | lr: 5.00e-04 | Val. Loss: 0.204 |  Val. Acc: 90.84% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.89s | lr: 4.98e-04 | Val. Loss: 0.258 |  Val. Acc: 89.72% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.28s | lr: 4.96e-04 | Val. Loss: 0.227 |  Val. Acc: 89.68% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "Epoch: 007 | ET: 46.64s | \t Train Loss: 0.197 | Train Acc: 91.66% \t Val. Loss: 0.227 |  Val. Acc: 90.55% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 90.98%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.52s | lr: 4.90e-04 | Val. Loss: 0.191 |  Val. Acc: 91.03% | B. Val. Loss: 0.191 |  B. Val. Acc: 91.03%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.17s | lr: 4.86e-04 | Val. Loss: 0.221 |  Val. Acc: 89.92% | B. Val. Loss: 0.191 |  B. Val. Acc: 91.03%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.53s | lr: 4.81e-04 | Val. Loss: 0.204 |  Val. Acc: 90.84% | B. Val. Loss: 0.191 |  B. Val. Acc: 91.03%\n",
      "Epoch: 008 | ET: 46.85s | \t Train Loss: 0.186 | Train Acc: 92.32% \t Val. Loss: 0.216 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.191 |  B. Val. Acc: 91.03%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.50s | lr: 4.69e-04 | Val. Loss: 0.194 |  Val. Acc: 92.00% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 14.07s | lr: 4.62e-04 | Val. Loss: 0.251 |  Val. Acc: 90.55% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.46s | lr: 4.55e-04 | Val. Loss: 0.232 |  Val. Acc: 89.97% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "Epoch: 009 | ET: 46.76s | \t Train Loss: 0.186 | Train Acc: 92.08% \t Val. Loss: 0.209 |  Val. Acc: 90.60% \t | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.199 |  Val. Acc: 91.08% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.87s | lr: 4.28e-04 | Val. Loss: 0.203 |  Val. Acc: 91.13% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.23s | lr: 4.18e-04 | Val. Loss: 0.209 |  Val. Acc: 90.40% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "Epoch: 010 | ET: 46.57s | \t Train Loss: 0.190 | Train Acc: 92.44% \t Val. Loss: 0.220 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.192 |  Val. Acc: 91.71% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.86s | lr: 3.85e-04 | Val. Loss: 0.201 |  Val. Acc: 90.89% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.23s | lr: 3.73e-04 | Val. Loss: 0.213 |  Val. Acc: 90.60% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "Epoch: 011 | ET: 46.58s | \t Train Loss: 0.169 | Train Acc: 93.04% \t Val. Loss: 0.200 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.206 |  Val. Acc: 90.98% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.85s | lr: 3.36e-04 | Val. Loss: 0.215 |  Val. Acc: 90.21% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.21s | lr: 3.23e-04 | Val. Loss: 0.218 |  Val. Acc: 90.64% | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "Epoch: 012 | ET: 46.58s | \t Train Loss: 0.167 | Train Acc: 93.32% \t Val. Loss: 0.202 |  Val. Acc: 91.52% \t | B. Val. Loss: 0.191 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.49s | lr: 2.96e-04 | Val. Loss: 0.187 |  Val. Acc: 91.81% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.88s | lr: 2.82e-04 | Val. Loss: 0.195 |  Val. Acc: 90.98% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.24s | lr: 2.68e-04 | Val. Loss: 0.201 |  Val. Acc: 91.52% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "Epoch: 013 | ET: 46.56s | \t Train Loss: 0.168 | Train Acc: 93.17% \t Val. Loss: 0.205 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.58s | lr: 2.41e-04 | Val. Loss: 0.195 |  Val. Acc: 91.52% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.93s | lr: 2.27e-04 | Val. Loss: 0.219 |  Val. Acc: 89.72% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.30s | lr: 2.14e-04 | Val. Loss: 0.187 |  Val. Acc: 92.00% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "Epoch: 014 | ET: 46.59s | \t Train Loss: 0.161 | Train Acc: 93.40% \t Val. Loss: 0.197 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.49s | lr: 1.87e-04 | Val. Loss: 0.182 |  Val. Acc: 91.95% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.85s | lr: 1.74e-04 | Val. Loss: 0.199 |  Val. Acc: 92.15% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.41s | lr: 1.61e-04 | Val. Loss: 0.190 |  Val. Acc: 91.86% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "Epoch: 015 | ET: 46.66s | \t Train Loss: 0.143 | Train Acc: 94.43% \t Val. Loss: 0.196 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.48s | lr: 1.36e-04 | Val. Loss: 0.194 |  Val. Acc: 91.90% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.84s | lr: 1.24e-04 | Val. Loss: 0.203 |  Val. Acc: 91.27% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.18s | lr: 1.13e-04 | Val. Loss: 0.193 |  Val. Acc: 92.15% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "Epoch: 016 | ET: 46.41s | \t Train Loss: 0.135 | Train Acc: 94.57% \t Val. Loss: 0.190 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.50s | lr: 9.17e-05 | Val. Loss: 0.191 |  Val. Acc: 92.05% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.84s | lr: 8.16e-05 | Val. Loss: 0.196 |  Val. Acc: 91.57% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.17s | lr: 7.21e-05 | Val. Loss: 0.198 |  Val. Acc: 91.81% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "Epoch: 017 | ET: 46.41s | \t Train Loss: 0.125 | Train Acc: 95.34% \t Val. Loss: 0.206 |  Val. Acc: 92.05% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.48s | lr: 5.51e-05 | Val. Loss: 0.199 |  Val. Acc: 91.61% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.81s | lr: 4.74e-05 | Val. Loss: 0.196 |  Val. Acc: 91.42% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.15s | lr: 4.04e-05 | Val. Loss: 0.194 |  Val. Acc: 91.95% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "Epoch: 018 | ET: 46.39s | \t Train Loss: 0.112 | Train Acc: 95.82% \t Val. Loss: 0.197 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.201 |  Val. Acc: 91.95% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.84s | lr: 2.37e-05 | Val. Loss: 0.206 |  Val. Acc: 91.57% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.27s | lr: 1.95e-05 | Val. Loss: 0.203 |  Val. Acc: 91.95% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "Epoch: 019 | ET: 46.70s | \t Train Loss: 0.106 | Train Acc: 96.04% \t Val. Loss: 0.202 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.49s | lr: 1.34e-05 | Val. Loss: 0.202 |  Val. Acc: 91.90% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.84s | lr: 1.15e-05 | Val. Loss: 0.203 |  Val. Acc: 91.66% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.20s | lr: 1.04e-05 | Val. Loss: 0.205 |  Val. Acc: 91.66% | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "Epoch: 020 | ET: 46.53s | \t Train Loss: 0.100 | Train Acc: 96.15% \t Val. Loss: 0.207 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.182 |  B. Val. Acc: 92.15%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    4    1    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.49s | lr: 1.02e-04 | Val. Loss: 0.446 |  Val. Acc: 80.27% | B. Val. Loss: 0.446 |  B. Val. Acc: 80.27%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.95s | lr: 1.07e-04 | Val. Loss: 0.446 |  Val. Acc: 78.38% | B. Val. Loss: 0.446 |  B. Val. Acc: 80.27%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.31s | lr: 1.15e-04 | Val. Loss: 0.463 |  Val. Acc: 76.78% | B. Val. Loss: 0.446 |  B. Val. Acc: 80.27%\n",
      "Epoch: 001 | ET: 46.88s | \t Train Loss: 0.417 | Train Acc: 82.13% \t Val. Loss: 0.416 |  Val. Acc: 83.03% \t | B. Val. Loss: 0.416 |  B. Val. Acc: 83.03%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.326 |  Val. Acc: 86.52% | B. Val. Loss: 0.326 |  B. Val. Acc: 86.52%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.05s | lr: 1.59e-04 | Val. Loss: 0.344 |  Val. Acc: 84.00% | B. Val. Loss: 0.326 |  B. Val. Acc: 86.52%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.41s | lr: 1.79e-04 | Val. Loss: 0.558 |  Val. Acc: 68.40% | B. Val. Loss: 0.326 |  B. Val. Acc: 86.52%\n",
      "Epoch: 002 | ET: 46.95s | \t Train Loss: 0.306 | Train Acc: 88.25% \t Val. Loss: 0.329 |  Val. Acc: 87.40% \t | B. Val. Loss: 0.326 |  B. Val. Acc: 87.40%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.262 |  Val. Acc: 89.05% | B. Val. Loss: 0.262 |  B. Val. Acc: 89.05%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.03s | lr: 2.48e-04 | Val. Loss: 0.238 |  Val. Acc: 89.29% | B. Val. Loss: 0.238 |  B. Val. Acc: 89.29%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.60s | lr: 2.74e-04 | Val. Loss: 0.257 |  Val. Acc: 88.51% | B. Val. Loss: 0.238 |  B. Val. Acc: 89.29%\n",
      "Epoch: 003 | ET: 46.92s | \t Train Loss: 0.222 | Train Acc: 90.60% \t Val. Loss: 0.242 |  Val. Acc: 89.05% \t | B. Val. Loss: 0.238 |  B. Val. Acc: 89.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.47s | lr: 3.26e-04 | Val. Loss: 0.281 |  Val. Acc: 89.97% | B. Val. Loss: 0.238 |  B. Val. Acc: 89.97%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.11s | lr: 3.52e-04 | Val. Loss: 0.255 |  Val. Acc: 88.90% | B. Val. Loss: 0.238 |  B. Val. Acc: 89.97%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.48s | lr: 3.77e-04 | Val. Loss: 0.240 |  Val. Acc: 89.19% | B. Val. Loss: 0.238 |  B. Val. Acc: 89.97%\n",
      "Epoch: 004 | ET: 46.80s | \t Train Loss: 0.263 | Train Acc: 89.45% \t Val. Loss: 0.258 |  Val. Acc: 89.38% \t | B. Val. Loss: 0.238 |  B. Val. Acc: 89.97%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.51s | lr: 4.22e-04 | Val. Loss: 0.227 |  Val. Acc: 90.11% | B. Val. Loss: 0.227 |  B. Val. Acc: 90.11%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.07s | lr: 4.42e-04 | Val. Loss: 0.238 |  Val. Acc: 89.29% | B. Val. Loss: 0.227 |  B. Val. Acc: 90.11%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.43s | lr: 4.59e-04 | Val. Loss: 0.233 |  Val. Acc: 90.98% | B. Val. Loss: 0.227 |  B. Val. Acc: 90.98%\n",
      "Epoch: 005 | ET: 46.95s | \t Train Loss: 0.224 | Train Acc: 90.31% \t Val. Loss: 0.240 |  Val. Acc: 89.38% \t | B. Val. Loss: 0.227 |  B. Val. Acc: 90.98%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.51s | lr: 4.85e-04 | Val. Loss: 0.203 |  Val. Acc: 91.42% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.08s | lr: 4.93e-04 | Val. Loss: 0.227 |  Val. Acc: 90.50% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.46s | lr: 4.98e-04 | Val. Loss: 0.219 |  Val. Acc: 90.26% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "Epoch: 006 | ET: 46.78s | \t Train Loss: 0.238 | Train Acc: 91.26% \t Val. Loss: 0.279 |  Val. Acc: 89.72% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 91.42%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.195 |  Val. Acc: 92.05% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.05s | lr: 4.98e-04 | Val. Loss: 0.221 |  Val. Acc: 90.98% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.41s | lr: 4.96e-04 | Val. Loss: 0.228 |  Val. Acc: 90.16% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "Epoch: 007 | ET: 46.74s | \t Train Loss: 0.321 | Train Acc: 89.75% \t Val. Loss: 0.387 |  Val. Acc: 88.56% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.52s | lr: 4.90e-04 | Val. Loss: 0.202 |  Val. Acc: 90.69% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 13.90s | lr: 4.86e-04 | Val. Loss: 0.271 |  Val. Acc: 89.92% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.27s | lr: 4.81e-04 | Val. Loss: 0.219 |  Val. Acc: 89.87% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "Epoch: 008 | ET: 46.62s | \t Train Loss: 0.191 | Train Acc: 92.34% \t Val. Loss: 0.205 |  Val. Acc: 90.60% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.50s | lr: 4.69e-04 | Val. Loss: 0.212 |  Val. Acc: 90.69% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.86s | lr: 4.62e-04 | Val. Loss: 0.258 |  Val. Acc: 88.66% | B. Val. Loss: 0.195 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.24s | lr: 4.55e-04 | Val. Loss: 0.194 |  Val. Acc: 91.13% | B. Val. Loss: 0.194 |  B. Val. Acc: 92.05%\n",
      "Epoch: 009 | ET: 46.60s | \t Train Loss: 0.188 | Train Acc: 92.96% \t Val. Loss: 0.227 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.57s | lr: 4.38e-04 | Val. Loss: 0.190 |  Val. Acc: 91.27% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.95s | lr: 4.28e-04 | Val. Loss: 0.193 |  Val. Acc: 91.23% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.32s | lr: 4.18e-04 | Val. Loss: 0.256 |  Val. Acc: 90.40% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "Epoch: 010 | ET: 46.68s | \t Train Loss: 0.173 | Train Acc: 93.00% \t Val. Loss: 0.212 |  Val. Acc: 91.03% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.51s | lr: 3.97e-04 | Val. Loss: 0.196 |  Val. Acc: 90.55% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.87s | lr: 3.85e-04 | Val. Loss: 0.211 |  Val. Acc: 90.69% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.23s | lr: 3.73e-04 | Val. Loss: 0.198 |  Val. Acc: 90.50% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "Epoch: 011 | ET: 46.58s | \t Train Loss: 0.160 | Train Acc: 93.11% \t Val. Loss: 0.192 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.191 |  Val. Acc: 91.71% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.86s | lr: 3.36e-04 | Val. Loss: 0.194 |  Val. Acc: 91.52% | B. Val. Loss: 0.190 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.25s | lr: 3.23e-04 | Val. Loss: 0.184 |  Val. Acc: 91.71% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "Epoch: 012 | ET: 46.60s | \t Train Loss: 0.158 | Train Acc: 93.69% \t Val. Loss: 0.200 |  Val. Acc: 91.86% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.50s | lr: 2.96e-04 | Val. Loss: 0.189 |  Val. Acc: 91.86% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.87s | lr: 2.82e-04 | Val. Loss: 0.201 |  Val. Acc: 91.42% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.23s | lr: 2.68e-04 | Val. Loss: 0.198 |  Val. Acc: 91.03% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "Epoch: 013 | ET: 46.54s | \t Train Loss: 0.161 | Train Acc: 93.20% \t Val. Loss: 0.204 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.52s | lr: 2.41e-04 | Val. Loss: 0.188 |  Val. Acc: 91.81% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.89s | lr: 2.27e-04 | Val. Loss: 0.189 |  Val. Acc: 91.66% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.25s | lr: 2.14e-04 | Val. Loss: 0.207 |  Val. Acc: 90.98% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "Epoch: 014 | ET: 46.59s | \t Train Loss: 0.147 | Train Acc: 94.11% \t Val. Loss: 0.184 |  Val. Acc: 91.47% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.50s | lr: 1.87e-04 | Val. Loss: 0.193 |  Val. Acc: 91.57% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.87s | lr: 1.74e-04 | Val. Loss: 0.190 |  Val. Acc: 91.27% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.25s | lr: 1.61e-04 | Val. Loss: 0.191 |  Val. Acc: 91.90% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "Epoch: 015 | ET: 46.71s | \t Train Loss: 0.171 | Train Acc: 93.49% \t Val. Loss: 0.241 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.194 |  Val. Acc: 91.47% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.89s | lr: 1.24e-04 | Val. Loss: 0.201 |  Val. Acc: 91.52% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.27s | lr: 1.13e-04 | Val. Loss: 0.199 |  Val. Acc: 91.03% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "Epoch: 016 | ET: 46.69s | \t Train Loss: 0.132 | Train Acc: 94.97% \t Val. Loss: 0.186 |  Val. Acc: 91.86% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.05%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.54s | lr: 9.17e-05 | Val. Loss: 0.184 |  Val. Acc: 92.29% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 14.13s | lr: 8.16e-05 | Val. Loss: 0.214 |  Val. Acc: 91.66% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.51s | lr: 7.21e-05 | Val. Loss: 0.200 |  Val. Acc: 91.27% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "Epoch: 017 | ET: 46.90s | \t Train Loss: 0.133 | Train Acc: 94.43% \t Val. Loss: 0.210 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.49s | lr: 5.51e-05 | Val. Loss: 0.189 |  Val. Acc: 92.20% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.87s | lr: 4.74e-05 | Val. Loss: 0.199 |  Val. Acc: 91.27% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.25s | lr: 4.04e-05 | Val. Loss: 0.196 |  Val. Acc: 91.86% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "Epoch: 018 | ET: 46.65s | \t Train Loss: 0.118 | Train Acc: 95.46% \t Val. Loss: 0.211 |  Val. Acc: 91.76% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.202 |  Val. Acc: 91.61% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.88s | lr: 2.37e-05 | Val. Loss: 0.207 |  Val. Acc: 91.66% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.26s | lr: 1.95e-05 | Val. Loss: 0.208 |  Val. Acc: 91.52% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "Epoch: 019 | ET: 46.67s | \t Train Loss: 0.104 | Train Acc: 96.00% \t Val. Loss: 0.208 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.52s | lr: 1.34e-05 | Val. Loss: 0.201 |  Val. Acc: 91.86% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.90s | lr: 1.15e-05 | Val. Loss: 0.209 |  Val. Acc: 91.71% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.27s | lr: 1.04e-05 | Val. Loss: 0.207 |  Val. Acc: 91.71% | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "Epoch: 020 | ET: 46.68s | \t Train Loss: 0.101 | Train Acc: 96.29% \t Val. Loss: 0.209 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.184 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    4    2    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.59s | lr: 1.02e-04 | Val. Loss: 0.512 |  Val. Acc: 77.70% | B. Val. Loss: 0.512 |  B. Val. Acc: 77.70%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 14.07s | lr: 1.07e-04 | Val. Loss: 0.471 |  Val. Acc: 77.22% | B. Val. Loss: 0.471 |  B. Val. Acc: 77.70%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.45s | lr: 1.15e-04 | Val. Loss: 0.411 |  Val. Acc: 82.31% | B. Val. Loss: 0.411 |  B. Val. Acc: 82.31%\n",
      "Epoch: 001 | ET: 47.19s | \t Train Loss: 0.335 | Train Acc: 85.50% \t Val. Loss: 0.346 |  Val. Acc: 85.17% \t | B. Val. Loss: 0.346 |  B. Val. Acc: 85.17%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.53s | lr: 1.41e-04 | Val. Loss: 0.336 |  Val. Acc: 86.38% | B. Val. Loss: 0.336 |  B. Val. Acc: 86.38%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.10s | lr: 1.59e-04 | Val. Loss: 0.399 |  Val. Acc: 81.39% | B. Val. Loss: 0.336 |  B. Val. Acc: 86.38%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.48s | lr: 1.79e-04 | Val. Loss: 0.359 |  Val. Acc: 87.40% | B. Val. Loss: 0.336 |  B. Val. Acc: 87.40%\n",
      "Epoch: 002 | ET: 47.22s | \t Train Loss: 0.266 | Train Acc: 88.88% \t Val. Loss: 0.281 |  Val. Acc: 87.64% \t | B. Val. Loss: 0.281 |  B. Val. Acc: 87.64%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.265 |  Val. Acc: 89.38% | B. Val. Loss: 0.265 |  B. Val. Acc: 89.38%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.02s | lr: 2.48e-04 | Val. Loss: 0.350 |  Val. Acc: 87.69% | B. Val. Loss: 0.265 |  B. Val. Acc: 89.38%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.38s | lr: 2.74e-04 | Val. Loss: 0.272 |  Val. Acc: 89.53% | B. Val. Loss: 0.265 |  B. Val. Acc: 89.53%\n",
      "Epoch: 003 | ET: 46.92s | \t Train Loss: 0.258 | Train Acc: 90.66% \t Val. Loss: 0.278 |  Val. Acc: 89.05% \t | B. Val. Loss: 0.265 |  B. Val. Acc: 89.53%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.49s | lr: 3.26e-04 | Val. Loss: 0.240 |  Val. Acc: 89.58% | B. Val. Loss: 0.240 |  B. Val. Acc: 89.58%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.06s | lr: 3.52e-04 | Val. Loss: 0.315 |  Val. Acc: 89.00% | B. Val. Loss: 0.240 |  B. Val. Acc: 89.58%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.42s | lr: 3.77e-04 | Val. Loss: 0.249 |  Val. Acc: 88.71% | B. Val. Loss: 0.240 |  B. Val. Acc: 89.58%\n",
      "Epoch: 004 | ET: 46.93s | \t Train Loss: 0.210 | Train Acc: 91.76% \t Val. Loss: 0.228 |  Val. Acc: 90.26% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 90.26%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.237 |  Val. Acc: 90.31% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.31%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.08s | lr: 4.42e-04 | Val. Loss: 0.260 |  Val. Acc: 89.87% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.31%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.52s | lr: 4.59e-04 | Val. Loss: 0.359 |  Val. Acc: 83.76% | B. Val. Loss: 0.228 |  B. Val. Acc: 90.31%\n",
      "Epoch: 005 | ET: 46.95s | \t Train Loss: 0.241 | Train Acc: 90.17% \t Val. Loss: 0.255 |  Val. Acc: 88.71% \t | B. Val. Loss: 0.228 |  B. Val. Acc: 90.31%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.50s | lr: 4.85e-04 | Val. Loss: 0.221 |  Val. Acc: 90.60% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.60%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.07s | lr: 4.93e-04 | Val. Loss: 0.242 |  Val. Acc: 89.14% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.60%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.43s | lr: 4.98e-04 | Val. Loss: 0.256 |  Val. Acc: 89.77% | B. Val. Loss: 0.221 |  B. Val. Acc: 90.60%\n",
      "Epoch: 006 | ET: 46.75s | \t Train Loss: 0.210 | Train Acc: 91.72% \t Val. Loss: 0.230 |  Val. Acc: 90.11% \t | B. Val. Loss: 0.221 |  B. Val. Acc: 90.60%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.208 |  Val. Acc: 91.03% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.03%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 14.06s | lr: 4.98e-04 | Val. Loss: 0.251 |  Val. Acc: 90.06% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.03%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.42s | lr: 4.96e-04 | Val. Loss: 0.224 |  Val. Acc: 90.50% | B. Val. Loss: 0.208 |  B. Val. Acc: 91.03%\n",
      "Epoch: 007 | ET: 46.77s | \t Train Loss: 0.282 | Train Acc: 87.91% \t Val. Loss: 0.297 |  Val. Acc: 86.57% \t | B. Val. Loss: 0.208 |  B. Val. Acc: 91.03%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.51s | lr: 4.90e-04 | Val. Loss: 0.193 |  Val. Acc: 92.00% | B. Val. Loss: 0.193 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.07s | lr: 4.86e-04 | Val. Loss: 0.228 |  Val. Acc: 89.63% | B. Val. Loss: 0.193 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.44s | lr: 4.81e-04 | Val. Loss: 0.196 |  Val. Acc: 90.69% | B. Val. Loss: 0.193 |  B. Val. Acc: 92.00%\n",
      "Epoch: 008 | ET: 46.83s | \t Train Loss: 0.178 | Train Acc: 92.58% \t Val. Loss: 0.199 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.193 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.50s | lr: 4.69e-04 | Val. Loss: 0.188 |  Val. Acc: 91.52% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.88s | lr: 4.62e-04 | Val. Loss: 0.222 |  Val. Acc: 90.35% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.27s | lr: 4.55e-04 | Val. Loss: 0.215 |  Val. Acc: 91.81% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "Epoch: 009 | ET: 46.62s | \t Train Loss: 0.197 | Train Acc: 92.04% \t Val. Loss: 0.236 |  Val. Acc: 89.97% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.49s | lr: 4.38e-04 | Val. Loss: 0.192 |  Val. Acc: 91.27% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.87s | lr: 4.28e-04 | Val. Loss: 0.199 |  Val. Acc: 91.37% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.24s | lr: 4.18e-04 | Val. Loss: 0.229 |  Val. Acc: 90.21% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "Epoch: 010 | ET: 46.63s | \t Train Loss: 0.198 | Train Acc: 92.62% \t Val. Loss: 0.217 |  Val. Acc: 91.37% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.59s | lr: 3.97e-04 | Val. Loss: 0.202 |  Val. Acc: 91.90% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.96s | lr: 3.85e-04 | Val. Loss: 0.233 |  Val. Acc: 90.64% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.34s | lr: 3.73e-04 | Val. Loss: 0.213 |  Val. Acc: 90.55% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "Epoch: 011 | ET: 46.76s | \t Train Loss: 0.194 | Train Acc: 92.28% \t Val. Loss: 0.216 |  Val. Acc: 89.97% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.50s | lr: 3.49e-04 | Val. Loss: 0.199 |  Val. Acc: 90.89% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.88s | lr: 3.36e-04 | Val. Loss: 0.205 |  Val. Acc: 91.95% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.27s | lr: 3.23e-04 | Val. Loss: 0.195 |  Val. Acc: 91.52% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "Epoch: 012 | ET: 46.63s | \t Train Loss: 0.163 | Train Acc: 93.36% \t Val. Loss: 0.195 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.49s | lr: 2.96e-04 | Val. Loss: 0.200 |  Val. Acc: 91.57% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.88s | lr: 2.82e-04 | Val. Loss: 0.207 |  Val. Acc: 90.94% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.26s | lr: 2.68e-04 | Val. Loss: 0.201 |  Val. Acc: 91.81% | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "Epoch: 013 | ET: 46.62s | \t Train Loss: 0.182 | Train Acc: 93.21% \t Val. Loss: 0.246 |  Val. Acc: 91.18% \t | B. Val. Loss: 0.188 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.51s | lr: 2.41e-04 | Val. Loss: 0.187 |  Val. Acc: 91.71% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.89s | lr: 2.27e-04 | Val. Loss: 0.235 |  Val. Acc: 90.01% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.27s | lr: 2.14e-04 | Val. Loss: 0.201 |  Val. Acc: 91.37% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "Epoch: 014 | ET: 46.64s | \t Train Loss: 0.149 | Train Acc: 93.82% \t Val. Loss: 0.201 |  Val. Acc: 91.76% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.49s | lr: 1.87e-04 | Val. Loss: 0.195 |  Val. Acc: 91.52% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.86s | lr: 1.74e-04 | Val. Loss: 0.208 |  Val. Acc: 91.42% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.25s | lr: 1.61e-04 | Val. Loss: 0.185 |  Val. Acc: 91.71% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.00%\n",
      "Epoch: 015 | ET: 46.63s | \t Train Loss: 0.140 | Train Acc: 94.20% \t Val. Loss: 0.188 |  Val. Acc: 91.81% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.199 |  Val. Acc: 91.66% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.89s | lr: 1.24e-04 | Val. Loss: 0.205 |  Val. Acc: 91.42% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.26s | lr: 1.13e-04 | Val. Loss: 0.190 |  Val. Acc: 92.10% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.10%\n",
      "Epoch: 016 | ET: 46.88s | \t Train Loss: 0.134 | Train Acc: 94.78% \t Val. Loss: 0.187 |  Val. Acc: 91.71% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.10%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.50s | lr: 9.17e-05 | Val. Loss: 0.200 |  Val. Acc: 92.10% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.88s | lr: 8.16e-05 | Val. Loss: 0.192 |  Val. Acc: 92.10% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.10%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.26s | lr: 7.21e-05 | Val. Loss: 0.199 |  Val. Acc: 91.76% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.10%\n",
      "Epoch: 017 | ET: 46.82s | \t Train Loss: 0.121 | Train Acc: 95.21% \t Val. Loss: 0.193 |  Val. Acc: 92.49% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.50s | lr: 5.51e-05 | Val. Loss: 0.196 |  Val. Acc: 92.29% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.86s | lr: 4.74e-05 | Val. Loss: 0.195 |  Val. Acc: 91.52% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.23s | lr: 4.04e-05 | Val. Loss: 0.199 |  Val. Acc: 91.81% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "Epoch: 018 | ET: 46.55s | \t Train Loss: 0.109 | Train Acc: 95.60% \t Val. Loss: 0.207 |  Val. Acc: 92.15% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.48s | lr: 2.86e-05 | Val. Loss: 0.199 |  Val. Acc: 91.81% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.85s | lr: 2.37e-05 | Val. Loss: 0.201 |  Val. Acc: 91.86% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.21s | lr: 1.95e-05 | Val. Loss: 0.207 |  Val. Acc: 91.76% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "Epoch: 019 | ET: 46.55s | \t Train Loss: 0.106 | Train Acc: 95.63% \t Val. Loss: 0.213 |  Val. Acc: 91.95% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.50s | lr: 1.34e-05 | Val. Loss: 0.204 |  Val. Acc: 92.10% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.85s | lr: 1.15e-05 | Val. Loss: 0.208 |  Val. Acc: 91.76% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.20s | lr: 1.04e-05 | Val. Loss: 0.206 |  Val. Acc: 91.66% | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "Epoch: 020 | ET: 46.53s | \t Train Loss: 0.100 | Train Acc: 96.10% \t Val. Loss: 0.205 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 92.49%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    4    3    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.470 |  Val. Acc: 77.70% | B. Val. Loss: 0.470 |  B. Val. Acc: 77.70%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.92s | lr: 1.07e-04 | Val. Loss: 0.430 |  Val. Acc: 80.61% | B. Val. Loss: 0.430 |  B. Val. Acc: 80.61%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.55s | lr: 1.15e-04 | Val. Loss: 0.450 |  Val. Acc: 79.93% | B. Val. Loss: 0.430 |  B. Val. Acc: 80.61%\n",
      "Epoch: 001 | ET: 47.03s | \t Train Loss: 0.379 | Train Acc: 84.24% \t Val. Loss: 0.404 |  Val. Acc: 83.66% \t | B. Val. Loss: 0.404 |  B. Val. Acc: 83.66%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.50s | lr: 1.41e-04 | Val. Loss: 0.318 |  Val. Acc: 86.23% | B. Val. Loss: 0.318 |  B. Val. Acc: 86.23%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.04s | lr: 1.59e-04 | Val. Loss: 0.366 |  Val. Acc: 84.44% | B. Val. Loss: 0.318 |  B. Val. Acc: 86.23%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.39s | lr: 1.79e-04 | Val. Loss: 0.291 |  Val. Acc: 87.54% | B. Val. Loss: 0.291 |  B. Val. Acc: 87.54%\n",
      "Epoch: 002 | ET: 46.95s | \t Train Loss: 0.309 | Train Acc: 87.14% \t Val. Loss: 0.300 |  Val. Acc: 87.25% \t | B. Val. Loss: 0.291 |  B. Val. Acc: 87.54%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.49s | lr: 2.23e-04 | Val. Loss: 0.262 |  Val. Acc: 89.09% | B. Val. Loss: 0.262 |  B. Val. Acc: 89.09%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.02s | lr: 2.48e-04 | Val. Loss: 0.331 |  Val. Acc: 87.06% | B. Val. Loss: 0.262 |  B. Val. Acc: 89.09%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.38s | lr: 2.74e-04 | Val. Loss: 0.362 |  Val. Acc: 85.80% | B. Val. Loss: 0.262 |  B. Val. Acc: 89.09%\n",
      "Epoch: 003 | ET: 46.87s | \t Train Loss: 0.233 | Train Acc: 91.11% \t Val. Loss: 0.249 |  Val. Acc: 89.58% \t | B. Val. Loss: 0.249 |  B. Val. Acc: 89.58%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.48s | lr: 3.26e-04 | Val. Loss: 0.233 |  Val. Acc: 89.68% | B. Val. Loss: 0.233 |  B. Val. Acc: 89.68%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.03s | lr: 3.52e-04 | Val. Loss: 0.254 |  Val. Acc: 89.34% | B. Val. Loss: 0.233 |  B. Val. Acc: 89.68%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.40s | lr: 3.77e-04 | Val. Loss: 0.235 |  Val. Acc: 90.11% | B. Val. Loss: 0.233 |  B. Val. Acc: 90.11%\n",
      "Epoch: 004 | ET: 46.97s | \t Train Loss: 0.294 | Train Acc: 87.81% \t Val. Loss: 0.315 |  Val. Acc: 87.11% \t | B. Val. Loss: 0.233 |  B. Val. Acc: 90.11%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.217 |  Val. Acc: 90.31% | B. Val. Loss: 0.217 |  B. Val. Acc: 90.31%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.07s | lr: 4.42e-04 | Val. Loss: 0.242 |  Val. Acc: 90.11% | B. Val. Loss: 0.217 |  B. Val. Acc: 90.31%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.43s | lr: 4.59e-04 | Val. Loss: 0.279 |  Val. Acc: 86.91% | B. Val. Loss: 0.217 |  B. Val. Acc: 90.31%\n",
      "Epoch: 005 | ET: 46.96s | \t Train Loss: 0.231 | Train Acc: 91.71% \t Val. Loss: 0.243 |  Val. Acc: 90.50% \t | B. Val. Loss: 0.217 |  B. Val. Acc: 90.50%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.56s | lr: 4.85e-04 | Val. Loss: 0.228 |  Val. Acc: 89.77% | B. Val. Loss: 0.217 |  B. Val. Acc: 90.50%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 13.94s | lr: 4.93e-04 | Val. Loss: 0.223 |  Val. Acc: 90.64% | B. Val. Loss: 0.217 |  B. Val. Acc: 90.64%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.51s | lr: 4.98e-04 | Val. Loss: 0.210 |  Val. Acc: 90.01% | B. Val. Loss: 0.210 |  B. Val. Acc: 90.64%\n",
      "Epoch: 006 | ET: 46.84s | \t Train Loss: 0.183 | Train Acc: 91.92% \t Val. Loss: 0.204 |  Val. Acc: 90.35% \t | B. Val. Loss: 0.204 |  B. Val. Acc: 90.64%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.49s | lr: 5.00e-04 | Val. Loss: 0.230 |  Val. Acc: 89.92% | B. Val. Loss: 0.204 |  B. Val. Acc: 90.64%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.87s | lr: 4.98e-04 | Val. Loss: 0.203 |  Val. Acc: 90.89% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.89%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.44s | lr: 4.96e-04 | Val. Loss: 0.213 |  Val. Acc: 90.79% | B. Val. Loss: 0.203 |  B. Val. Acc: 90.89%\n",
      "Epoch: 007 | ET: 46.75s | \t Train Loss: 0.191 | Train Acc: 92.51% \t Val. Loss: 0.210 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 90.89%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.51s | lr: 4.90e-04 | Val. Loss: 0.197 |  Val. Acc: 91.03% | B. Val. Loss: 0.197 |  B. Val. Acc: 91.03%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.07s | lr: 4.86e-04 | Val. Loss: 0.200 |  Val. Acc: 91.13% | B. Val. Loss: 0.197 |  B. Val. Acc: 91.13%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.64s | lr: 4.81e-04 | Val. Loss: 0.223 |  Val. Acc: 89.63% | B. Val. Loss: 0.197 |  B. Val. Acc: 91.13%\n",
      "Epoch: 008 | ET: 46.96s | \t Train Loss: 0.193 | Train Acc: 91.98% \t Val. Loss: 0.204 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.197 |  B. Val. Acc: 91.13%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.187 |  Val. Acc: 91.76% | B. Val. Loss: 0.187 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 14.04s | lr: 4.62e-04 | Val. Loss: 0.224 |  Val. Acc: 90.45% | B. Val. Loss: 0.187 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.41s | lr: 4.55e-04 | Val. Loss: 0.188 |  Val. Acc: 91.76% | B. Val. Loss: 0.187 |  B. Val. Acc: 91.76%\n",
      "Epoch: 009 | ET: 46.74s | \t Train Loss: 0.192 | Train Acc: 92.04% \t Val. Loss: 0.203 |  Val. Acc: 90.84% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 91.76%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.185 |  Val. Acc: 91.42% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.76%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.86s | lr: 4.28e-04 | Val. Loss: 0.192 |  Val. Acc: 91.90% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.41s | lr: 4.18e-04 | Val. Loss: 0.190 |  Val. Acc: 91.52% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 010 | ET: 46.75s | \t Train Loss: 0.179 | Train Acc: 92.62% \t Val. Loss: 0.220 |  Val. Acc: 91.08% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.204 |  Val. Acc: 91.57% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.94s | lr: 3.85e-04 | Val. Loss: 0.205 |  Val. Acc: 91.52% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.31s | lr: 3.73e-04 | Val. Loss: 0.207 |  Val. Acc: 90.55% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 011 | ET: 46.68s | \t Train Loss: 0.173 | Train Acc: 92.67% \t Val. Loss: 0.199 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.199 |  Val. Acc: 91.23% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 13.86s | lr: 3.36e-04 | Val. Loss: 0.194 |  Val. Acc: 91.47% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.26s | lr: 3.23e-04 | Val. Loss: 0.204 |  Val. Acc: 90.89% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 012 | ET: 46.71s | \t Train Loss: 0.193 | Train Acc: 91.91% \t Val. Loss: 0.216 |  Val. Acc: 90.21% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.51s | lr: 2.96e-04 | Val. Loss: 0.188 |  Val. Acc: 91.47% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.93s | lr: 2.82e-04 | Val. Loss: 0.201 |  Val. Acc: 90.55% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.33s | lr: 2.68e-04 | Val. Loss: 0.245 |  Val. Acc: 90.94% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 013 | ET: 46.75s | \t Train Loss: 0.156 | Train Acc: 93.32% \t Val. Loss: 0.196 |  Val. Acc: 91.08% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.51s | lr: 2.41e-04 | Val. Loss: 0.185 |  Val. Acc: 91.66% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.89s | lr: 2.27e-04 | Val. Loss: 0.193 |  Val. Acc: 91.32% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.27s | lr: 2.14e-04 | Val. Loss: 0.192 |  Val. Acc: 91.61% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 014 | ET: 46.64s | \t Train Loss: 0.152 | Train Acc: 93.76% \t Val. Loss: 0.198 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.50s | lr: 1.87e-04 | Val. Loss: 0.195 |  Val. Acc: 91.08% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 13.89s | lr: 1.74e-04 | Val. Loss: 0.202 |  Val. Acc: 91.66% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.29s | lr: 1.61e-04 | Val. Loss: 0.194 |  Val. Acc: 91.42% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 015 | ET: 46.66s | \t Train Loss: 0.148 | Train Acc: 93.69% \t Val. Loss: 0.195 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.196 |  Val. Acc: 91.42% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.90s | lr: 1.24e-04 | Val. Loss: 0.202 |  Val. Acc: 91.37% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.27s | lr: 1.13e-04 | Val. Loss: 0.197 |  Val. Acc: 91.42% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 016 | ET: 46.63s | \t Train Loss: 0.131 | Train Acc: 94.84% \t Val. Loss: 0.195 |  Val. Acc: 91.32% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.59s | lr: 9.17e-05 | Val. Loss: 0.192 |  Val. Acc: 91.66% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.98s | lr: 8.16e-05 | Val. Loss: 0.206 |  Val. Acc: 91.27% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.38s | lr: 7.21e-05 | Val. Loss: 0.191 |  Val. Acc: 91.23% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "Epoch: 017 | ET: 46.80s | \t Train Loss: 0.130 | Train Acc: 94.40% \t Val. Loss: 0.208 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.50s | lr: 5.51e-05 | Val. Loss: 0.205 |  Val. Acc: 91.32% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.88s | lr: 4.74e-05 | Val. Loss: 0.205 |  Val. Acc: 91.71% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.28s | lr: 4.04e-05 | Val. Loss: 0.195 |  Val. Acc: 91.95% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "Epoch: 018 | ET: 46.87s | \t Train Loss: 0.115 | Train Acc: 95.44% \t Val. Loss: 0.204 |  Val. Acc: 90.94% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.203 |  Val. Acc: 91.37% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.87s | lr: 2.37e-05 | Val. Loss: 0.208 |  Val. Acc: 90.89% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.25s | lr: 1.95e-05 | Val. Loss: 0.213 |  Val. Acc: 91.13% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "Epoch: 019 | ET: 46.64s | \t Train Loss: 0.108 | Train Acc: 95.93% \t Val. Loss: 0.208 |  Val. Acc: 91.13% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.50s | lr: 1.34e-05 | Val. Loss: 0.205 |  Val. Acc: 91.03% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.88s | lr: 1.15e-05 | Val. Loss: 0.210 |  Val. Acc: 90.94% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.25s | lr: 1.04e-05 | Val. Loss: 0.207 |  Val. Acc: 91.18% | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "Epoch: 020 | ET: 46.66s | \t Train Loss: 0.107 | Train Acc: 95.73% \t Val. Loss: 0.213 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.185 |  B. Val. Acc: 91.95%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of the parameters: 6948609\n",
      "\n",
      "Training\n",
      "-----    4    4    ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 001 | Batch Id: 00065 | ET: 5.48s | lr: 1.02e-04 | Val. Loss: 0.438 |  Val. Acc: 78.14% | B. Val. Loss: 0.438 |  B. Val. Acc: 78.14%\n",
      "\t | Epoch: 001 | Batch Id: 00130 | ET: 13.93s | lr: 1.07e-04 | Val. Loss: 0.416 |  Val. Acc: 80.37% | B. Val. Loss: 0.416 |  B. Val. Acc: 80.37%\n",
      "\t | Epoch: 001 | Batch Id: 00195 | ET: 22.49s | lr: 1.15e-04 | Val. Loss: 0.424 |  Val. Acc: 80.85% | B. Val. Loss: 0.416 |  B. Val. Acc: 80.85%\n",
      "Epoch: 001 | ET: 47.25s | \t Train Loss: 0.342 | Train Acc: 85.74% \t Val. Loss: 0.349 |  Val. Acc: 85.22% \t | B. Val. Loss: 0.349 |  B. Val. Acc: 85.22%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 002 | Batch Id: 00065 | ET: 5.49s | lr: 1.41e-04 | Val. Loss: 0.335 |  Val. Acc: 85.65% | B. Val. Loss: 0.335 |  B. Val. Acc: 85.65%\n",
      "\t | Epoch: 002 | Batch Id: 00130 | ET: 14.03s | lr: 1.59e-04 | Val. Loss: 0.331 |  Val. Acc: 86.72% | B. Val. Loss: 0.331 |  B. Val. Acc: 86.72%\n",
      "\t | Epoch: 002 | Batch Id: 00195 | ET: 22.56s | lr: 1.79e-04 | Val. Loss: 0.394 |  Val. Acc: 86.19% | B. Val. Loss: 0.331 |  B. Val. Acc: 86.72%\n",
      "Epoch: 002 | ET: 46.82s | \t Train Loss: 0.335 | Train Acc: 85.41% \t Val. Loss: 0.348 |  Val. Acc: 85.02% \t | B. Val. Loss: 0.331 |  B. Val. Acc: 86.72%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 003 | Batch Id: 00065 | ET: 5.48s | lr: 2.23e-04 | Val. Loss: 0.281 |  Val. Acc: 88.27% | B. Val. Loss: 0.281 |  B. Val. Acc: 88.27%\n",
      "\t | Epoch: 003 | Batch Id: 00130 | ET: 14.03s | lr: 2.48e-04 | Val. Loss: 0.344 |  Val. Acc: 87.98% | B. Val. Loss: 0.281 |  B. Val. Acc: 88.27%\n",
      "\t | Epoch: 003 | Batch Id: 00195 | ET: 22.40s | lr: 2.74e-04 | Val. Loss: 0.273 |  Val. Acc: 89.14% | B. Val. Loss: 0.273 |  B. Val. Acc: 89.14%\n",
      "Epoch: 003 | ET: 46.93s | \t Train Loss: 0.303 | Train Acc: 89.19% \t Val. Loss: 0.321 |  Val. Acc: 88.56% \t | B. Val. Loss: 0.273 |  B. Val. Acc: 89.14%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 004 | Batch Id: 00065 | ET: 5.48s | lr: 3.26e-04 | Val. Loss: 0.236 |  Val. Acc: 89.63% | B. Val. Loss: 0.236 |  B. Val. Acc: 89.63%\n",
      "\t | Epoch: 004 | Batch Id: 00130 | ET: 14.05s | lr: 3.52e-04 | Val. Loss: 0.286 |  Val. Acc: 87.83% | B. Val. Loss: 0.236 |  B. Val. Acc: 89.63%\n",
      "\t | Epoch: 004 | Batch Id: 00195 | ET: 22.41s | lr: 3.77e-04 | Val. Loss: 0.249 |  Val. Acc: 87.88% | B. Val. Loss: 0.236 |  B. Val. Acc: 89.63%\n",
      "Epoch: 004 | ET: 46.72s | \t Train Loss: 0.209 | Train Acc: 91.68% \t Val. Loss: 0.232 |  Val. Acc: 89.48% \t | B. Val. Loss: 0.232 |  B. Val. Acc: 89.63%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 005 | Batch Id: 00065 | ET: 5.50s | lr: 4.22e-04 | Val. Loss: 0.241 |  Val. Acc: 90.21% | B. Val. Loss: 0.232 |  B. Val. Acc: 90.21%\n",
      "\t | Epoch: 005 | Batch Id: 00130 | ET: 14.09s | lr: 4.42e-04 | Val. Loss: 0.275 |  Val. Acc: 87.88% | B. Val. Loss: 0.232 |  B. Val. Acc: 90.21%\n",
      "\t | Epoch: 005 | Batch Id: 00195 | ET: 22.44s | lr: 4.59e-04 | Val. Loss: 0.271 |  Val. Acc: 88.95% | B. Val. Loss: 0.232 |  B. Val. Acc: 90.21%\n",
      "Epoch: 005 | ET: 47.06s | \t Train Loss: 0.192 | Train Acc: 91.94% \t Val. Loss: 0.203 |  Val. Acc: 90.35% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 90.35%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 006 | Batch Id: 00065 | ET: 5.48s | lr: 4.85e-04 | Val. Loss: 0.213 |  Val. Acc: 91.47% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 006 | Batch Id: 00130 | ET: 14.04s | lr: 4.93e-04 | Val. Loss: 0.227 |  Val. Acc: 89.92% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 006 | Batch Id: 00195 | ET: 22.41s | lr: 4.98e-04 | Val. Loss: 0.214 |  Val. Acc: 90.74% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "Epoch: 006 | ET: 46.69s | \t Train Loss: 0.207 | Train Acc: 91.40% \t Val. Loss: 0.221 |  Val. Acc: 90.01% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 007 | Batch Id: 00065 | ET: 5.48s | lr: 5.00e-04 | Val. Loss: 0.208 |  Val. Acc: 91.23% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 007 | Batch Id: 00130 | ET: 13.83s | lr: 4.98e-04 | Val. Loss: 0.218 |  Val. Acc: 89.87% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "\t | Epoch: 007 | Batch Id: 00195 | ET: 22.18s | lr: 4.96e-04 | Val. Loss: 0.228 |  Val. Acc: 89.77% | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "Epoch: 007 | ET: 46.45s | \t Train Loss: 0.207 | Train Acc: 91.38% \t Val. Loss: 0.221 |  Val. Acc: 89.97% \t | B. Val. Loss: 0.203 |  B. Val. Acc: 91.47%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 008 | Batch Id: 00065 | ET: 5.49s | lr: 4.90e-04 | Val. Loss: 0.196 |  Val. Acc: 91.61% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 008 | Batch Id: 00130 | ET: 14.04s | lr: 4.86e-04 | Val. Loss: 0.277 |  Val. Acc: 87.64% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 008 | Batch Id: 00195 | ET: 22.38s | lr: 4.81e-04 | Val. Loss: 0.261 |  Val. Acc: 89.19% | B. Val. Loss: 0.196 |  B. Val. Acc: 91.61%\n",
      "Epoch: 008 | ET: 46.67s | \t Train Loss: 0.184 | Train Acc: 92.40% \t Val. Loss: 0.207 |  Val. Acc: 91.23% \t | B. Val. Loss: 0.196 |  B. Val. Acc: 91.61%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 009 | Batch Id: 00065 | ET: 5.49s | lr: 4.69e-04 | Val. Loss: 0.195 |  Val. Acc: 91.13% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 009 | Batch Id: 00130 | ET: 13.84s | lr: 4.62e-04 | Val. Loss: 0.199 |  Val. Acc: 91.32% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.61%\n",
      "\t | Epoch: 009 | Batch Id: 00195 | ET: 22.19s | lr: 4.55e-04 | Val. Loss: 0.196 |  Val. Acc: 91.71% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "Epoch: 009 | ET: 46.69s | \t Train Loss: 0.191 | Train Acc: 91.92% \t Val. Loss: 0.217 |  Val. Acc: 90.98% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 010 | Batch Id: 00065 | ET: 5.48s | lr: 4.38e-04 | Val. Loss: 0.199 |  Val. Acc: 91.27% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00130 | ET: 13.86s | lr: 4.28e-04 | Val. Loss: 0.197 |  Val. Acc: 91.52% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 010 | Batch Id: 00195 | ET: 22.22s | lr: 4.18e-04 | Val. Loss: 0.204 |  Val. Acc: 91.03% | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "Epoch: 010 | ET: 46.54s | \t Train Loss: 0.167 | Train Acc: 93.07% \t Val. Loss: 0.195 |  Val. Acc: 91.42% \t | B. Val. Loss: 0.195 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 011 | Batch Id: 00065 | ET: 5.50s | lr: 3.97e-04 | Val. Loss: 0.194 |  Val. Acc: 91.57% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 011 | Batch Id: 00130 | ET: 13.87s | lr: 3.85e-04 | Val. Loss: 0.200 |  Val. Acc: 91.18% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.71%\n",
      "\t | Epoch: 011 | Batch Id: 00195 | ET: 22.31s | lr: 3.73e-04 | Val. Loss: 0.211 |  Val. Acc: 90.40% | B. Val. Loss: 0.194 |  B. Val. Acc: 91.71%\n",
      "Epoch: 011 | ET: 46.65s | \t Train Loss: 0.168 | Train Acc: 92.52% \t Val. Loss: 0.194 |  Val. Acc: 90.69% \t | B. Val. Loss: 0.194 |  B. Val. Acc: 91.71%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 012 | Batch Id: 00065 | ET: 5.49s | lr: 3.49e-04 | Val. Loss: 0.189 |  Val. Acc: 91.90% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00130 | ET: 14.05s | lr: 3.36e-04 | Val. Loss: 0.210 |  Val. Acc: 91.37% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 012 | Batch Id: 00195 | ET: 22.42s | lr: 3.23e-04 | Val. Loss: 0.190 |  Val. Acc: 91.90% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "Epoch: 012 | ET: 46.76s | \t Train Loss: 0.163 | Train Acc: 93.21% \t Val. Loss: 0.193 |  Val. Acc: 91.27% \t | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 013 | Batch Id: 00065 | ET: 5.49s | lr: 2.96e-04 | Val. Loss: 0.196 |  Val. Acc: 91.23% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 013 | Batch Id: 00130 | ET: 13.86s | lr: 2.82e-04 | Val. Loss: 0.230 |  Val. Acc: 90.11% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "\t | Epoch: 013 | Batch Id: 00195 | ET: 22.22s | lr: 2.68e-04 | Val. Loss: 0.190 |  Val. Acc: 91.57% | B. Val. Loss: 0.189 |  B. Val. Acc: 91.90%\n",
      "Epoch: 013 | ET: 46.80s | \t Train Loss: 0.150 | Train Acc: 93.75% \t Val. Loss: 0.187 |  Val. Acc: 92.00% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 014 | Batch Id: 00065 | ET: 5.52s | lr: 2.41e-04 | Val. Loss: 0.195 |  Val. Acc: 91.71% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00130 | ET: 13.91s | lr: 2.27e-04 | Val. Loss: 0.200 |  Val. Acc: 91.57% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "\t | Epoch: 014 | Batch Id: 00195 | ET: 22.29s | lr: 2.14e-04 | Val. Loss: 0.197 |  Val. Acc: 91.66% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "Epoch: 014 | ET: 46.70s | \t Train Loss: 0.165 | Train Acc: 92.86% \t Val. Loss: 0.208 |  Val. Acc: 90.79% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.00%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 015 | Batch Id: 00065 | ET: 5.50s | lr: 1.87e-04 | Val. Loss: 0.193 |  Val. Acc: 92.29% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 015 | Batch Id: 00130 | ET: 14.08s | lr: 1.74e-04 | Val. Loss: 0.187 |  Val. Acc: 91.90% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 015 | Batch Id: 00195 | ET: 22.46s | lr: 1.61e-04 | Val. Loss: 0.196 |  Val. Acc: 91.37% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "Epoch: 015 | ET: 46.86s | \t Train Loss: 0.134 | Train Acc: 94.54% \t Val. Loss: 0.201 |  Val. Acc: 91.66% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 016 | Batch Id: 00065 | ET: 5.50s | lr: 1.36e-04 | Val. Loss: 0.195 |  Val. Acc: 91.86% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 016 | Batch Id: 00130 | ET: 13.89s | lr: 1.24e-04 | Val. Loss: 0.194 |  Val. Acc: 91.42% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 016 | Batch Id: 00195 | ET: 22.27s | lr: 1.13e-04 | Val. Loss: 0.202 |  Val. Acc: 91.18% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "Epoch: 016 | ET: 46.79s | \t Train Loss: 0.136 | Train Acc: 94.39% \t Val. Loss: 0.211 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 017 | Batch Id: 00065 | ET: 5.58s | lr: 9.17e-05 | Val. Loss: 0.201 |  Val. Acc: 91.90% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 017 | Batch Id: 00130 | ET: 13.96s | lr: 8.16e-05 | Val. Loss: 0.206 |  Val. Acc: 91.57% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 017 | Batch Id: 00195 | ET: 22.32s | lr: 7.21e-05 | Val. Loss: 0.205 |  Val. Acc: 91.86% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "Epoch: 017 | ET: 46.66s | \t Train Loss: 0.119 | Train Acc: 95.44% \t Val. Loss: 0.198 |  Val. Acc: 91.61% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 018 | Batch Id: 00065 | ET: 5.51s | lr: 5.51e-05 | Val. Loss: 0.201 |  Val. Acc: 91.81% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 018 | Batch Id: 00130 | ET: 13.87s | lr: 4.74e-05 | Val. Loss: 0.208 |  Val. Acc: 91.86% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 018 | Batch Id: 00195 | ET: 22.24s | lr: 4.04e-05 | Val. Loss: 0.205 |  Val. Acc: 91.47% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "Epoch: 018 | ET: 46.56s | \t Train Loss: 0.106 | Train Acc: 95.87% \t Val. Loss: 0.202 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 019 | Batch Id: 00065 | ET: 5.49s | lr: 2.86e-05 | Val. Loss: 0.205 |  Val. Acc: 91.90% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 019 | Batch Id: 00130 | ET: 13.86s | lr: 2.37e-05 | Val. Loss: 0.210 |  Val. Acc: 91.86% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 019 | Batch Id: 00195 | ET: 22.23s | lr: 1.95e-05 | Val. Loss: 0.214 |  Val. Acc: 91.95% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "Epoch: 019 | ET: 46.55s | \t Train Loss: 0.100 | Train Acc: 96.09% \t Val. Loss: 0.211 |  Val. Acc: 91.57% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\t | Epoch: 020 | Batch Id: 00065 | ET: 5.49s | lr: 1.34e-05 | Val. Loss: 0.210 |  Val. Acc: 92.00% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 020 | Batch Id: 00130 | ET: 13.85s | lr: 1.15e-05 | Val. Loss: 0.217 |  Val. Acc: 91.95% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "\t | Epoch: 020 | Batch Id: 00195 | ET: 22.21s | lr: 1.04e-05 | Val. Loss: 0.220 |  Val. Acc: 91.76% | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "Epoch: 020 | ET: 46.50s | \t Train Loss: 0.096 | Train Acc: 96.41% \t Val. Loss: 0.221 |  Val. Acc: 91.90% \t | B. Val. Loss: 0.187 |  B. Val. Acc: 92.29%\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for split_num, (train_index, valid_index) in enumerate(kf.split(data_train)):\n",
    "    for model_num in range(5): \n",
    "        X_train, X_valid = data_train[train_index], data_train[valid_index]\n",
    "        y_train, y_valid = data_train_labels[train_index], data_train_labels[valid_index]\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loader = create_dataloader(X_train, y_train, batch_size=BATCH_SIZE, n_fft=N_FFT, hop_length=HOP_LEN, shuffle=True, augment=AUGM)\n",
    "        valid_loader = create_dataloader(X_valid, y_valid, batch_size=BATCH_SIZE, n_fft=N_FFT, hop_length=HOP_LEN, shuffle=False, augment=False)\n",
    "        \n",
    "        EVAL_FREQ_ = len(train_loader)//EVAL_FREQ + 1\n",
    "        \n",
    "        \n",
    "        model = Densenet121()\n",
    "        model.to(device)\n",
    "        \n",
    "        if len(dev_names)>1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        model.to(device)\n",
    "        print(f\"Number of the parameters: {count_parameters(model)}\\n\")\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        \n",
    "        criterion = torch.nn.BCEWithLogitsLoss(reduction=\"sum\").to(device)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LEARNING_RATE, div_factor=DIV_FACTOR, final_div_factor=FINAL_DIV_FACTOR, steps_per_epoch=len(train_loader), epochs = EPOCHS, verbose=0)\n",
    "        \n",
    "    \n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        valid_accs = []\n",
    "        valid_losses = []\n",
    "    \n",
    "    \n",
    "    \n",
    "        f = open(f\"{RESULTS_FILENAME}_{split_num}_{model_num}.csv\", \"w\")\n",
    "        f.write(160*\"-\"+\"\\n\")\n",
    "        f.write(f\"Device: {dev_names[0]} | Number: {len(dev_names)}\\n\")\n",
    "        f.write(f\"Epochs: {EPOCHS}\\n\")\n",
    "        f.write(f\"Optimizer: {type (optimizer).__name__}\\n\") \n",
    "        f.write(f\"Scheduler: {type (scheduler).__name__}\\n\") \n",
    "        f.write(f\"Div factor: {DIV_FACTOR}\\n\") \n",
    "        f.write(f\"Final div factor: {FINAL_DIV_FACTOR}\\n\") \n",
    "        f.write(f\"Weight decay: {WEIGHT_DECAY}\\n\") \n",
    "        f.write(f\"Learning rate: {LEARNING_RATE}\\n\") \n",
    "        f.write(f\"Number of the parameters: {count_parameters(model)}\\n\")\n",
    "        f.write(f\"Model: {model}\\n\")\n",
    "        f.write(160*\"-\"+\"\\n\")\n",
    "        f.close()\n",
    "        print(\"Training\")\n",
    "        print(5 * \"-\" + f\"{split_num:5}\"+f\"{model_num:5}\" + 4*\" \"+ 160 * \"-\")\n",
    "    \n",
    "        best_valid_loss = float('inf')\n",
    "        best_valid_acc = -1.0\n",
    "        valid_acc = 0.0\n",
    "    \n",
    "        all_time_s = 0.0\n",
    "        lr = 0.0\n",
    "    \n",
    "        train_accs = []\n",
    "        train_losses = []\n",
    "        valid_accs = []\n",
    "        valid_losses = []\n",
    "        valid_indices = []\n",
    "    \n",
    "        # Training the `split_num`-th model\n",
    "        for epoch in range(EPOCHS):\n",
    "    \n",
    "            start_time = default_timer()\n",
    "    \n",
    "            epoch_loss = 0.0\n",
    "            epoch_acc = 0.0\n",
    "    \n",
    "            model.train()\n",
    "    \n",
    "            batch_id = 0\n",
    "            number_of_training_elements = 0\n",
    "    \n",
    "            valid_accs_temp = []\n",
    "            valid_losses_temp = []\n",
    "            valid_indices_temp = []\n",
    "    \n",
    "            for x, y in train_loader:\n",
    "                x, y = x.to(device), y.float().to(device).view(-1,1)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                y_pred = model(x)\n",
    "                \n",
    "                loss = criterion(y_pred, y)\n",
    "                \n",
    "                batch_size = x.shape[0]\n",
    "                number_of_training_elements += batch_size\n",
    "    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "    \n",
    "                end_time = default_timer()\n",
    "    \n",
    "                # Evaluating the model\n",
    "                if (batch_id+1)%EVAL_FREQ_==0:\n",
    "    \n",
    "                    valid_indices_temp.append(batch_id+1)\n",
    "                    valid_loss, valid_acc = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "                    valid_losses_temp.append(valid_loss)\n",
    "                    valid_accs_temp.append(valid_acc)\n",
    "    \n",
    "                    if valid_acc > best_valid_acc:\n",
    "                        best_valid_acc = valid_acc\n",
    "                        torch.save(model.state_dict(), f\"{BEST_MODEL_FILENAME}_{split_num}_{model_num}.pt\")\n",
    "    \n",
    "                    if valid_loss < best_valid_loss:\n",
    "                        best_valid_loss = valid_loss\n",
    "    \n",
    "                    lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "                    line = f'\\t | Epoch: {epoch+1:03} | Batch Id: {batch_id+1:05} | ET: {end_time-start_time:.2f}s | lr: {lr:.2e} | Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | B. Val. Loss: {best_valid_loss:.3f} |  B. Val. Acc: {best_valid_acc*100:.2f}%'\n",
    "                    print(line)\n",
    "                    f = open(f\"{RESULTS_FILENAME}_{split_num}_{model_num}.csv\", \"a\")\n",
    "                    f.write(line+\"\\n\")\n",
    "                    f.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "                batch_id+=1\n",
    "                scheduler.step()\n",
    "    \n",
    "            valid_indices_temp.append(batch_id)\n",
    "            valid_loss, valid_acc = evaluate(model, valid_loader, criterion, device)\n",
    "    \n",
    "            valid_losses_temp.append(valid_loss)\n",
    "            valid_accs_temp.append(valid_acc)\n",
    "    \n",
    "            valid_losses.append(valid_losses_temp)\n",
    "            valid_accs.append(valid_accs_temp)\n",
    "    \n",
    "            valid_indices.append(valid_indices_temp)\n",
    "    \n",
    "            if valid_acc > best_valid_acc:\n",
    "                best_valid_acc = valid_acc\n",
    "                torch.save(model.state_dict(), f\"{BEST_MODEL_FILENAME}_{split_num}_{model_num}.pt\")\n",
    "    \n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "    \n",
    "            train_loss, train_acc = evaluate(model, train_loader, criterion, device)\n",
    "    \n",
    "            end_time = default_timer()\n",
    "    \n",
    "            all_time_s += end_time - start_time\n",
    "    \n",
    "            train_losses.append(train_loss)\n",
    "            train_accs.append(train_acc)\n",
    "    \n",
    "            line = f'Epoch: {epoch+1:03} | ET: {end_time-start_time:.2f}s | \\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% \\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\t | B. Val. Loss: {best_valid_loss:.3f} |  B. Val. Acc: {best_valid_acc*100:.2f}%'\n",
    "            print(line)\n",
    "            print(160*\"-\")\n",
    "    \n",
    "            f = open(f\"{RESULTS_FILENAME}_{split_num}_{model_num}.csv\", \"a\")\n",
    "            f.write(line+\"\\n\")\n",
    "            f.write(160*\"-\"+\"\\n\")\n",
    "            f.close()\n",
    "    \n",
    "        line = f\"\\nDuration: {all_time_s:.2f}s\\n\"\n",
    "        f = open(f\"{RESULTS_FILENAME}_{split_num}_{model_num}.csv\", \"a\")\n",
    "        f.write(line+\"\\n\")\n",
    "        f.write(80*\"-\"+\"\\n\")\n",
    "        f.close()\n",
    "    \n",
    "        # Saving the results for analyzing them later in the evaluation part\n",
    "        valid_losses_plot = []\n",
    "        valid_accs_plot = []\n",
    "        epoch_plot = []\n",
    "        for epoch in range(len(valid_accs)):\n",
    "            valid_accs_temp = valid_accs[epoch]\n",
    "            valid_losses_temp = valid_losses[epoch]\n",
    "            valid_indices_temp = valid_indices[epoch]\n",
    "            ind = 0\n",
    "            for mini_batch_id in valid_indices_temp:\n",
    "                epoch_plot.append(epoch + mini_batch_id/len(train_loader))\n",
    "                valid_accs_plot.append(valid_accs_temp[ind]*100)\n",
    "                valid_losses_plot.append(valid_losses_temp[ind])\n",
    "                ind += 1\n",
    "    \n",
    "        valid_results = pd.DataFrame({\"epoch\":epoch_plot,\n",
    "                      \"valid_loss\":valid_losses_plot,\n",
    "                      \"valid_acc\":valid_accs_plot\n",
    "                      })\n",
    "    \n",
    "        valid_results.to_csv(f\"{VALID_RESULTS_FILENAME}_{split_num}_{model_num}.csv\",sep=\";\",index=False)\n",
    "        train_accs = [acc*100 for acc in train_accs]\n",
    "        train_results = pd.DataFrame({\"epoch\":list(np.arange(1,EPOCHS+1,1)),\n",
    "                      \"train_loss\":train_losses,\n",
    "                      \"train_acc\":train_accs\n",
    "                      })\n",
    "        train_results.to_csv(f\"{TRAIN_RESULTS_FILENAME}_{split_num}_{model_num}.csv\",sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e4458c1-bb7c-4431-9b28-d50a3cb74b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4163\n",
       "0    4090\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e24536b-29e4-48e2-a0ed-b58cf1540998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1068\n",
       "1     995\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_valid).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac146c6-75f8-4ca0-bc5f-5bd3ac74d79c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
